t.test(pop_est_immigrants ~ home_location_in_UK,
data = data_wk9_f,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_christian ~ home_location_in_UK, data = data_wk9_f)
# run unrelated samples t-test
t.test(pop_est_christian ~ home_location_in_UK,
data = data_wk9_f,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_muslim ~ home_location_in_UK, data = data_wk9_f)
# run unrelated samples t-test
t.test(pop_est_muslim ~ home_location_in_UK,
data = data_wk9_f,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_age ~ home_location_in_UK, data = data_wk9_f)
# run unrelated samples t-test
t.test(pop_est_age ~ home_location_in_UK,
data = data_wk9_f,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
library(effectsize)
library(pwr)
cohens_d(time ~ condition,
data = d_stroop,
paired = TRUE)
compatible_condition <-
d_stroop %>%
filter(condition == "compatible")
incompatible_condition <-
d_stroop %>%
filter(condition == "incompatible")
cohens_d(x = compatible_condition,
y = incompatible_condition
paired = TRUE)
cohens_d(x = compatible_condition,
y = incompatible_condition,
paired = TRUE)
cohens_d(x = compatible_condition$time,
y = incompatible_condition$time,
paired = TRUE)
pwr.t.test(d = 1.27, n = 20) #Q4
pwr.t.test(d = 1.27, power = .8) #Q4
pwr.t.test(d = 1.27, power = .8, type = paired) #Q5
pwr.t.test(d = value_from_step_3, n = 20, type = "paired-samples") #Q4
pwr.t.test(d = 1.27, power = .8, type = "paired-samples") #Q5
pwr.t.test(d = 1.27, power = .8, type = "paired") #Q5
pwr.t.test(d = 1.27, power = .8, type = "paired") #Q4
pwr.t.test(d = 1.27, n = 20, type = "paired") #Q4
pwr.t.test(d = 1.27, power = .8, type = "paired") #Q4
pwr.t.test(power = .8, n = 40, type = "paired") #Q5
quarto render
quarto render
install.packages("rmarkdown")
quarto render
install.packages("shiny")
install.packages("tidyverse")
install.packages("learnr")
install.packages("kableExtra")
install.packages("car")
install.packages("lsr")
install.packages("Hmisc")
install.packages("ggeffects")
install.packages("patchwork")
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(tidyverse)
setwd("~/year1/PSYC122/data/week11")
mh <- read_csv("MillderHadenData.csv")
setwd("~/year1/PSYC122/data/week11")
mh <- read_csv("MillderHadenData.csv")
setwd("~/year1/PSYC122/data/week11")
mh <- read_csv("MillderHadenData.csv")
download.file("https://github.com/lu-psy-r/year1/blob/main/PSYC122/data/week11/MillerHadenData.csv?raw=true", destfile = "MillerHadenData.csv")
mh <- read_csv("MillderHadenData.csv")
mh <- read_csv("MillerHadenData.csv")
ggplot (mh, aes(x="TV", y="Home")) +
geom_point()
scatterplot <- ggplot (mh, aes(x="TV", y="Home")) +
geom_point()
library(broom)
library(tidyverse)
download.file("https://github.com/lu-psy-r/year1/blob/main/PSYC122/data/week11/MillerHadenData.csv?raw=true", destfile = "MillerHadenData.csv")
mh <- read_csv("MillerHadenData.csv")
ggplot (mh, aes(x="TV", y="Home")) +
geom_point()
scatterplot
library(broom)
library(tidyverse)
download.file("https://github.com/lu-psy-r/year1/blob/main/PSYC122/data/week11/MillerHadenData.csv?raw=true", destfile = "MillerHadenData.csv")
mh <- read_csv("MillerHadenData.csv")
ggplot (mh, aes(x="TV", y="Home")) +
geom_point()
mh
ggplot (mh, aes(x=TV, y=Home)) +
geom_point()
mh <- read_csv("MillerHadenData.csv")
mh #just to have a quick look at the data
ggplot (mh, aes (x = TV, y = Home)) +
geom_point()
ggplot (mh, aes (x = TV, y = Home)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
ggplot (mh, aes (x = TV, y = Home)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_bw() +
labs(x = "Time spend reading at home", y = "Time spend watching TV at home")
results <- cor.test(mh$Home,
mh$TV,
method = "pearson",
alternative = "two.sided") %>%
tidy()
results
pull(results, estimate)
r <- pull(results, estimate)
p <- pull(results, p.value)
df <- pull(results, parameter)
r <- pull(results, round(estimate,2)
r <- pull(results, round(estimate,2))
r <- results %>%
pull(estimate) %>%
round(2)
p <- results %>%
pull(p.value) %>%
round(3)
results
df <- results %>%
pull(parameter)
r-squared <- squared(r)
r-squared <- r*r
rsquared <- r*r
rsquared <- (r*r)*100
data <- read_csv("alcoholUse_Impulsivity.csv")
data
ggplot(data, aes(x = hau, y = imp)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_bw() +
labs(x = "Hazardous Alcohol Use", y = "Impulsivity")
results <- cor.test(data$hau,
data$imp,
method = "pearson",
alternative = "two.sided") %>%
tidy()
results
r <- results %>%
pull(estimate) %>%
round(2)
df <- results %>%
pull(parameter)
pvalue <- results %>%
pull(p.value) %>%
round(3)
rsquared <- r*r
rsquaredPercent <- round(rsquared * 100, 0)
?broom
---
title: "122_wk12_labActivity2"
---
title: "122_wk12_labActivity2"
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(car)
library(lsr)
library(Hmisc)
library(tidyverse)
dat <- read_csv("VapingData.csv")
dat <- dat %>%
filter(IAT_BLOCK3_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 3
filter(IAT_BLOCK5_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 5
mutate(IAT_ACC = (IAT_BLOCK3_Acc + IAT_BLOCK5_Acc)/2) %>% # 2) calculate an average IAT accuracy score across blocks 3 and 5
filter(IAT_ACC > .8) %>%                                  # 2) only keep participants with an average score greater than .8.
mutate(IAT_RT = IAT_BLOCK5_RT - IAT_BLOCK3_RT)            # 3) compute the IAT_RT score
descriptives <- dat %>%
summarise(n = n(),
mean_IAT_ACC = mean(IAT_ACC),
mean_IAT_RT = mean(IAT_RT),
mean_VPQ = mean(VapingQuestionnaireScore, na.rm = TRUE))
descriptives
dat <- dat %>%
filter(!is.na(VapingQuestionnaireScore)) %>%
filter(!is.na(IAT_RT))
ggplot(dat, aes(x = VapingQuestionnaireScore)) +
geom_histogram(binwidth = 10) +
theme_bw()
qqPlot(x = dat$VapingQuestionnaireScore)
ggplot(dat, aes(x = IAT_RT)) +
geom_histogram(binwidth = 10) +
theme_bw()
qqPlot(x = dat$IAT_RT)
ggplot(dat, aes(x = IAT_RT, y = VapingQuestionnaireScore)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_bw() +
labs(x = "Implicit attitude", y = "Explicit attitude")
results <- cor.test(dat$VapingQuestionnaireScore,
dat$IAT_RT,
method = "pearson") %>%
tidy()
results
correlation <- results %>%
pull(estimate) %>%
round(2)
df <- results %>%
pull(parameter) %>%
round(0)
pvalue <- results %>%
pull(p.value) %>%
round(3)
dat_matrix <- dat %>%
select(Age, IAT_RT, VapingQuestionnaireScore) %>%
as.data.frame() # Make sure tell R that dat is a data frame
pairs(dat_matrix)
intercor_results <- correlate(x = dat_matrix, # our data
test = TRUE, # compute p-values
corr.method = "spearman", # run a spearman test
p.adjust.method = "bonferroni") # use the bonferroni correction
intercor_results
?qqPlot
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(car)
library(tidyverse)
stars <- read_csv("stars2.csv")
engage <- read_csv("psess.csv")
head(stars) # Look at the data frames
head(engage)
stars_means <- stars %>%
group_by(ID) %>%
summarise(mean_anxiety = mean(Score, na.rm = TRUE))
stars_means
joined <- inner_join(stars_means, engage, "ID")
descriptives <- joined %>%
summarise(mean_anx = mean(mean_anxiety, na.rm = TRUE),
sd_anx = sd(mean_anxiety, na.rm = TRUE),
mean_weeks = mean(n_weeks, na.rm = TRUE),
sd_weeks = sd(n_weeks, na.rm = TRUE))
descriptives
length(joined$mean_anxiety)
length(joined$n_weeks)
ggplot(joined, aes(x = mean_anxiety, y = n_weeks)) +
geom_point() +
geom_smooth(method = "lm") +
labs(x = "Anxiety", y = "Engagement") +
theme_bw()
summarise(sd = sd(mean_anxiety), stars_means)
summarise(sd = sd(mean_anxiety), joined)
?mean
?qplot
libary(car)
library(car)
?qPlot
??qPlot
install.packages("shiny")
install.packages("learnr")
library(shiny)
library(ggplot2)
# User Interface (UI)
ui <- fluidPage(
titlePanel("t-Distribution vs. Normal Distribution (Degrees of Freedom Illustration)"),
sidebarLayout(
sidebarPanel(
sliderInput("df",
"Degrees of Freedom (df):",
min = 1,
max = 30,
value = 5)
),
mainPanel(
plotOutput("tPlot")
)
)
)
# Server logic
server <- function(input, output) {
output$tPlot <- renderPlot({
# Generate data for the plot
x_range <- seq(-4, 4, length = 500)
normal_density <- dnorm(x_range)
t_density <- dt(x_range, df = input$df) # Uses the input df value
# Create a data frame for ggplot
plot_data <- data.frame(
x = x_range,
Normal = normal_density,
T_dist = t_density
)
# Plot the distributions
ggplot(plot_data, aes(x = x)) +
geom_line(aes(y = Normal, color = "Normal Distribution"), linetype = "dashed", linewidth = 1) +
geom_line(aes(y = T_dist, color = "t-Distribution"), linewidth = 1.5) +
labs(title = paste("t-Distribution with df =", input$df),
y = "Density",
color = "Distribution") +
scale_color_manual(values = c("Normal Distribution" = "black", "t-Distribution" = "red")) +
theme_minimal()
})
}
# Run the application
shinyApp(ui = ui, server = server)
knitr::opts_chunk$set(echo = TRUE)
library(broom)
# Step 2: Load packages ---------------------------------------------------
## We'll need the following packages:
library(broom)
library(car)
library(lsr)
library(Hmisc)
library(tidyverse)
# Step 3: Read in the data ----------------------------------------------
dat <- read_csv("VapingData.csv")
# Step 1: Set your working directory --------------------------------------
getwd()
setwd("~/stats/year1/PSYC122/data/week12")
# Step 3: Read in the data ----------------------------------------------
dat <- read_csv("VapingData.csv")
# Step 4: Data wrangling --------------------------------------------------
dat <- dat %>%
filter(IAT_BLOCK3_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 3
filter(IAT_BLOCK5_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 5
mutate(IAT_ACC = (IAT_BLOCK3_Acc + IAT_BLOCK5_Acc)/2) %>% # 2) calculate an average IAT accuracy score across blocks 3 and 5
filter(IAT_ACC > .8) %>%                                  # 2) only keep participants with an average score greater than .8.
mutate(IAT_RT = IAT_BLOCK5_RT - IAT_BLOCK3_RT)            # 3) compute the IAT_RT score
descriptives <- dat %>%
summarise(n = n(),
mean_IAT_ACC = mean(IAT_ACC),
mean_IAT_RT = mean(IAT_RT),
mean_VPQ = mean(VapingQuestionnaireScore, na.rm = TRUE))
# Missing data
dat <- dat %>%
filter(!is.na(VapingQuestionnaireScore)) %>%
filter(!is.na(IAT_RT))
# Normality
ggplot(dat, aes(x = VapingQuestionnaireScore)) +
geom_histogram(binwidth = 10) +
theme_bw()
qqPlot(x = dat$VapingQuestionnaireScore)
ggplot(dat, aes(x = IAT_RT)) +
geom_histogram(binwidth = 10) +
theme_bw()
qqPlot(x = dat$IAT_RT)
# Linearity and homoscedasticity
ggplot(dat, aes(x = IAT_RT, y = VapingQuestionnaireScore)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_bw() +
labs(x = "Implicit attitude", y = "Explicit attitude")
# Step 7: Conduct a correlation analysis ----------------------------------
results <- cor.test(dat$VapingQuestionnaireScore,
dat$IAT_RT,
method = "pearson") %>%
tidy()
results
correlation <- results %>%
pull(estimate) %>%
round(2)
df <- results %>%
pull(parameter) %>%
round(0)
pvalue <- results %>%
pull(p.value) %>%
round(3)
# Create a new data frame that only include the relevant variables
dat_matrix <- dat %>%
select(Age, IAT_RT, VapingQuestionnaireScore) %>%
as.data.frame() # Make sure tell R that dat is a data frame
# Create a matrix of scatterplots
pairs(dat_matrix)
# Conduct intercorrelation (multiple correlations)
intercor_results <- correlate(x = dat_matrix, # our data
test = TRUE, # compute p-values
corr.method = "spearman", # run a spearman test
p.adjust.method = "bonferroni") # use the bonferroni correction
intercor_results
# Normality
histogramVapingQS <- ggplot(dat, aes(x = VapingQuestionnaireScore)) +
geom_histogram(binwidth = 10) +
theme_bw()
histogramVapingQS
?facet_wrap
?qqplot
# Step 2: Load packages ---------------------------------------------------
## We'll need the following packages:
library(broom)
library(car)
library(lsr)
library(Hmisc)
library(tidyverse)
# Step 3: Read in the data ----------------------------------------------
dat <- read_csv("VapingData.csv")
setwd("~/stats/year1/PSYC122")
# Step 3: Read in the data ----------------------------------------------
dat <- read_csv("VapingData.csv")
setwd("~/stats/year1/PSYC122/data/week12")
# Step 2: Load packages ---------------------------------------------------
## We'll need the following packages:
library(broom)
library(car)
library(lsr)
library(Hmisc)
library(tidyverse)
# Step 3: Read in the data ----------------------------------------------
dat <- read_csv("VapingData.csv")
# Step 4: Data wrangling --------------------------------------------------
dat <- dat %>%
filter(IAT_BLOCK3_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 3
filter(IAT_BLOCK5_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 5
mutate(IAT_ACC = (IAT_BLOCK3_Acc + IAT_BLOCK5_Acc)/2) %>% # 2) calculate an average IAT accuracy score across blocks 3 and 5
filter(IAT_ACC > .8) %>%                                  # 2) only keep participants with an average score greater than .8.
mutate(IAT_RT = IAT_BLOCK5_RT - IAT_BLOCK3_RT)            # 3) compute the IAT_RT score
descriptives <- dat %>%
summarise(n = n(),
mean_IAT_ACC = mean(IAT_ACC),
mean_IAT_RT = mean(IAT_RT),
mean_VPQ = mean(VapingQuestionnaireScore, na.rm = TRUE))
# Missing data
dat <- dat %>%
filter(!is.na(VapingQuestionnaireScore)) %>%
filter(!is.na(IAT_RT))
# Normality
histogramVapingQS <- ggplot(dat, aes(x = VapingQuestionnaireScore)) +
geom_histogram(binwidth = 10) +
theme_bw()
histogramVapingQS
qqPlot(x = dat$VapingQuestionnaireScore)
ggplot(dat, aes(x = IAT_RT)) +
geom_histogram(binwidth = 10) +
theme_bw()
qqPlot(x = dat$IAT_RT)
# Linearity and homoscedasticity
ggplot(dat, aes(x = IAT_RT, y = VapingQuestionnaireScore)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_bw() +
labs(x = "Implicit attitude", y = "Explicit attitude")
# Step 7: Conduct a correlation analysis ----------------------------------
results <- cor.test(dat$VapingQuestionnaireScore,
dat$IAT_RT,
method = "pearson") %>%
tidy()
results
correlation <- results %>%
pull(estimate) %>%
round(2)
df <- results %>%
pull(parameter) %>%
round(0)
pvalue <- results %>%
pull(p.value) %>%
round(3)
# Create a new data frame that only include the relevant variables
dat_matrix <- dat %>%
select(Age, IAT_RT, VapingQuestionnaireScore) %>%
as.data.frame() # Make sure tell R that dat is a data frame
# Create a matrix of scatterplots
pairs(dat_matrix)
# Conduct intercorrelation (multiple correlations)
intercor_results <- correlate(x = dat_matrix, # our data
test = TRUE, # compute p-values
corr.method = "spearman", # run a spearman test
p.adjust.method = "bonferroni") # use the bonferroni correction
intercor_results
# Step 3: Read in the data ----------------------------------------------
dat <- read_csv("VapingData.csv")
dat <- dat %>%
filter(IAT_BLOCK3_Acc < 1)
dat <- dat %>%
filter(IAT_BLOCK3_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 3
filter(IAT_BLOCK5_Acc < 1)
# Step 4: Data wrangling --------------------------------------------------
dat <- dat %>%
filter(IAT_BLOCK3_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 3
filter(IAT_BLOCK5_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 5
mutate(IAT_ACC = (IAT_BLOCK3_Acc + IAT_BLOCK5_Acc)/2) %>% # 2) calculate an average IAT accuracy score across blocks 3 and 5
filter(IAT_ACC > .8) %>%                                  # 2) only keep participants with an average score greater than .8.
mutate(IAT_RT = IAT_BLOCK5_RT - IAT_BLOCK3_RT)            # 3) compute the IAT_RT score
descriptives <- dat %>%
summarise(n = n(),
mean_IAT_ACC = mean(IAT_ACC),
mean_IAT_RT = mean(IAT_RT),
mean_VPQ = mean(VapingQuestionnaireScore, na.rm = TRUE))
descriptives <- dat %>%
summarise(sampleSize = n(),
mean_IAT_ACC = mean(IAT_ACC),
mean_IAT_RT = mean(IAT_RT),
mean_VPQ = mean(VapingQuestionnaireScore, na.rm = TRUE))
?n
# Step 1: Load packages ---------------------------------------------------
library(broom)
library(car)
library(tidyverse)
# Step 2: Read in the data ------------------------------------------------
stars <- read_csv("stars2.csv")
setwd("~/stats/year1/PSYC122/data/week13")
# Step 2: Read in the data ------------------------------------------------
stars <- read_csv("stars2.csv")
engage <- read_csv("psess.csv")
starsWeb <- download.file("https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week13/stars2.csv?raw=true", destfile = "stars2.csv")
# Step 1: Load packages ---------------------------------------------------
library(broom)
library(car)
library(tidyverse)
stars2 <- download.file("https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week13/stars2.csv?raw=true", destfile = "stars2.csv")
stars2
