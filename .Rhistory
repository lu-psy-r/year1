d_f <-
d %>%
filter(salary_estimate > 10000)
d_f <-
d_f %>%
filter(salary_estimate < 60000)
?t.test
library(tidyverse)
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
setwd("C:/Repos/Research/year1/PSYC121")
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
# set up the data for Task 3
d <-
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na() %>%
mutate(pID = 1:n()) %>%
pivot_longer(cols = contains("stroop"),
names_to = "condition",
names_prefix = "stroop_",
values_to = "time") %>%
mutate(time = round(time,2)) %>%
group_by(pID) %>%
mutate(avg_time = round(mean(time),2))
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25)
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric))
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na()
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na() %>%
mutate(pID = 1:n()) %>%
pivot_longer(cols = contains("stroop"),
names_to = "condition",
names_prefix = "stroop_",
values_to = "time")
# set up the data for Task 3
d <-
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na() %>%
mutate(pID = 1:n()) %>%
pivot_longer(cols = contains("stroop"),
names_to = "condition",
names_prefix = "stroop_",
values_to = "time") %>%
mutate(time = round(time,2)) %>%
group_by(pID) %>%
mutate(avg_time = round(mean(time),2))
View(d)
write_csv(d, file = "data/Week_8/stroop_wk8.csv")
write_csv(d, file = "data/Week_8/stroop_wk8_2024.csv")
#| eval: false
#| include: false
d %>%
ggplot() +
geom_density(aes(x = time, fill = condition), alpha = .8) + # you need to EDIT this line
theme_dark()
#| eval: false
#| include: false
# distribution of times by condition
d %>%
ggplot() +
geom_histogram(aes(x = avg_time), fill = "pink", colour = "purple") +
theme_classic()
#| eval: false
#| include: false
# filter out the high values
d_f <- # create a new object (or overwrite)
d %>% # original data object
filter(avg_time < 12)
# draw a new
d_f %>%
ggplot() +
geom_histogram(aes(x = avg_time),
fill = "yellow",
colour = "black",
bins = 20) +
theme_minimal()
#| eval: false
#| include: false
# filter out the high values
d_f <- # create a new object (or overwrite)
d %>% # original data object
filter(avg_time < 10)
# draw a new
d_f %>%
ggplot() +
geom_histogram(aes(x = avg_time),
fill = "yellow",
colour = "black",
bins = 20) +
theme_minimal()
348/3
#| eval: false
#| include: false
library(tidyverse)
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
setwd("D:/Repos/Research/year1/PSYC121")
#| eval: false
#| include: false
library(tidyverse)
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
# set up the data for Task 3
d <-
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na() %>%
mutate(pID = 1:n()) %>%
pivot_longer(cols = contains("stroop"),
names_to = "condition",
names_prefix = "stroop_",
values_to = "time") %>%
mutate(time = round(time,2)) %>%
group_by(pID) %>%
mutate(avg_time = round(mean(time),2))
write_csv(d, file = "data/Week_8/stroop_wk8_2024.csv")
#| eval: false
# distribution of times by condition
your_data_object %>%
ggplot() +
geom_density(aes(x = missing_column_name_A, fill = missing_column_name_B), alpha = .8) + # you need to EDIT this for Q4
theme_dark()
#| eval: false
#| include: false
d %>%
ggplot() +
geom_density(aes(x = time, fill = condition), alpha = .8) + # you need to EDIT this line
theme_dark()
#| eval: false
#| include: false
# distribution of times by condition
d %>%
ggplot() +
geom_histogram(aes(x = avg_time), fill = "pink", colour = "purple") +
theme_classic()
#| eval: false
#| include: false
# filter out the high values
d_f <- # create a new object (or overwrite)
d %>% # original data object
filter(avg_time < 10)
# draw a new
d_f %>%
ggplot() +
geom_histogram(aes(x = avg_time),
fill = "yellow",
colour = "black",
bins = 20) +
theme_minimal()
#| eval: false
#| include: false
d_f %>%
group_by(condition) %>% # you need to EDIT this for Q1
summarise(stroop_mean = mean(time)) # you need to EDIT this for Q1
#| eval: false
#| include: false
# use filter to select two levels of the IV - Q3-5
stroop_compatible <-
d_f %>% # Edit this for the name of YOUR data object
filter(condition == "compatible")
# use filter to select two levels of the IV - Q3-5
stroop_control <-
d_f %>% # Edit this for the name of YOUR data object
filter(condition == "control")
# use filter to select two levels of the IV - Q3-5
stroop_incompatible <-
d_f %>% # Edit this for the name of YOUR data object
filter(condition == "incompatible")
# run the t-test comparing the means of these two levels
t.test(x = stroop_compatible$time, y = stroop_control$time, paired = TRUE)
t.test(x = stroop_incompatible$time, y = stroop_control$time, paired = TRUE)
t.test(x = stroop_compatible$time, y = stroop_incompatible$time, paired = TRUE)
#| eval: false
#| include: false
stroop_summary <-
d_f %>%
group_by(condition) %>% # you need to EDIT this for Q2
summarise(stroop_mean = mean(time),
stroop_SE = sd(time)/sqrt(n())) # you need to EDIT this for Q1
stroop_summary
#| eval: false
#| include: false
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_point(size = 5) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
#| eval: false
#| include: false
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_col(size = 5) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
setwd("D:/Repos/Research/year1/PSYC121")
#| eval: false
#| include: false
# filter out the high values
d_f <- # create a new object (or overwrite)
d %>% # original data object
filter(avg_time < 10)
#| eval: false
#| include: false
library(tidyverse)
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
# set up the data for Task 3
d <-
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na() %>%
mutate(pID = 1:n()) %>%
pivot_longer(cols = contains("stroop"),
names_to = "condition",
names_prefix = "stroop_",
values_to = "time") %>%
mutate(time = round(time,2)) %>%
group_by(pID) %>%
mutate(avg_time = round(mean(time),2))
write_csv(d, file = "data/Week_8/stroop_wk8_2024.csv")
#| eval: false
#| include: false
# filter out the high values
d_f <- # create a new object (or overwrite)
d %>% # original data object
filter(avg_time < 10)
# draw a new
d_f %>%
ggplot() +
geom_histogram(aes(x = avg_time),
fill = "yellow",
colour = "black",
bins = 20) +
theme_minimal()
#| eval: false
#| include: false
d_f %>%
group_by(condition) %>% # you need to EDIT this for Q1
summarise(stroop_mean = mean(time)) # you need to EDIT this for Q1
setwd("D:/Repos/Research/year1/PSYC121")
# Chunk 1: setup
library(tidyverse)
library(learnr)
library(kableExtra)
load("tidy_data.RData")
load("tidy_data.RData")
setwd("D:/Repos/Research/year1/PSYC121/data/Week_9")
library(tidyverse)
library(learnr)
library(kableExtra)
load("tidy_data.RData")
data <-
data %>%
mutate(z_stroop = scale(avg_stroop))
View(data)
data <-
data %>%
rowwise() %>%
mutate(avg_stroop = round(mean(c(stroop_control,stroop_compatible,stroop_incompatible), na.rm = TRUE),2),
across(facebook_days:twitter_days, ~str_sub(.x, 1,1))) %>%
ungroup() %>%
select(facebook_days, instagram_days, twitter_days, avg_stroop) %>%
drop_na()
data <-
data %>%
mutate(z_stroop = scale(avg_stroop))
data
# because we are assigning (<-) the changes to update "data",
# we write it again here to display the results
quarto::quarto_version()
library(tidyverse)
setwd("D:/Repos/Research/year1/PSYC121/data/Week_9")
data_wk9 <- read_csv("data/Week_9/data_wk9.csv")
d_stroop <- read_csv("data/Week_9/data_stroop_wk9.csv")
#| eval: false
#| include: false
summary(data_wk9)
#| eval: false
#| include: false
data_wk9 %>%
ggplot(aes(x = pop_est_muslim, y = pop_est_immigrants)) + # map two of the columns to x and y
geom_point() # you can change the size or colour of the points if you wish
#| eval: false
#| include: false
# use mutate and scale to create z-scores of immigration estimates
data_wk9_z <-
data_wk9 %>%
mutate(z_imm = scale(pop_est_immigrants))
data_wk9
data_wk9 %>%
ggplot()
data_wk9 %>%
ggplot() +
geom_point(aes(x = pop_est_muslim, y = pop_est_immigrants))
data_wk9 %>%
ggplot(aes(x = pop_est_muslim, y = pop_est_immigrants)) +
geom_point()
data_wk9 %>%
ggplot(aes(x = pop_est_muslim, y = pop_est_immigrants)) + # map two of the columns to x and y
geom_point() # you can change the size or colour of the points if you wish
data_wk9 %>%
ggplot(aes(x = pop_est_muslim, y = pop_est_immigrants)) + # map two of the columns to x and y
geom_point() # you can change the size or colour of the points if you wish
# check the mean and sd of the new column
mean(data_object_name$column_name)
#| eval: false
#| include: false
# check the mean of the new column
mean(data_wk9_z$z_imm)
sd(data_wk9_z$z_imm)
# check the mean of the new column
mean(data_wk9_z$z_imm)
sd(data_wk9_z$z_imm)
#| eval: false
#| include: false
data_wk9_z %>%
ggplot() +
geom_histogram(aes(x = z_imm),
bins = 40)
data_wk9_z %>%
ggplot() +
geom_histogram(aes(x = z_imm),
bins = 40)
#| eval: false
#| include: false
data_wk9_z %>%
ggplot() +
geom_histogram(aes(x = z_imm),
bins = 40)
View(data_wk9_z)
# use mutate and scale to create z-scores of immigration estimates
data_wk9_z <-
data_wk9 %>%
mutate(z_imm = scale(pop_est_immigrants)[1])
# use mutate and scale to create z-scores of immigration estimates
data_wk9_z <-
data_wk9 %>%
mutate(z_imm = scale(pop_est_immigrants)[])
# use mutate and scale to create z-scores of immigration estimates
data_wk9_z <-
data_wk9 %>%
mutate(z_imm = scale(pop_est_immigrants)[1])
#| eval: false
#| include: false
# add a filter command
data_wk9_f <-
data_wk9_z %>%
filter(z_imm > -2.5 & z_imm < 2.5)
# use mutate and scale to create z-scores of immigration estimates
new_data_object_name <-
data_object_name %>%
mutate(z_imm = scale(column_name)[])
# use mutate and scale to create z-scores of immigration estimates
data_wk9_z <-
data_wk9 %>%
mutate(z_imm = scale(pop_est_immigrants)[])
# use mutate and scale to create z-scores of immigration estimates
data_wk9_z <-
data_wk9 %>%
mutate(z_imm = scale(pop_est_immigrants)[1])
# use mutate and scale to create z-scores of immigration estimates
data_wk9_z <-
data_wk9 %>%
mutate(z_imm = scale(pop_est_immigrants)[,1])
# add a filter command
data_wk9_f <-
data_wk9_z %>%
filter(z_imm > -2.5 & z_imm < 2.5)
#| eval: false
#| include: false
# summary statistics
data_wk9_f %>%
group_by(home_location_in_UK) %>%
summarise(mean_imm_est = mean(pop_est_immigrants),
sample_size = n())
#| eval: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name)
#| eval: false
# run unrelated samples t-test
t.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name,
paired = FALSE,
var.equal = missing_value) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
# run unrelated samples t-test
t.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name,
var.equal = missing_value) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_immigrants ~ home_location_in_UK, data = data_wk9_f)
#| eval: false
#| include: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_immigrants ~ home_location_in_UK, data = data_wk9_f)
# run unrelated samples t-test
t.test(pop_est_immigrants ~ home_location_in_UK,
data = data_wk9_f,
paired = FALSE,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_immigrants ~ home_location_in_UK, data = data_wk9_f)
# run unrelated samples t-test
t.test(pop_est_immigrants ~ home_location_in_UK,
data = data_wk9_f,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_christian ~ home_location_in_UK, data = data_wk9_f)
# run unrelated samples t-test
t.test(pop_est_christian ~ home_location_in_UK,
data = data_wk9_f,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_muslim ~ home_location_in_UK, data = data_wk9_f)
# run unrelated samples t-test
t.test(pop_est_muslim ~ home_location_in_UK,
data = data_wk9_f,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
# check if variances are unequal (p < .05) - Q3
var.test(pop_est_age ~ home_location_in_UK, data = data_wk9_f)
# run unrelated samples t-test
t.test(pop_est_age ~ home_location_in_UK,
data = data_wk9_f,
var.equal = TRUE) # you'll need to set this to TRUE or FALSE depending on what you found in var.test
#| eval: false
#| include: false
library(effectsize)
library(pwr)
cohens_d(time ~ condition,
data = d_stroop,
paired = TRUE)
compatible_condition <-
d_stroop %>%
filter(condition == "compatible")
incompatible_condition <-
d_stroop %>%
filter(condition == "incompatible")
cohens_d(x = compatible_condition,
y = incompatible_condition
paired = TRUE)
cohens_d(x = compatible_condition,
y = incompatible_condition,
paired = TRUE)
cohens_d(x = compatible_condition$time,
y = incompatible_condition$time,
paired = TRUE)
pwr.t.test(d = 1.27, n = 20) #Q4
pwr.t.test(d = 1.27, power = .8) #Q4
pwr.t.test(d = 1.27, power = .8, type = paired) #Q5
pwr.t.test(d = value_from_step_3, n = 20, type = "paired-samples") #Q4
pwr.t.test(d = 1.27, power = .8, type = "paired-samples") #Q5
pwr.t.test(d = 1.27, power = .8, type = "paired") #Q5
pwr.t.test(d = 1.27, power = .8, type = "paired") #Q4
pwr.t.test(d = 1.27, n = 20, type = "paired") #Q4
pwr.t.test(d = 1.27, power = .8, type = "paired") #Q4
pwr.t.test(power = .8, n = 40, type = "paired") #Q5
quarto render
quarto render
install.packages("rmarkdown")
quarto render
install.packages("shiny")
install.packages("tidyverse")
install.packages("learnr")
install.packages("kableExtra")
install.packages("car")
install.packages("lsr")
install.packages("Hmisc")
install.packages("ggeffects")
install.packages("patchwork")
