tidy()
results
pull(results, estimate)
r <- pull(results, estimate)
p <- pull(results, p.value)
df <- pull(results, parameter)
r <- pull(results, round(estimate,2)
r <- pull(results, round(estimate,2))
r <- results %>%
pull(estimate) %>%
round(2)
p <- results %>%
pull(p.value) %>%
round(3)
results
df <- results %>%
pull(parameter)
r-squared <- squared(r)
r-squared <- r*r
rsquared <- r*r
rsquared <- (r*r)*100
data <- read_csv("alcoholUse_Impulsivity.csv")
data
ggplot(data, aes(x = hau, y = imp)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_bw() +
labs(x = "Hazardous Alcohol Use", y = "Impulsivity")
results <- cor.test(data$hau,
data$imp,
method = "pearson",
alternative = "two.sided") %>%
tidy()
results
r <- results %>%
pull(estimate) %>%
round(2)
df <- results %>%
pull(parameter)
pvalue <- results %>%
pull(p.value) %>%
round(3)
rsquared <- r*r
rsquaredPercent <- round(rsquared * 100, 0)
?broom
---
title: "122_wk12_labActivity2"
---
title: "122_wk12_labActivity2"
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(car)
library(lsr)
library(Hmisc)
library(tidyverse)
dat <- read_csv("VapingData.csv")
dat <- dat %>%
filter(IAT_BLOCK3_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 3
filter(IAT_BLOCK5_Acc < 1) %>%                            # 1) only keep participants with accuracy scores equal to or smaller than 1 from block 5
mutate(IAT_ACC = (IAT_BLOCK3_Acc + IAT_BLOCK5_Acc)/2) %>% # 2) calculate an average IAT accuracy score across blocks 3 and 5
filter(IAT_ACC > .8) %>%                                  # 2) only keep participants with an average score greater than .8.
mutate(IAT_RT = IAT_BLOCK5_RT - IAT_BLOCK3_RT)            # 3) compute the IAT_RT score
descriptives <- dat %>%
summarise(n = n(),
mean_IAT_ACC = mean(IAT_ACC),
mean_IAT_RT = mean(IAT_RT),
mean_VPQ = mean(VapingQuestionnaireScore, na.rm = TRUE))
descriptives
dat <- dat %>%
filter(!is.na(VapingQuestionnaireScore)) %>%
filter(!is.na(IAT_RT))
ggplot(dat, aes(x = VapingQuestionnaireScore)) +
geom_histogram(binwidth = 10) +
theme_bw()
qqPlot(x = dat$VapingQuestionnaireScore)
ggplot(dat, aes(x = IAT_RT)) +
geom_histogram(binwidth = 10) +
theme_bw()
qqPlot(x = dat$IAT_RT)
ggplot(dat, aes(x = IAT_RT, y = VapingQuestionnaireScore)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_bw() +
labs(x = "Implicit attitude", y = "Explicit attitude")
results <- cor.test(dat$VapingQuestionnaireScore,
dat$IAT_RT,
method = "pearson") %>%
tidy()
results
correlation <- results %>%
pull(estimate) %>%
round(2)
df <- results %>%
pull(parameter) %>%
round(0)
pvalue <- results %>%
pull(p.value) %>%
round(3)
dat_matrix <- dat %>%
select(Age, IAT_RT, VapingQuestionnaireScore) %>%
as.data.frame() # Make sure tell R that dat is a data frame
pairs(dat_matrix)
intercor_results <- correlate(x = dat_matrix, # our data
test = TRUE, # compute p-values
corr.method = "spearman", # run a spearman test
p.adjust.method = "bonferroni") # use the bonferroni correction
intercor_results
?qqPlot
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(car)
library(tidyverse)
stars <- read_csv("stars2.csv")
engage <- read_csv("psess.csv")
head(stars) # Look at the data frames
head(engage)
stars_means <- stars %>%
group_by(ID) %>%
summarise(mean_anxiety = mean(Score, na.rm = TRUE))
stars_means
joined <- inner_join(stars_means, engage, "ID")
descriptives <- joined %>%
summarise(mean_anx = mean(mean_anxiety, na.rm = TRUE),
sd_anx = sd(mean_anxiety, na.rm = TRUE),
mean_weeks = mean(n_weeks, na.rm = TRUE),
sd_weeks = sd(n_weeks, na.rm = TRUE))
descriptives
length(joined$mean_anxiety)
length(joined$n_weeks)
ggplot(joined, aes(x = mean_anxiety, y = n_weeks)) +
geom_point() +
geom_smooth(method = "lm") +
labs(x = "Anxiety", y = "Engagement") +
theme_bw()
summarise(sd = sd(mean_anxiety), stars_means)
summarise(sd = sd(mean_anxiety), joined)
?mean
?qplot
libary(car)
library(car)
?qPlot
??qPlot
install.packages("modeest")
modeest::mfv(c(1,2,3,4,5,5,5))
modeest::mfv(c(1,2,3,4,4,4,5,5,5))
install.packages("modeest")
week_1_lecture_data <- c(7,8,8,7,3,1,6,9,3,8)
library(modeest)
mlv(week_1_lecture_data)
mfv(week_1_lecture_data)
sessionInfo()
setwd("C:/Repos/Research/UNNL_series/UNNL01")
round(6.3,0)
my_vals <- c(3.4,6.5)
my_vals_round <- round(my_vals, 0)
my_vals_round
library(pwrss)
pwrss.f.rmanova(n = 80, power = .8, type = "interaction")
pwrss.f.rmanova(eta2 = .15, n = 80, power = NULL, type = "interaction")
pwrss.f.rmanova(eta2 = .075, n = 80, power = NULL, type = "interaction")
pwrss.f.rmanova(eta2 = .075, n = NULL, power = .9, type = "interaction")
pwrss.f.rmanova(eta2 = 0.075,  n.levels = 2, n.rm = 1,
type = "between",
alpha = 0.05, power = 0.80)
pwrss.f.rmanova(eta2 = NULL,  n.levels = 2, n.rm = 1,
type = "between", n = 80,
alpha = 0.05, power = 0.80)
pwrss.f.rmanova(eta2 = 0.09,  n.levels = 2, n.rm = 1,
type = "between",
alpha = 0.05, power = 0.80)
pwrss.f.rmanova(eta2 = 0.088,  n.levels = 2, n.rm = 1,
type = "between",
alpha = 0.05, power = 0.80)
pwrss.f.rmanova(eta2 = 0.092,  n.levels = 2, n.rm = 1,
type = "between",
alpha = 0.05, power = 0.80)
pwrss.f.rmanova(eta2 = 0.15,  n.levels = 2, n.rm = 1,
type = "between",
alpha = 0.05, power = 0.80)
library(tidyverse)
d <- read_csv("PSYC121/data/Week_6/PSYC121_survey_values_2025.csv")
d
View(d)
d <- read_csv("PSYC121/data/Week_6/PSYC121_survey_data_2025.csv")
d_raw <- read_csv("data/Week_6/PSYC121_survey_data_2025.csv")
setwd("C:/Repos/Teaching/year1/PSYC121")
d_raw <- read_csv("data/Week_6/PSYC121_survey_data_2025.csv")
# get the relevant risky decision columns and wrangle
d <-
d_raw %>%
select("gain" = Q16, "loss" = Q17) %>%
dplyr::slice(3:n()) %>%
mutate(across(gain:loss, ~ (case_when(.x == "1" ~ "safe", .x == "2" ~ "risky")))) %>%
drop_na()
View(d)
View(d_raw)
d_raw <- read_csv("data/Week_6/PSYC121_survey_values_2025.csv")
# get the relevant risky decision columns and wrangle
d <-
d_raw %>%
select("gain" = Q16, "loss" = Q17) %>%
dplyr::slice(3:n()) %>%
mutate(across(gain:loss, ~ (case_when(.x == "1" ~ "safe", .x == "2" ~ "risky")))) %>%
drop_na()
View(d)
write_csv(d, file = "data/Week_6/risky_decisions.csv")
risk_dec <- read_csv("data/Week_6/risky_decisions.csv")
count(risk_dec,gain)
binom.test(58,66)
count(risk_dec,loss)
binom.test(32,66)
setwd("C:/Repos/year1/PSYC121")
setwd("C:/Repos/year1")
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
setwd("C:/Repos/Teaching/year1/PSYC121")
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
library(tidyverse)
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
d <-
d_raw %>%
select("sibling_order" = Q6,
"home_location" = Q7,
"home_location_in_UK" = Q8,
"attention_check" = Q54,
"salary_estimate" = Q13,
"human_CC" = Q52) %>%
dplyr::slice(3:n()) %>%
mutate(sibling_order = case_when(str_detect(sibling_order, "oldest") ~ "oldest",
str_detect(sibling_order, "middle") ~ "middle",
str_detect(sibling_order, "youngest") ~ "youngest",
str_detect(sibling_order, "only") ~ "only"),
home_location_in_UK = case_when(str_detect(home_location_in_UK, "North West") ~ "NW",
str_detect(home_location_in_UK, "North East") ~ "NE",
str_detect(home_location_in_UK, "South West") ~ "SW",
str_detect(home_location_in_UK, "South East") ~ "SE",
str_detect(home_location_in_UK, "Midlands") ~ "Midlands",
str_detect(home_location_in_UK, "Wales") ~ "Wales"),
attention_check = case_when(str_detect(attention_check, "strongly agree") ~ "pass",
.default = "fail")) %>%
mutate(salary_estimate = as.numeric(salary_estimate),
human_CC = as.numeric(human_CC)) %>%
drop_na(home_location_in_UK)  %>%
filter(home_location_in_UK != "Wales") %>%
select(-home_location) %>%
write_csv("data/Week_7/salary_data_wk7_2025.csv")
#| eval: false
#| include: false
d_f <-
d %>%
filter(salary_estimate > 10000)
d_f <-
d_f %>%
filter(salary_estimate < 100000)
d_f %>%
filter(home_location_in_UK == "NE")
d_f %>%
filter(home_location_in_UK == "SE" & sibling_order == "oldest")
d_f %>%
filter(attention_check == "fail")
d_raw <- read_csv("data/Week_6/PSYC121_survey_data_2025.csv")
d_raw <- read_csv("data/Week_6/PSYC121_survey_data_2025.csv")
d <-
d_raw %>%
select("sibling_order" = Q6,
"home_location" = Q7,
"home_location_in_UK" = Q8,
"attention_check" = Q54,
"salary_estimate" = Q13,
"human_CC" = Q52) %>%
dplyr::slice(3:n()) %>%
mutate(sibling_order = case_when(str_detect(sibling_order, "oldest") ~ "oldest",
str_detect(sibling_order, "middle") ~ "middle",
str_detect(sibling_order, "youngest") ~ "youngest",
str_detect(sibling_order, "only") ~ "only"),
home_location_in_UK = case_when(str_detect(home_location_in_UK, "North West") ~ "NW",
str_detect(home_location_in_UK, "North East") ~ "NE",
str_detect(home_location_in_UK, "South West") ~ "SW",
str_detect(home_location_in_UK, "South East") ~ "SE",
str_detect(home_location_in_UK, "Midlands") ~ "Midlands",
str_detect(home_location_in_UK, "Wales") ~ "Wales"),
attention_check = case_when(str_detect(attention_check, "strongly agree") ~ "pass",
.default = "fail")) %>%
mutate(salary_estimate = as.numeric(salary_estimate),
human_CC = as.numeric(human_CC)) %>%
drop_na(home_location_in_UK)  %>%
filter(home_location_in_UK != "Wales") %>%
select(-home_location) %>%
write_csv("data/Week_7/salary_data_wk7_2025.csv")
#| eval: false
#| include: false
d_f <-
d %>%
filter(salary_estimate > 10000)
d_f <-
d_f %>%
filter(salary_estimate < 100000)
d_f %>%
filter(home_location_in_UK == "NE")
d_f %>%
filter(home_location_in_UK == "SE" & sibling_order == "oldest")
d_f %>%
filter(home_location_in_UK == "NE")
d_f %>%
filter(home_location_in_UK == "SE")
d_f %>%
filter(home_location_in_UK == "SE" & sibling_order == "oldest")
d_f %>%
filter(home_location_in_UK == "NW" & sibling_order == "oldest")
d_f %>%
filter(attention_check == "fail")
d_f %>%
filter(attention_check == "pass" & sibling_order == "youngest")
d_f %>%
filter(home_location_in_UK != "NW")
d_f %>%
filter(home_location_in_UK == "SE" | home_location_in_UK == "SW")
setwd("C:/Repos/Teaching/year1")
library(tidyverse)
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
setwd("C:/Repos/Teaching/year1/PSYC121")
d_raw <- read_csv("data/Week_6/PSYC121_survey_data.csv")
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25)
# set up the data for Task 3
d <-
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na() %>%
mutate(pID = 1:n()) %>%
pivot_longer(cols = contains("stroop"),
names_to = "condition",
names_prefix = "stroop_",
values_to = "time") %>%
mutate(time = round(time,2)) %>%
group_by(pID) %>%
mutate(avg_time = round(mean(time),2))
View(d)
write_csv(d, file = "data/Week_8/stroop_wk8_2025.csv")
#| eval: false
#| include: false
d %>%
ggplot() +
geom_density(aes(x = time, fill = condition), alpha = .8) + # you need to EDIT this line
theme_dark()
d_raw <- read_csv("data/Week_6/PSYC121_survey_data_2025.csv")
# set up the data for Task 3
d <-
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na() %>%
mutate(pID = 1:n()) %>%
pivot_longer(cols = contains("stroop"),
names_to = "condition",
names_prefix = "stroop_",
values_to = "time") %>%
mutate(time = round(time,2)) %>%
group_by(pID) %>%
mutate(avg_time = round(mean(time),2))
d_raw %>%
select("stroop_control" = Q23,
"stroop_compatible" = Q24,
"stroop_incompatible" = Q25) %>%
slice(3:n()) %>%
mutate(across(contains("stroop"), as.numeric)) %>%
drop_na() %>%
mutate(pID = 1:n()) %>%
pivot_longer(cols = contains("stroop"),
names_to = "condition",
names_prefix = "stroop_",
values_to = "time") %>%
mutate(time = round(time,2)) %>%
group_by(pID) %>%
mutate(avg_time = round(mean(time),2))
View(d)
write_csv(d, file = "data/Week_8/stroop_wk8_2025.csv")
#| eval: false
#| include: false
d %>%
ggplot() +
geom_density(aes(x = time, fill = condition), alpha = .8) + # you need to EDIT this line
theme_dark()
write_csv(d, file = "data/Week_8/stroop_wk8_2025.csv")
#| eval: false
# distribution of average times
your_data_object %>%
ggplot() +
geom_histogram(aes(x = missing_column_name_A), fill = "pink") + # you need to EDIT this line
theme_classic()
#| eval: false
#| include: false
# distribution of times by condition
d %>%
ggplot() +
geom_histogram(aes(x = avg_time), fill = "pink", colour = "purple") +
theme_classic()
# filter out the high values
d_f <- # create a new object (or overwrite)
d %>% # original data object
filter(avg_time < 10)
189/3
# draw a new
d_f %>%
ggplot() +
geom_histogram(aes(x = avg_time),
fill = "yellow",
colour = "black",
bins = 20) +
theme_minimal()
d_f %>%
group_by(condition) %>% # you need to EDIT this for Q1
summarise(stroop_mean = mean(time)) # you need to EDIT this for Q1
# use filter to select two levels of the IV - Q3-5
stroop_compatible <-
d_f %>% # Edit this for the name of YOUR data object
filter(condition == "compatible")
# use filter to select two levels of the IV - Q3-5
stroop_control <-
d_f %>% # Edit this for the name of YOUR data object
filter(condition == "control")
# use filter to select two levels of the IV - Q3-5
stroop_incompatible <-
d_f %>% # Edit this for the name of YOUR data object
filter(condition == "incompatible")
# run the t-test comparing the means of these two levels
t.test(x = stroop_compatible$time, y = stroop_control$time, paired = TRUE)
t.test(x = stroop_incompatible$time, y = stroop_control$time, paired = TRUE)
t.test(x = stroop_compatible$time, y = stroop_incompatible$time, paired = TRUE)
stroop_summary <-
d_f %>%
group_by(condition) %>% # you need to EDIT this for Q2
summarise(stroop_mean = mean(time),
stroop_SE = sd(time)/sqrt(n())) # you need to EDIT this for Q1
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_point(size = 5) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_col(size = 5) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_col(linewidth = 5) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_col(linewidth = 5) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_col(linewidth = 20) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_col(linewidth = 0) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
# let's first plot the means
stroop_summary %>%
ggplot(aes(x = condition, y = stroop_mean)) + # map variables to x and y for Q5
geom_point(size = 5) +
geom_errorbar(aes(ymin = stroop_mean - stroop_SE, # edit this for Q5
ymax = stroop_mean + stroop_SE), # edit this for Q5
width = .2)
#| eval: false
#| include: false
d_f %>%
group_by(condition) %>% # you need to EDIT this for Q1
summarise(stroop_mean = mean(time)) # you need to EDIT this for Q1
#| eval: false
stroop_summary <-
name_of_data_object %>%
group_by(name_of_IV_column) %>% # you need to EDIT this for Q2
summarise(stroop_mean = mean(name_of_DV_column),
stroop_SE = sd(name_of_DV_column)/sqrt(n())) # you need to EDIT this for Q1
#| eval: false
#| include: false
stroop_summary <-
d_f %>%
group_by(condition) %>% # you need to EDIT this for Q2
summarise(stroop_mean = mean(time),
stroop_SE = sd(time)/sqrt(n())) # you need to EDIT this for Q1
stroop_summary
setwd("C:/Users/beesleyt/OneDrive - Lancaster University/Desktop PC/Teaching - Admin/PSYC121/Week 8")
setwd("C:/Repos/Teaching/year1/PSYC121")
