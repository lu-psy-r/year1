[
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "",
    "text": "In Week 18, we aim to further develop skills in working with the linear model.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like the linear model.\nWhen we do these analyses, we need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model.\n\nWe usually need to decide:\n\nis the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nand is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\nfocusing on how we edit ggplot() code to produce professional looking plots.\n\n\n\nI will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#naming-things",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#naming-things",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "",
    "text": "In this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-1-set-up",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-1-set-up",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"ggeffects\")\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-2-load-the-data",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")\n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look.\n\nhead(study.two.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studytwo.1        0.411      6.07 studyt…    26      27     6      50        9\n2 studytwo.10       0.607      8.5  studyt…    38      24     9      58       15\n3 studytwo.100      0.875      8.93 studyt…    66      40    13      60       20\n4 studytwo.101      0.964      8.5  studyt…    21      31    11      59       14\n5 studytwo.102      0.714      7.07 studyt…    74      35     7      52       18\n6 studytwo.103      0.768      5.07 studyt…    18      40    11      54       15\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\n\nEven though you have done this before, you will want to do it again, here, and pay particular attention to:\n\nsummary information about the numeric variables;\nsummary information about variables of class: character."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-3-use-a-linear-model-to-to-answer-the-research-questions-one-predictor",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-3-use-a-linear-model-to-to-answer-the-research-questions-one-predictor",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 3: Use a linear model to to answer the research questions – one predictor",
    "text": "Step 3: Use a linear model to to answer the research questions – one predictor\n\nRevise: practice to strengthen skills\n\n\nRevise: We start by revising how to use lm() with one predictor\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe can address this question by examining whether someone’s rated evaluation of their own understanding matches their performance on a test of that understanding, and by investigating what variables predict variation in mean self-rated accuracy.\n\nNote that ratings of accuracy are ordinal data but that, here, we may choose to examine the average of participants’ ratings of their own understanding of health information to keep our analysis fairly simple.\nFor these data, participants were asked to respond to questions about health information to get mean.acc scores and then were asked to rate their own understanding of the same information.\n\nIf you can evaluate your own understanding then ratings of understanding should be associated with performance on tests of understanding\n\n\nTask 5 – Estimate the relation between outcome mean self-rated accuracy (mean.self) and tested accuracy of understanding (mean.acc)\n\n\nhint: Task 5\nFor these data, participants were asked to respond to questions about health information to get mean.acc scores and were asked to rate their own understanding of the same information.\n\n\nhint: Task 5\nWe can use lm() to estimate whether the ratings of accuracy actually predict the outcome tested accuracy levels.\n\nmodel &lt;- lm(mean.self ~ mean.acc, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\nIn R analysis code, we write method(outcome ~ predictor) so:\nlm(mean.self ~ mean.acc, data = study.two.gen)\n\ngets us an analysis of whether or how mean.self predicts variation in outcome mean.acc.\n\nIf you look at the model summary you can answer the following questions.\n\nQuestions: Task 5\n\nQ.1. What is the estimate for the coefficient of the effect of the predictor mean.acc on the outcome mean.self in this model?\nA.1. 5.5670\nQ.2. Is the effect significant?\nA.2. It is significant, p &lt; .05\nQ.3. What are the values for t and p for the significance test for the coefficient?\nA.3. t = 8.499, p = 9.36e-15\nQ.4. What do you conclude is the answer to the research question, given the linear model results?\nA.4. The model slope estimate suggests that higher levels of tested understanding can predict higher levels of rated understanding so, yes: it does appear that people can evaluate their own understanding.\nQ.5. What is the F-statistic for the regression? Report F, DF and the p-value.\nA.5. F-statistic: 72.24 on 1 and 170 DF, p-value: 9.356e-15\nQ.6. Is the regression significant?\nA.6. Yes: the regression is significant.\nQ.7. What is the Adjusted R-squared?\nA.7. Adjusted R-squared: 0.2941\nQ.8. Explain in words what this R-squared value indicates?\nA.8. The R-squared suggests that about 30% of outcome variance can be explained by the model"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-4-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-4-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 4: Use a linear model to to answer the research questions – multiple predictors",
    "text": "Step 4: Use a linear model to to answer the research questions – multiple predictors\n\nIntroduce: make some new moves\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe have already looked at this question by asking whether ratings of understanding predict performance on tests of understanding.\nBut there is a problem with that analysis – it leaves open the question:\n\nWhat actually predicts ratings of understanding?\n\nWe can look at this follow-up question, next.\n\n\nTask 6 – Examine the relation between outcome mean self-rated accuracy (mean.self) and multiple predictors\nHere, the predictors will include:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nage in years (AGE);\nreading strategy (FACTOR3);\nas well as average accuracy of the tested understanding of health information (mean.acc).\n\n\nhint: Task 6 – We use lm(), as before, but now specify each variable listed here by variable name\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc, \n            data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc, \n    data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.72027 -0.49118 -0.00177  0.55561  2.00134 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.561110   0.700632   0.801   0.4244    \nHLVA         0.041272   0.034833   1.185   0.2378    \nSHIPLEY     -0.046125   0.018701  -2.466   0.0147 *  \nFACTOR3      0.063689   0.010747   5.926 1.74e-08 ***\nAGE          0.025570   0.005472   4.673 6.12e-06 ***\nmean.acc     4.763278   0.708166   6.726 2.69e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8805 on 166 degrees of freedom\nMultiple R-squared:  0.5014,    Adjusted R-squared:  0.4864 \nF-statistic: 33.39 on 5 and 166 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nQuestions: Task 6\nIf you look at the model summary you can answer the following questions.\n\nQ.9. What predictors are significant in this model?\nA.9. Vocabulary (SHIPLEY), reading strategy (FACTOR3), AGE, and performance on tests of accuracy of understanding (mean.acc) all appear to significantly predict variation in mean ratings of understanding (mean.self).\nQ.10. What is the estimate for the coefficient of the effect of the predictor mean.acc in this model?\nA.10. 4.763278\nQ.11. Is the effect significant?\nA.11. It is significant, p &lt; .05\nQ.12. What are the values for t and p for the significance test for the coefficient?\nA.12. t = 6.726, p = 2.69e-10\nQ.13. What do you conclude is the answer to the follow-up question, what actually predicts ratings of understanding?\nA.13. Ratings of understanding appear to be predicted by performance on tests of accuracy of understanding, together with variation in age, vocabulary knowledge, health literacy and reading strategy"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-5-understanding-linear-model-predictions-by-comparing-one-outcome-predictor-relation",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-5-understanding-linear-model-predictions-by-comparing-one-outcome-predictor-relation",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 5: Understanding linear model predictions by comparing one outcome-predictor relation",
    "text": "Step 5: Understanding linear model predictions by comparing one outcome-predictor relation\nNext, we focus in on whether mean.self predicts mean.acc or, in reverse, whether mean.acc predicts mean.self?\n\nNote that a comparison between these models teaches us something important about what it is that linear models predict.\nQ.14. Why do you think it appears that the slope coefficient estimate is different if you compare :\n\n\nThe model mean.acc ~ mean.self versus\nThe model mean.self ~ mean.acc?\n\n\nhint: Q.14. You want to fit two simple models here, using the verbal description in the Q.14 wording.\n\n1. The model mean.acc ~ mean.self\n\nmodel.1 &lt;- lm(mean.acc ~ mean.self, data = study.two.gen)\nsummary(model.1)\n\n\nCall:\nlm(formula = mean.acc ~ mean.self, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.293692 -0.069200  0.005422  0.080041  0.215240 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.379182   0.045415   8.349 2.31e-14 ***\nmean.self   0.053566   0.006303   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1013 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\n2. The model mean.self ~ mean.acc\n\nmodel.2 &lt;- lm(mean.self ~ mean.acc, \n              data = study.two.gen)\nsummary(model.2)\n\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\n\nhint: Q.14. You may benefit here by reflecting on the lm-intro lecture and practical materials, especially where they concern predictions.\nA.14. Linear models are prediction models. We use them to predict variation in outcomes given some set of predictor variables. Predictions will necessarily be scaled in the same way as the outcome variable.\n\nSo, to expand on that explanation a bit more, to help understanding – the answer is:\n\nIf we have the model, mean.acc ~ mean.self then this means that the outcome is mean.acc.\n\n\nSo if we are predicting change in outcome mean.acc, which is scaled 0-1, then we are looking at coefficients that will lie somewhere on the same scale (also 0-1).\nHere: the model estimate suggests that each unit change in values of the variable mean.self predicts an increase of 0.053566 in mean.acc.\n\n\nWhereas if we have the model, mean.self ~ mean.acc then this means that the outcome is mean.self.\n\n\nSo if we are predicting change in outcome mean.self, which is scaled 1-9 , then we are looking at coefficients that will lie somewhere on the same scale (also 1-9).\nHere: the model estimate suggests that unit change in mean.acc predicts increase of 5.5670 in mean.self.\n\nNote that:\n\nWhere we reference model estimates, here, we are looking at the values in the Estimate column of the lm() model summary.\nThese estimates give us the expected or predicted change in the outcome, given change in the predictor variable named on that row.\n\nRemember that:\n\nmean.acc is scaled from 0 to 1 because it represents the average accuracy of the responses made by study participants to questions about health texts. This average has to have a minimum of 0 (no responses correct) and a maximum of 1 (all responses correct). The average is calculated by adding up all the correct answers and dividing by the number of questions answered by each participant.\nmean.self is scaled from 1 to 9 bcause it represents the average self-rated accuracy of understanding. Participants are asked to rate on a scale form 1 (not all) to 9 (very well) how well they think they understand a health information text. The average is calculated by adding up all the ratings and dividing by the number of texts responded to by each participant.\n\nThe important lesson, here, is that estimates of predictor effects are scaled in terms of predicted change in the outcome, so whatever scale the outcome measurement is in determines how big or small the predictor coefficient estimates can be.\nWe can visualize this to see what it means in practice.\n\nQ.15. Can you plot the predictions from each model?\nA.15. Here is the code to plot the predictions from both models.\n\nFirst fit the models.\n\nRemember to give each model object distinct names.\n\n\nmodel.1 &lt;- lm(mean.acc ~ mean.self, data = study.two.gen)\nsummary(model.1)\n\n\nCall:\nlm(formula = mean.acc ~ mean.self, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.293692 -0.069200  0.005422  0.080041  0.215240 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.379182   0.045415   8.349 2.31e-14 ***\nmean.self   0.053566   0.006303   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1013 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\nmodel.2 &lt;- lm(mean.self ~ mean.acc, \n            data = study.two.gen)\nsummary(model.2)\n\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\nSecond get the predictions:\n\ndat.1 &lt;- ggpredict(model.1, \"mean.self\")\ndat.2 &lt;- ggpredict(model.2, \"mean.acc\")\n\nThird make the prediction plots:\n\nPredictions from the model mean.acc ~ mean.self\n\n\nplot(dat.1)\n\n\n\n\n\n\n\n\n\nPredictions from the model mean.self ~ mean.acc\n\n\nplot(dat.2)\n\n\n\n\n\n\n\n\n\nQ.16. Look at the two plots: what do you see?\nhint: Q.16. Look at changes in height of the prediction line, given changes in x-axis position of the line\nA.16. A side-by-side comparison shows that:\n\n\nFor model mean.acc ~ mean.self increases in mean.self from about 4 to 9 are associated with a change in mean.acc from about .6 to about .85;\nFor model mean.self ~ mean.acc increases in mean.acc from about 0.4 to 1.0 are associated with a change in mean.self from about 5 to about 9."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-6-estimate-the-effects-of-factors-as-well-as-numeric-variables",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-6-estimate-the-effects-of-factors-as-well-as-numeric-variables",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 6: Estimate the effects of factors as well as numeric variables",
    "text": "Step 6: Estimate the effects of factors as well as numeric variables\n\nConsolidation: build your skills\nWe have not yet included any categorical or nominal variables as predictors but we can, and should: lm() can cope with any kind of variable as a predictor.\nThere are different ways to do this, here we ask you to use the R default method.\n\n\nTask 7 – Fit a linear model to examine what variables predict outcome mean self-rated accuracy of mean.self\n\nhint: Task 7 – Include as predictors both numeric variables and categorical variables\nHere, our model includes predictors that are both numeric like:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nAGE;\nreading strategy (FACTOR3);\naccuracy mean.acc\n\nAs well as a categorical or nominal variable like\n\nEDUCATION.\n\nNote: EDUCATION is different because participants are classified by what education category (higher education, further education, secondary school) they report themselves as having received.\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc +\n                        EDUCATION, \n            data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + \n    EDUCATION, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70987 -0.50037  0.01988  0.55965  2.01412 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.487753   0.702049   0.695   0.4882    \nHLVA                0.047100   0.034915   1.349   0.1792    \nSHIPLEY            -0.044132   0.018719  -2.358   0.0196 *  \nFACTOR3             0.061918   0.010771   5.749 4.29e-08 ***\nAGE                 0.023997   0.005595   4.289 3.06e-05 ***\nmean.acc            4.912833   0.712381   6.896 1.10e-10 ***\nEDUCATIONHigher    -0.082217   0.146390  -0.562   0.5751    \nEDUCATIONSecondary  0.346161   0.266030   1.301   0.1950    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8783 on 164 degrees of freedom\nMultiple R-squared:  0.5099,    Adjusted R-squared:  0.489 \nF-statistic: 24.38 on 7 and 164 DF,  p-value: &lt; 2.2e-16\n\n\n\nQ.17. Can you report the overall model and model fit statistics?\nA.17.\n\n\nWe fitted a linear model with mean self-rated accuracy as the outcome and with the predictors: health literacy (HLVA), vocabulary (SHIPLEY), reading strategy (FACTOR3), AGE, as well as mean accuracy (mean.acc) and education level (EDUCATION). The model is significant overall, with F(7, 164) = 24.38, p &lt; .001, and explains 49% of variance (adjusted R2 = 0.489).\n\n\nQ.18. Can you plot the predicted effect of EDUCATION given your model?\nhint: Q.18. We first fit the model, including EDUCATION.\n\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + EDUCATION, \n            data = study.two.gen)\n\n\nhint: Q.18. We then use the ggpredict() function to get the prediction for the effect of EDUCATION differences on outcome mean.self.\n\n\ndat &lt;- ggpredict(model, \"EDUCATION\")\n\nSome of the focal terms are of type `character`. This may lead to\n  unexpected results. It is recommended to convert these variables to\n  factors before fitting the model.\n  The following variables are of type character: `EDUCATION`\n\nplot(dat)\n\n\n\n\n\n\n\n\n\nQ.19. The plot should give you dot-and-whisker representations of the estimated mean.self outcome for different levels of EDUCATION. What is the difference in the estimated mean.self between the groups?\nhint: Q.19. The effect or prediction plot will show you dot-and-whisker representations of predicted outcome mean.self. In these plots, the dots represent the estimated mean.self while the lines (whiskers) represent confidence intervals.\nA.19. The difference in the estimated mean.self between these groups is small: the groups vary between ratings of about 7, 7.10 and 7.5.\nQ.20. Compare the difference in the estimated mean.self between these groups, given the plot, with the coefficient estimate from the model summary: what do you see?\nA.20. The effect of EDUCATION is presented in the summary as two estimates:\nEDUCATIONHigher    -0.082217\nEDUCATIONSecondary  0.346161\n\nThe reference level for EDUCATION is Further.\nThe estimates therefore show that people with Higher education have mean.self scores about -.08 lower than mean.self for people with Further education.\nPeople with Secondary education have mean.self scores about .35 higher than mean.self for people with Further education.\nWe are learning some new things here so it is useful to explain them:\n\nCategorical variables or factors and reference levels.\n\n\nIf you have a categorical variable like EDUCATION then when you use it in an analysis, R will look at the different categories (called levels) e.g., here,higher education, further education, secondary school` and it will pick one level to be the reference or baseline level.\nThe reference is the the level against which other levels are compared.\nHere, the reference level is Further (education) simply because, unless you tell R otherwise, it picks the level with a category name that begins earlier in the alphabet as the reference level.\n\n\nDot and whisker plots show estimates with confidence intervals.\n\n\nDot and whisker plots are a nice way to present a concise visual summary about the estimates we get from prediction models.\nHere, the plots show the coefficient estimates from our model (the dots) plus confidence intervals (the lines or “whiskers”).\n\n\nConfidence intervals are often misunderstood but they are helpful.\n\n\nEssentially, a confidence interval tells us about we might expect to see using our analysis procedure (Hoekstra et al., 2014).\n\n\nIf we were to repeat the experiment over and over, then 95 % of the time the confidence intervals contain the true mean.\n\n\nAnd you can read more about this here\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E. J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21, 1157-1164."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "",
    "text": "In Week 16, we aim to develop skills in visualizing and testing the associations between variables in psychological data.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like correlation and linear models.\nWe will consolidate and extend learning on data visualization:\n\nUse histograms to examine the distributions of variables;\nUse scatterplots to examine the relationships we may observe or predict.\n\n\n\nI will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#naming-things",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#naming-things",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "",
    "text": "In this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-1-set-up",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-1-set-up",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-2-load-the-data",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask Task 3 – Read in the data file we will be using\nThe data file is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")\n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a clear name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\n\n\nQ.1. What is the median of AGE?\nA.1. 32.50\nQ.2. What class is the variable ETHNICITY?\nA.2. character\nQ.3. Does the summary indicate if any variable has missing values (NAs)?\nQ.3. No\n\n\n\nTask 5 – Change the class or type of the variable ETHNICITY to factor\nYou can use the as.factor() function you have used before:\n\nstudy.two.gen$ETHNICITY &lt;- as.factor(study.two.gen$ETHNICITY)\n\n\nQ.4. After you have done this, what information does summary() give you about the variable ETHNICITY?\n\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION         ETHNICITY  \n Min.   : 6.00   Length:172         Length:172         Asian: 15  \n 1st Qu.:12.00   Class :character   Class :character   Black:  5  \n Median :14.00   Mode  :character   Mode  :character   Mixed:  7  \n Mean   :13.88                                         White:145  \n 3rd Qu.:16.00                                                    \n Max.   :20.00                                                    \n\n\n\nA.4. We can see that ETHNICITY lists observations following UK Office National Statistics ethnicity grouping:\nAsian: 15\nBlack: 5\nMixed: 7\nWhite: 145"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 3: Use histograms to examine the distributions of variables",
    "text": "Step 3: Use histograms to examine the distributions of variables\n\nTask 6 – Draw histograms to examine the distributions of variables\n\nHint: Task 6\nUse ggplot() with geom_histogram().\nThe first time we do this, we take things step-by-step.\nHere’s an example: run the line of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.two.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\n\n\nQuestions: Task 6\n\nQ.5. Did you get a message in the Console window in R-Studio: what does it say?\nA.5. The message says:\nstat_bin() using bins = 30. Pick better value with binwidth.\nQ.6. Draw two different histograms to examine the distributions of two different variables: SHIPLEY and HLVA\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nQ.7. Now re-do both plots: can you change the binwidth in geom_histogram() to make the bars wider?\n\nIf you are going to change binwidth the number you use needs to be a number larger than\nthe minimum and smaller than the maximum for the variable.\nRemember, min and max values are given for each numeric variable in summary().\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\nWe adjust binwidth typically to improve the appearance of the plot.\nThis is a bit subjective so try different numbers and see how you feel about the changes in appearance.\nWe want histograms that show us enough detail about the frequency of occurrence of groupings (bins) of values for each variable.\nBut we do not want histograms that show us so much detail it is difficult to see the pattern for the distribution.\n\nQ.8 – How would you describe the distributions – in a sentence – of the distributions of the SHIPLEY and HLVA variable values for our sample?\nA.8. The SHIPLEY values lie between about 25 and 40, and are skewed towards high scores.\nA.8. The HLVA values lie between 4 and about 14, and peak in the middle (near 7)."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-4-edit-your-plots-to-make-them-look-good",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-4-edit-your-plots-to-make-them-look-good",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 4: Edit your plots to make them look good",
    "text": "Step 4: Edit your plots to make them look good\n\nTask 7 – Edit the appearance of a histogram plot for one numeric variable\nNote that ggplot() code does not all have to be on the same line.\nYou can create a new plot for each edit so you can see what difference your edits make.\n\nQ.9. Edit the appearance of the bars using binwidth\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\nQ.10. Edit the colour of the background using theme_bw()\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nQ.11. Edit the appearance of the labels using labs()\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"count\")\n\n\n\n\n\n\n\n\nNotice how, if you are doing edits in steps, one line at a time, each line in your code except the last one ends in a +.\nWhat we are doing is telling R we want this + this + this … Each line then adds an extra step.\nYou can break this code by not adding a + at the end of each bit (except the last line).\nNotice that how to break the code, and how to figure out how to fix the break, are discussed in the how-to .R"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-5-now-draw-scatterplots-to-examine-associations-between-variables",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-5-now-draw-scatterplots-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 5: Now draw scatterplots to examine associations between variables",
    "text": "Step 5: Now draw scatterplots to examine associations between variables\n\nTask 8 – Create a scatterplot to examine the association between some variables\nWe are working with geom_point() and you need x and y aesthetic mappings\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThis plot shows the possible association between x-axis variable HLVA and y-axis variable mean.acc.\nThe plot code moves through the following steps:\n\nggplot(...) make a plot\nggplot(data = study.two.gen, ...) with the study.two.gen dataset\nggplot(...aes(x = HLVA, y = mean.acc)) using two aesthetic mappings:\n\n\nx = HLVAmapHLVA` values to x-axis (horizontal, left to right) positions\ny = mean.accmapmeann.acc` values to y-axis (vertical, bottom to top) positions\n\n\ngeom_point() show the mappings as points\n\n\n\nTask 9 – Now do scatterplots with every numeric predictor variable in the study.two.gen dataset\nYou always want to use as the y-axis variable the outcome mean.acc so:\n\ny = mean.acc\n\nThen you can use each numeric predictor variable as the x-axis variable so:\n\nx = mean.self\n\nRemember what we saw with summary(): not every variable consists of numbers\nIf the summary() does not show you a mean for a variable, then R does not think that variable is numeric\nIt can be hard to decide what an association looks like:\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point()  \n\n\n\n\n\n\n\n\n\nQ.12. What is the shape (direction) of the association between mean.self and mean.acc?\nA.12. Increase in mean.self is associated with increase in mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nQ.13. What is the shape (direction) of the association between AGE and mean.acc?\nA.13. There is no clear association between AGE and mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()  \n\n\n\n\n\n\n\n\n\nQ.14. What is the shape (direction) of the association between SHIPLEY and mean.acc?\nA.14. Increase in SHIPLEY is associated with increase in mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nQ.15. – What is the shape (direction) of the association between HLVA and mean.acc?\nA.15. Increase in HLVA is associated with increase in mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = FACTOR3, y = mean.acc)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nQ.16. What is the shape (direction) of the association between FACTOR3 and mean.acc?\nA.16. Increase in FACTOR3 is associated with increase in mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = QRITOTAL, y = mean.acc)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nQ.17. What is the shape (direction) of the association between QRITOTAL and mean.acc?\nA.17. Increase in QRITOTAL is associated with increase in mean.acc"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-6-edit-the-scatterplots-to-make-them-look-good",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-6-edit-the-scatterplots-to-make-them-look-good",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 6: Edit the scatterplots to make them look good",
    "text": "Step 6: Edit the scatterplots to make them look good\n\nTask 10 – Edit the appearance of one plot step-by-step\n\nHint: Task 10 – We are going to edit:\n\nthe appearance of the points using alpha, size and colour;\nthe colour of the background using theme_bw();\nthe appearance of the labels using labs().\n\nJust like with geom_histogram() there is ggplot reference information for the geom you can use here – take a look:\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\nYou can find some example code and come back here if you are unsure what to do\n\n\nQuestions: Task 10\n\nQ.18. Change the appearance of the points using alpha, size and colour:\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\") \n\n\n\n\n\n\n\n\n\nQ.19. Edit the colour of the background using theme_bw()\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\")   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nQ.20. Edit the appearance of the labels using labs()\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\")   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\nQ.21. Can you find the ggplot reference page?\n\nDo a search with the keywords “ggplot reference geom_point”\n\nA.21. – It is here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_point.html"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#now-you-experiment",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#now-you-experiment",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Now you: experiment!",
    "text": "Now you: experiment!"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-7-use-correlation-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-7-use-correlation-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 7: Use correlation to to answer the research questions",
    "text": "Step 7: Use correlation to to answer the research questions\n\nTask 11 – Examine the correlation between mean accuracy (mean.acc) and some numeric predictor variables\nWe use cor.test()\n\nQ.22. What is r (given as cor in the output) for the correlation between HLVA and mean.acc?\n\n\ncor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$HLVA and study.two.gen$mean.acc\nt = 7.5288, df = 170, p-value = 2.866e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3787626 0.6044611\nsample estimates:\n      cor \n0.5000559 \n\n\n\nA.22. r = 0.5000559\nQ.23. Is the correlation significant?\nA.23. r is significant\nQ.24. What are the values for t and p for the significance test for the correlation?\nA.24. t = 7.5288, p = 2.866e-12\nQ.25. What do you conclude, given the correlation results? (Maybe draw a scatterplot to examine the shape of the association.)\nA.25. HLVA and mean.acc are positively correlated suggesting that as HLVA scores increase so also do mean.acc scores\nQ.26. What is r (given as cor in the output) for the correlation between mean.self and mean.acc?\n\n\ncor.test(study.two.gen$mean.self, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$mean.self and study.two.gen$mean.acc\nt = 8.4991, df = 170, p-value = 9.356e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4317217 0.6431596\nsample estimates:\n      cor \n0.5460792 \n\n\n\nA.26. r = 0.5460792\nQ.27. Is the correlation between AGE and mean.acc significant?\n\n\ncor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$AGE and study.two.gen$mean.acc\nt = 0.30121, df = 170, p-value = 0.7636\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1269774  0.1721354\nsample estimates:\n       cor \n0.02309589 \n\n\n\nA.27. r is not significant\nQ.28. What are the values for t and p for the significance test for the correlation between QRITOTAL and mean.acc?\n\n\ncor.test(study.two.gen$QRITOTAL, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$QRITOTAL and study.two.gen$mean.acc\nt = 6.4711, df = 170, p-value = 9.993e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3159538 0.5571417\nsample estimates:\n    cor \n0.44457 \n\n\n\nA.28. t = 6.4711, p = 9.993e-10\nQ.29. What do you conclude, given the correlation results, about the association between SHIPLEY and mean.acc?\n\n\ncor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$SHIPLEY and study.two.gen$mean.acc\nt = 6.8493, df = 170, p-value = 1.299e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3390103 0.5746961\nsample estimates:\n      cor \n0.4650537 \n\n\n\nA.29. SHIPLEY and mean.acc are positively correlated suggesting that as HLVA scores increase so also do mean.acc scores"
  },
  {
    "objectID": "PSYC122/data/week11/122_wk11_labActivities2_3.html#lab-activity-3---hazardous-alcohol-use-and-impulsivity",
    "href": "PSYC122/data/week11/122_wk11_labActivities2_3.html#lab-activity-3---hazardous-alcohol-use-and-impulsivity",
    "title": "122_wk11_labActivities2_3",
    "section": "Lab activity 3 - Hazardous alcohol use and impulsivity",
    "text": "Lab activity 3 - Hazardous alcohol use and impulsivity"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "",
    "text": "In Week 17, we aim to further develop skills in visualizing and testing the associations between variables in psychological data.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like the linear model.\nWhen we do these analyses, we need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model;\nwe usually need to decide, is the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nand is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\nfocusing on how we edit ggplot() code to produce professional looking plots.\n\n\n\nI will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#naming-things",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#naming-things",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "",
    "text": "In this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-1-set-up",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-1-set-up",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-2-load-the-data",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")\n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look.\n\nhead(study.two.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studytwo.1        0.411      6.07 studyt…    26      27     6      50        9\n2 studytwo.10       0.607      8.5  studyt…    38      24     9      58       15\n3 studytwo.100      0.875      8.93 studyt…    66      40    13      60       20\n4 studytwo.101      0.964      8.5  studyt…    21      31    11      59       14\n5 studytwo.102      0.714      7.07 studyt…    74      35     7      52       18\n6 studytwo.103      0.768      5.07 studyt…    18      40    11      54       15\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\n\nEven though you have done this before, you will want to do it again, here, and pay particular attention to what you see, for the numeric variables, in the information about minimum (Min.) and maximum (Max.) values."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 3: Use histograms to examine the distributions of variables",
    "text": "Step 3: Use histograms to examine the distributions of variables\n\nRevise: practice to strengthen skills\n\n\nTask 5 – Draw histograms to examine the distributions of variables\n\n\nhint: Task 5\nUse ggplot() with geom_histogram().\nWhen we create a plot, we take things step-by-step.\nHere’s an example you have seen before: run the lines of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.two.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\nNotice that the code works the same whether we have the different bits of code on the same line or in a series of lines.\n\n\nRevise: make sure you are confident about doing these things\n\n\nTask 6 – Practice editing the appearance of a histogram plot step-by-step\nStart by constructing a basic histogram.\n\nhint: Task 6 – Choose whichever numeric variable from the study.two.gen dataset you please\n\n\nhint: Task 6 – Use the line-by-line format to break the plot code into steps\nIt will make it easier to read, and it will make it easier to add edits e.g.\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe are going to revise editing:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using `labs().\n\nThen we are going to try some new moves:\n\nSetting the x-axis limits to reflect the full range of possible scores on the x-axis variable;\nAdding annotation – here, a vertical line – indicating the sample average for a variable.\n\n\n\nQuestions: Task 6\n\nQ.1. Edit the appearance of the bars by specifying a binwidth value.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\nQ.2. Then add an edit to the appearance of the background using theme_bw().\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nQ.3. Then add an edit to the appearance of the labels using labs().\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"frequency count\")\n\n\n\n\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\nQ.4. Now add an edit by setting the x-axis limits using x.lim().\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nQ.5. Then add an edit to draw a vertical line to show the mean value of the variable you are plotting.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40) +\n  geom_vline(xintercept = mean(study.two.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nQ.6. Can you find information on how to define the limits on the x-axis and on the y-axis?\nhint: Q.6. You can see the information in this week’s how-to but try a search online for “ggplot reference xlim”.\nA.6. See ggplot reference information on setting limits here:\n\nhttps://ggplot2.tidyverse.org/reference/lims.html\n\nQ.7. Can you find information on how to a reference line?\nhint: Q.7. You can see the information in this week’s how-to but try a search online for “ggplot reference vline”.\nA.7. See ggplot reference information on setting limits here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-4-now-draw-scatterplots-to-examine-associations-between-variables",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-4-now-draw-scatterplots-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 4: Now draw scatterplots to examine associations between variables",
    "text": "Step 4: Now draw scatterplots to examine associations between variables\n\nConsolidation: should be no surprises here\n\n\nTask 7 – Create a scatterplot to examine the association between some variables\nBetween the outcome mean.acc and each of three numeric potential predictor variables SHIPLEY, HLVA and AGE.\n\nhint: Task 7 – We are working with geom_point() and you need x and y aesthetic mappings.\n\n\nhint: Task 7 – The outcome variable mean.acc has to be mapped to the y-axis using ...y = ...\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nRevise: make sure you are confident about doing these things\n\n\nTask 8 – Edit the appearance of each plot step-by-step\n\nhint: Task 8 – You may want to use the same plot appearance choices for all plots\nBecause a consistent appearance is generally neater and easier for your audience to process.\n\n\nhint: Task 8 – You can find links to reference information on options in the how-to guide\nUse the information to make the plots pleasing in appearance to you.\n\n\nhint: Task 8 – Do not be afraid to copy then paste code you re-use.\nBut be careful that things like axis values are sensible for each variable.\n\n\nQuestions: Task 8\n\nQ.8. – First, edit the appearance of the points using alpha, size, shape, and colour:\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\n\n\n\n\n\n\n\n\nQ.9. – Then edit the colour of the background using theme_bw():\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nQ.10. – Then edit the appearance of the labels using labs():\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"Age (Years)\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\nQ.11. – Then set the x-axis and y-axis limits to the minimum-maximum ranges of the variables you are plotting\nhint: Q.11. – For these plots the y-axis limits will be the same because the outcome stays the same\nhint: Q.11. – But the x-axis limits will be different for each different predictor variable\nhint: Q.11. – The minimum value will always be 0\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\") +\n  xlim(0, 16) + ylim(0, 1)\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"Age (Years)\", y = \"mean accuracy\") +\n  xlim(0, 80) + ylim(0, 1)"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-5-use-correlation-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-5-use-correlation-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 5: Use correlation to to answer the research questions",
    "text": "Step 5: Use correlation to to answer the research questions\n\nRevise: make sure you are confident about doing these things\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\nTask 9 – Examine the correlations between the outcome variable and predictor variables\n\nhint: Task 9 – We use cor.test()\n\n\nhint: Task 9 – You can look at the how-to guide for more advice\nYou need to run three separate correlations:\n\nbetween mean accuracy and SHIPLEY\nbetween mean accuracy and HLVA and\nbetween mean accuracy and AGE\n\n\ncor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$SHIPLEY and study.two.gen$mean.acc\nt = 6.8493, df = 170, p-value = 1.299e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3390103 0.5746961\nsample estimates:\n      cor \n0.4650537 \n\n\n\ncor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$HLVA and study.two.gen$mean.acc\nt = 7.5288, df = 170, p-value = 2.866e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3787626 0.6044611\nsample estimates:\n      cor \n0.5000559 \n\n\n\ncor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$AGE and study.two.gen$mean.acc\nt = 0.30121, df = 170, p-value = 0.7636\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1269774  0.1721354\nsample estimates:\n       cor \n0.02309589 \n\n\nNow use the results from the correlations to answer the following questions.\n\nQ.12. – What is r, the coefficient for the correlation between mean.acc and SHIPLEY?\nA.12. – r = 0.4650537\nQ.13. – Is the correlation between mean.acc and HLVA significant?\nA.13. – r is significant, p &lt; .05\nQ.14. – What are the values for t and p for the significance test for the correlation between mean.acc and AGE?\nA.14. – t = 0.30121, p = 0.7636\nQ.15. – For which pair of outcome-predictor variables is the correlation the largest?\nA.15. – The correlation is the largest between mean.acc and HLVA.\nQ.16. – What is the sign or direction of each of the correlations?\nA.16. – All the correlations are positive."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-6-use-a-linear-model-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-6-use-a-linear-model-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 6: Use a linear model to to answer the research questions",
    "text": "Step 6: Use a linear model to to answer the research questions\n\nIntroduce: Make some new moves\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\nTask 10 – Examine the relation between outcome mean accuracy (mean.acc)\nAnd each of the predictors: SHIPLEY, HLVA and AGE\n\nhint: Task 10 – Use lm()\n\n\nhint: Task 10 – Run three separate lm() analyses\nAll with mean.acc as the outcome but each with one predictor variable\n\n\nhint: Task 10 – See the how-to guide for example code\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.285771 -0.076662  0.002099  0.079416  0.257793 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.308027   0.066426   4.637 7.01e-06 ***\nSHIPLEY     0.012854   0.001877   6.849 1.30e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.107 on 170 degrees of freedom\nMultiple R-squared:  0.2163,    Adjusted R-squared:  0.2117 \nF-statistic: 46.91 on 1 and 170 DF,  p-value: 1.299e-10\n\n\n\nmodel &lt;- lm(mean.acc ~ HLVA, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27457 -0.06777  0.01474  0.08025  0.23146 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.522016   0.032544  16.040  &lt; 2e-16 ***\nHLVA        0.026207   0.003481   7.529 2.87e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1047 on 170 degrees of freedom\nMultiple R-squared:  0.2501,    Adjusted R-squared:  0.2456 \nF-statistic: 56.68 on 1 and 170 DF,  p-value: 2.866e-12\n\n\n\nmodel &lt;- lm(mean.acc ~ AGE, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ AGE, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.34684 -0.08464  0.01084  0.08323  0.21968 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.7519965  0.0267206  28.143   &lt;2e-16 ***\nAGE         0.0002136  0.0007092   0.301    0.764    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1208 on 170 degrees of freedom\nMultiple R-squared:  0.0005334, Adjusted R-squared:  -0.005346 \nF-statistic: 0.09073 on 1 and 170 DF,  p-value: 0.7636\n\n\nNotice that we do the linear model in the steps:\n\nmodel &lt;- lm(...) fit the model using lm(...), and give the model a name, here, we call it model;\n...lm(mean.acc ~ SHIPLEY...) tell R you want a model of the outcome mean.acc predicted ~ by the predictor SHIPLEY\n...data = study.two) tell R that the variables you name in the formula live in the study.two dataset.\nsummary(model) ask R for a summary of the model you called model.\n\nNotice that R has a general formula syntax:\noutcome ~ predictor *or* y ~ x\n\nand uses the same format across a number of different functions;\neach time, the left of the tilde symbol ~ is some output or outcome;\nand the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\nQuestions: Task 10\nIf you look at the model summary you can answer the following questions.\n\nQ.17. What is the estimate for the coefficient of the effect of the predictor HLVA on mean.acc?\nA.17. 0.026207\nQ.18. Is the effect significant?\nA.18. It is significant, p &lt; .05\nQ.19. What are the values for t and p for the significance test for the coefficient?\nA.19. t = 7.529, p = 2.87e-12\nQ.20. How would you describe in words the shape or direction of the association between HLVA and mean.acc?\nA.20. The slope coefficient – and a scatterplot (draw it) – suggest that as HLVA scores increase so also do mean accuracy scores.\nQ.21. How how would you describe the relations apparent between the predictor and outcome in all three models?\nA.21. It is possible to see, given coefficient estimates, that the association between predictor and outcome is positive for each model: mean accuracy appears to increase for increasing values of SHIPLEY vocabulary, HLVA health literacy, and age."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-7-use-a-linear-model-to-generate-predictions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-7-use-a-linear-model-to-generate-predictions",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 7: Use a linear model to generate predictions",
    "text": "Step 7: Use a linear model to generate predictions\n\nIntroduce: make some new moves\n\n\nTask 11 – We can use the model we have just fitted to plot the model predictions\n\nhint: Task 11 – We are going to draw a scatterplot and add a line\nThe line will show the model predictions, given the model intercept and effect coefficient estimates.\nFirst fit a model and get a summary: model the relationship between mean.acc and HLVA\n\nmodel &lt;- lm(mean.acc ~ HLVA, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27457 -0.06777  0.01474  0.08025  0.23146 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.522016   0.032544  16.040  &lt; 2e-16 ***\nHLVA        0.026207   0.003481   7.529 2.87e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1047 on 170 degrees of freedom\nMultiple R-squared:  0.2501,    Adjusted R-squared:  0.2456 \nF-statistic: 56.68 on 1 and 170 DF,  p-value: 2.866e-12\n\n\n\nQ.22. What is the coefficient estimate for the intercept?\nA.22. 0.522016\nQ.23. What is the coefficient estimate for the slope of HLVA (see earlier)?\nA.23. 0.026207\n\nSecond, use the geom_point() to draw a scatterplot and geom_abline() function to draw the prediction line representing the association between this outcome and predictor\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  geom_abline(intercept = 0.522016, slope = 0.026207, colour = \"red\", size = 1.5) +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\") +\n  xlim(0, 15) + ylim(0, 1)\n\n\n\n\n\n\n\n\nYou can see reference information here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html"
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#variable-types",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#variable-types",
    "title": "122_wk12_labActivity2",
    "section": "Variable types",
    "text": "Variable types\nQuestions 5a: What are the variable types for the implicit (IAT_RT) and the explicit (VapingQuestionnaireScore) attitude variables?\nBoth can be considered continuous variables and at least at interval level."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#missing-data",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#missing-data",
    "title": "122_wk12_labActivity2",
    "section": "Missing data",
    "text": "Missing data\n\ndat &lt;- dat %&gt;% \n  filter(!is.na(VapingQuestionnaireScore)) %&gt;% \n  filter(!is.na(IAT_RT))\n\nQuestion 5b How many people had missing data?\nBefore we removed participants with missing data, we had 104 observations, now we have 96. So there must have been 8 participants without a score on one or the other variable."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#normality",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#normality",
    "title": "122_wk12_labActivity2",
    "section": "Normality",
    "text": "Normality\n\nggplot(dat, aes(x = VapingQuestionnaireScore)) + \n  geom_histogram(binwidth = 10) +\n  theme_bw()\n\n\n\n\n\n\n\nqqPlot(x = dat$VapingQuestionnaireScore)\n\n\n\n\n\n\n\n\n[1] 35 95\n\nggplot(dat, aes(x = IAT_RT)) + \n  geom_histogram(binwidth = 10) +\n  theme_bw()\n\n\n\n\n\n\n\nqqPlot(x = dat$IAT_RT)\n\n\n\n\n\n\n\n\n[1] 25 54\n\n\nQuestion 5c What do you conclude from the histograms and the qq-plots? Are the VapingQuestionnaireScore and the IAT_RT normally distributed?\nYes. Both histograms resemble a normal distribution (bell curve) and the open circles in the qq-plots fall within the blue stripy lines."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#linearity-and-homoscedasticity",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#linearity-and-homoscedasticity",
    "title": "122_wk12_labActivity2",
    "section": "Linearity and homoscedasticity",
    "text": "Linearity and homoscedasticity\n\nggplot(dat, aes(x = IAT_RT, y = VapingQuestionnaireScore)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Implicit attitude\", y = \"Explicit attitude\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nQuestion 5d What do you conclude from the scatterplot in terms of the homoscedasticity of the data and the linearity, direction and strength of the relationship? What does the scatterplot tell you about possible issues (outliers, range restrictions)?\nThe data look like a cloud without a clear direction. This suggests the relationship might might be weak. In terms of linearity, the scatterplot doesn’t suggest any curvilinear relationships. Variance seems quite constant, but there do seem to be few people with negative IAT_RT (Implicit attitude) scores, suggesting few people held the view that vaping is positive."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#create-a-new-data-frame-that-only-includes-the-relevant-variables",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#create-a-new-data-frame-that-only-includes-the-relevant-variables",
    "title": "122_wk12_labActivity2",
    "section": "Create a new data frame that only includes the relevant variables",
    "text": "Create a new data frame that only includes the relevant variables\n\ndat_matrix &lt;- dat %&gt;%\n  select(Age, IAT_RT, VapingQuestionnaireScore) %&gt;%\n  as.data.frame() # Make sure tell R that dat is a data frame"
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#create-a-matrix-of-scatterplots",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#create-a-matrix-of-scatterplots",
    "title": "122_wk12_labActivity2",
    "section": "Create a matrix of scatterplots",
    "text": "Create a matrix of scatterplots\n\npairs(dat_matrix)\n\n\n\n\n\n\n\n\nQuestion 8a What do you conclude from the scatterplots?\nThe scatterplots with age suggest that age is highly skewed with only a few participants older than 25. For now, let’s say we’ll therefore calculate Spearman’s rho, rather than Pearson’s r. That is ok for now, but if you were analysing these data for a research project, you’d want to have a closer look at the age variable (think histogram, qq-plot, and think about either collecting more data from older participants or transforming the variable (more about that next year)."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#conduct-intercorrelation-multiple-correlations",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#conduct-intercorrelation-multiple-correlations",
    "title": "122_wk12_labActivity2",
    "section": "Conduct intercorrelation (multiple correlations)",
    "text": "Conduct intercorrelation (multiple correlations)\n\nintercor_results &lt;- correlate(x = dat_matrix, # our data\n                          test = TRUE, # compute p-values\n                          corr.method = \"spearman\", # run a spearman test \n                          p.adjust.method = \"bonferroni\") # use the bonferroni correction\nintercor_results\n\n\nCORRELATIONS\n============\n- correlation type:  spearman \n- correlations shown only when both variables are numeric\n\n                            Age    IAT_RT    VapingQuestionnaireScore   \nAge                           .     0.156                      -0.086   \nIAT_RT                    0.156         .                      -0.022   \nVapingQuestionnaireScore -0.086    -0.022                           .   \n\n---\nSignif. codes: . = p &lt; .1, * = p&lt;.05, ** = p&lt;.01, *** = p&lt;.001\n\n\np-VALUES\n========\n- total number of tests run:  3 \n- correction for multiple testing:  bonferroni \n- WARNING: cannot compute exact p-values with ties\n\n                           Age IAT_RT VapingQuestionnaireScore\nAge                          .  0.384                    1.000\nIAT_RT                   0.384      .                    1.000\nVapingQuestionnaireScore 1.000  1.000                        .\n\n\nSAMPLE SIZES\n============\n\n                         Age IAT_RT VapingQuestionnaireScore\nAge                       96     96                       96\nIAT_RT                    96     96                       96\nVapingQuestionnaireScore  96     96                       96\n\n\nQuestion 8b What do you conclude from the results of the correlation analysis?\nNo significant correlation with age was found."
  },
  {
    "objectID": "PSYC122/data/week13/122_wk13_labAct2.html",
    "href": "PSYC122/data/week13/122_wk13_labAct2.html",
    "title": "122_wk13_labActivity2",
    "section": "",
    "text": "Question 1a If our hypothesis is correct, what type of correlation (if any) should we observe between students’ mean anxiety levels and the variable n_weeks? A negative correlation"
  },
  {
    "objectID": "PSYC122/data/week13/122_wk13_labAct2.html#lab-activity-2---statistics-anxiety-and-engagement-in-module-activities",
    "href": "PSYC122/data/week13/122_wk13_labAct2.html#lab-activity-2---statistics-anxiety-and-engagement-in-module-activities",
    "title": "122_wk13_labActivity2",
    "section": "",
    "text": "Question 1a If our hypothesis is correct, what type of correlation (if any) should we observe between students’ mean anxiety levels and the variable n_weeks? A negative correlation"
  },
  {
    "objectID": "PSYC122/index.html",
    "href": "PSYC122/index.html",
    "title": "Statistics for Psychologists II",
    "section": "",
    "text": "Welcome\nWelcome to PSYC122!\nThis module builds on the knowledge and skills acquired in Statistics for Psychologists 1 (PSYC121). You will continue to practise data handling, data processing and data visualisation, using R and R Studio. In addition, you will learn about statistical methods to test whether two (or more) variables are associated and how to implement those methods in R and R Studio.\nWatch the video below (~ 5 minutes) to get a short overview of the topics we will cover in weeks 11 to 15.\n\nThis page gives you access to all the materials that you will need. You will have timetabled lab classes during which you are expected to work through a series of exercises to practise that week’s material. Before you come to your lab session, you should watch the lectures for that week, read the relevant book chapter and complete the pre-lab activities. Following all that and to check that you’ve understood the week’s materials, you can complete a quick quiz.\nThere will be class tests in weeks 15 and 20. These take place, in person, during your regular lab session.\n\n\nAsking for help\nWe have carefully prepared and refined the lab materials in this course over several years, and we feel that the pace of the materials is just right for our students. Some students will complete them more quickly, and others more slowly - both of these scenarios are absolutely fine. You should work at the pace that suits you best, making sure you understand the materials before you move forward.\nIt is fairly inevitable that you will get stuck on the lab materials in this module at some point. This might be in Week 11, Week 12, or later. When you do, it’s important you reach out for help:\n\nAsk your friends on your table. We’ve designed this teaching space to help collaborative work. You are encouraged to work with other students. Make sure you ask others to explain how they’ve solved an exercise. Make sure you help out others where you can. Always make sure you understand the code and the exercise; don’t simply be satisfied that you’ve got the right answer.\nAsk a GTA or Lecturer. Our Graduate Teaching Assistants are there to help you. There are no “stupid questions” in statistics, so just ask the GTAs any question about what you’re doing. Likewise, ask the Lecturer.\nAsk on the Discussion Forum. On the PSYC122 moodle page you will find a Discussion Forum. This is a great way to ask a question outside of the lab sessions. It might seem scary to ask a question in the forum, but please don’t be afraid to do this. If you have a question, you can bet 30+ other students also have the same question! So by asking the question on the forum, you help out many more people on the module. A friendly GTA or Lecturer will be along to answer the question as soon as possible (we aim for within 48 hours during the working week).\nAsk on the module Q & A session. Each week we hold a “Q&A” online session where we will try and resolve any general queries and problems. It’s an ideal time to discuss things that students are struggling with or confused about, and can share ideas and answers. You can ask on the discussion forum above and then we might be able to pick up the issues and discuss them, but also you can ask in the session itself.\n\n\n\nCourse Contacts\n\n\n\n\nEmail Address\n\n\n\n\nMargriet Groen\nm.groen at lancaster dot ac dot uk\n\n\nRob Davies\nr.davies1 at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "PSYC122"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html",
    "href": "PSYC122/Week11.html",
    "title": "1. Week 11 - Correlation",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.\nTHIS IS A TEST\nToday we will take a look at correlation as a measure of association between two numerical variables. We will create scatterplots to visualise correlations, we will run a correlation analysis and we will practise interpreting and reporting the results.",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-lectures",
    "href": "PSYC122/Week11.html#sec-wk11-lectures",
    "title": "1. Week 11 - Correlation",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material comes in two parts.\n\nTheory(~30 minutes) Watch this part before you complete the reading and the pre-lab activities. The video has captions, in case you find that helpful. You can download the slides and a transcript from the links below the video. Finally, if you open the video in ‘eStream’ by clicking on the green ‘e’ in the bottom right, you can navigate to separate sections of the video by clicking on the ‘chapters’ pane. This might be particularly useful if you quickly want to revisit a particular section.\n\n\nSlides Transcript\n\nHow to(~13 minutes) Watch this part after you’ve completed the pre-lab activities and before you attend the lab session.\n\n\nSlides Transcript",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-reading",
    "href": "PSYC122/Week11.html#sec-wk11-reading",
    "title": "1. Week 11 - Correlation",
    "section": "Reading",
    "text": "Reading\nThe reading that accompanies the lectures this week and next week is from chapter 9 of the core text by Howell (2017).\nRougly, this week we’ll cover the material in sections 9.1 to 9.4, as well as sections 9.8 to 9.11 and section 9.15. Next week, we’ll cover the material in sections 9.5 to 9.7, and sections 9.12 to 9.13. Even if a section is not mentioned here, all of chapter 9 is relevant.",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-prelab-activities",
    "href": "PSYC122/Week11.html#sec-wk11-prelab-activities",
    "title": "1. Week 11 - Correlation",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures on correlation and read the textbook sections you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Visualing correlations\nHave a look at this visualisation of correlations by Kristoffer Magnusson.\nAfter having read the relevant sections of Howell (2017) Chapter 9, use this visualisation page to visually replicate the scatterplots in Figures 9.1 and 9.2 - use a sample of 100. After that, visually replicate the scatterplots in Figure 9.3.\nEach time you change the correlation, pay attention to the shared variance (the overlap between the two variables) and see how this changes with the changing level of relationship between the two variables. The greater the shared variance, the stronger the relationship.\nAlso, try setting the correlation to r = .5 and then moving a single dot to see how one data point, a potential outlier, can change the stated correlation value between two variables.\n\n\nPre-lab activity 2: Guess the correlation\nNow that you are well versed in interpreting scatterplots (scattergrams) have a go at this online app on guessing the correlation.\nThis is a very basic app that allows you to see how good you are at recognising different correlation strengths from the scatterplots. We would recommend you click the “Track Performance” tab so you can keep an overview of your overall bias to underestimate or overestimate a correlation.\nIs this all just a bit of fun? Well, yes, because stats is actually fun, and no, because it serves a purpose of helping you determine if the correlations you see in your own data are real, and to help you see if correlations in published research match with what you are being told. As you will have seen from the above examples, one data point can lead to a misleading relationship and even what might be considered a medium to strong relationship may actually have only limited relevance in the real world. One only needs to mention Anscombe’s Quartet to be reminded of the importance of visualising your data, which leads us to the final pre-lab activity for this week.\n\n\nPre-lab activity 3: Anscombe’s quartet\nAnscombe (1973) showed that four sets of bivariate data (X, Y) that have the exact same means, medians, and relationships can look very different when plotted. You can read more about this here.\nAll in this is a clear example of why you should visualise your data and not to rely on just the numbers.\n\n\nPre-lab activity 4: Getting ready for the lab class\n\nRemind yourself of the basics of how to work with RStudio and get your files ready\nYou might want to re-visit the materials that John and Tom provided in PSYC121:\n\nBasics of working with RStudio\nCreate a folder for Week 11.\nDownload the 122_week11_forStudents.zip file and upload it into the new folder in RStudio Server you created at the previous step.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below.\n\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/122_week11_forStudents/exams.csv?raw=true\", destfile = \"exams.csv\")",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-labactivities",
    "href": "PSYC122/Week11.html#sec-wk11-labactivities",
    "title": "1. Week 11 - Correlation",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nconstructing and interpreting scatterplots\nrunning correlation analysis and interpret the results\nreporting the results in APA format\nconstructing a correlation matrix in APA format\nwhen and why to apply correlation analysis to answers questions in psychological science\n\n\nLab activity 1: Interpreting correlation\n\nQuestion 1\nBelow are scatterplots that show the relationship between ‘how much you know about correlation and how attractive you appear to members of the opposite (&/or same) sex’. Choose the type of correlation (strength and direction) displayed in each graph using one of the following:\n\nPerfect positive correlation\nPerfect negative correlation\nStrong positive correlation\nStrong negative correlation\nModerate positive correlation\nModerate negative correlation\nNull correlation\n\nFigure A \nFigure B \nFigure C \nFigure D \n\n\n\n\n\n\nNote\n\n\n\nFor the following questions, explain your chosen answer based on the statistic given, not on why you think the correlation may or may note make ‘logical’ sense.\n\n\n\n\nQuestion 2\nSuppose it was observed that there is a correlation of r = -.81 between a driver’s age and the cost of car insurance. This correlation would mean that, in general, older people pay more for car insurance.\nTRUE or FALSE? Explain why.\n\n\nQuestion 3\nSuppose that there is a correlation of r = .87 between the length of time a person is in prison and the amount of aggression the person displays on a psychological inventory administered at release. This means that spending a longer amount of time in prison causes people to become more aggressive.\nTRUE or FALSE? Explain why.\n\n\nQuestion 4\nA significant correlation was found between having great hair and performance in correlation labs. The correlation coefficient was .7. How much variance in correlation lab performance can the ‘greatness’ of your hair explain?\n\n51%\n70%\n49%\n30%\nWho cares I’ve got great hair.\n\nWhat was the reason for your answer?\nWhat is this ‘new coefficient’ called?\n\n\n\nLab activity 2: Visualising, calculating and reporting correlations\n\n\n\n\n\n\nWatch the ‘How to’ video\n\n\n\nIf you haven’t done so already, this is a good time to watch the ‘How to’ video (here Section 1) on ‘How to conduct a correlation analysis using R’.\n\n\nGoing back to the data discussed in the ‘How to’ video (see Section 1), you’ll remember it contains data from 25 8-year-old children on:\n\na standardised test of reading ability (Abil)\nintelligence (IQ)\nthe number of minutes per week spent reading in the home (Home)\nand the number of minutes per week spent watching TV (TV)\n\nIn the video on ‘How to conduct correlation analysis using R’ we looked at the correlation between reading ability and intelligence. Now, let’s look at the correlation between number of minutes per week spent reading in the home and watching TV.\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 4: Getting ready for the lab class’ contains the datafile (“MillerHadenData.csv”). Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nDo this if you couldn’t upload files to the server\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/MillerHadenData.csv?raw=true\", destfile = \"MillerHadenData.csv\")\n\n\n\n\n\n\n\nNew R Markdown script\n\n\n\nBefore we begin, make sure you have started a new R Markdown script. If you need a reminder of how to do that, please revisit week 6 of PSYC121 (here).\n\n\n\nStep 1. Add the code to load the broom and the tidyverse libraries in a new code chunk. If you are unsure, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library()function. Remember to put it inside a ‘code chunk’ in your R Markdown script.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(tidyverse)\n\n\n\n\nStep 2. Read in the data. You should now see a dataframe with 25 observations and 5 variables in the ‘Environment’. Click on it to view it.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nmh &lt;- read_csv(\"MillerHadenData.csv\")\n\n\n\n\nStep 3. Construct a scatterplot of the relationship between ‘Home’ and ‘TV’. Also add a line of best fit and make sure you use clear labels for your axes.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the ggplot()function in combination with geom_point() and geom_smooth(). Make sure you use clear labels for your axes by using labs().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variable names. Also add clear labels for your axes.\nggplot(DATA, aes(x = , y = )) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"\", y = \"\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nggplot(mh, aes(x = Home, y = TV)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Time spend reading at home\", y = \"Time spend watching TV at home\")\n\n\n\nQuestion 3a: What can you tell from the scatterplot about the direction of the relationship? Write a few sentences in your R Markdown script to describe the relationship.\n\nStep 4. Conduct the correlation analysis.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the cor.test()function in combination with tidy().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variables names.\nresults &lt;- cor.test(DATA$X, \n                    DATA$Y, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nresults &lt;- cor.test(mh$Home, \n                    mh$TV, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\nOnce you’ve run this code chunk, the output should appear in your R Markdown script and you can answer the questions below using that output. You can also pull out the different pieces of information by using the pull() function and round the values using the round() function, like this:\nr &lt;- results %&gt;%\n  pull(estimate) %&gt;%\n  round(2)\nQuestion 4a: What is the correlation coefficient (Pearson’s r)?\nQuestion 4b: What is the p value?\nQuestion 4c: Is the correlation significant at the p &lt; .05 level?\nQuestion 4d: What are the degrees of freedom you need to report?\n\nStep 5. Calculate how much variance in ‘time spent reading’ can be accounted for by ‘time spent watching TV’?\n\nAs discussed in the theory lecture, this is referred to as the ‘coefficient of determination’ or ‘R-squared’. To calculate it, you square the value for Pearson’s r. To calculate how much variance in one variable is accounted for by the other variable, you multiply it by 100 and round it to 0 decimals.\n\nStep 6. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\nLab activity 3: Hazardous alcohol use and impulsivity\nResearchers were interested in the relationship between hazardous alcohol use and impulsivity (making unplanned, rapid decisions without thinking or ‘acting on a whim’). To investigate the relationship, 20 participants completed both the alcohol use disorder identification test (AUDIT; Saunders, Aasland, Babor, de la Fuente, & Grant, 1993) and Barratt’s Impulsiveness Scale (BIS-11) (Patton, Stanford, & Barratt, 1995).\n\n\n\n\n\n\nBefore we begin\n\n\n\nAssuming you are using the same R Markdown script as for the previous lab activity, you should already have code to load the broom and the tidyverse libraries. If this is a new session, you just need to re-run that code chunk to ensure they are loaded. At this point, it is a good idea to clear your environment to avoid any confusion between data frames or values. You can do this by clicking on the broom icon on the top right of the Environment pane. The data file (“alcoholUse_Impulsivity.csv”) is in the folder you were asked to download under ‘Pre-lab activity 4: Getting ready for the lab class’. As long as that folder is set as your working directory, you are good to go.\n\n\n\n\n\n\n\n\nDo this if you couldn’t upload files to the server\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/122_week11_forStudents/alcoholUse_Impulsivity.csv?raw=true\", destfile = \"alcoholUse_Impulsivity.csv\")\n\n\nStep 1. Read in the data. You should now see an object containing the data in the ‘Environment’.\n\nQuestion 1a: How many variables does it have?\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\ndata &lt;- read_csv(\"alcoholUse_Impulsivity.csv\")\n\n\n\n\nStep 2. Plot the relationship between hazard alcohol use and impulsivity using a scatterplot and a line of best fit\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the ggplot()function in combination with geom_point() and geom_smooth(). Make sure you use clear labels for your axes by using labs().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nUse this code template and add the name of the data frame and the variables. Also add informative labels for your axes.\nggplot(, aes(x = , y = )) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"\", y = \"\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below\nggplot(data, aes(x = hau, y = imp)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Hazardous Alcohol Use\", y = \"Impulsivity\")\n\n\n\nQuestion 2a: What can you tell from the scatterplot about the direction of the relationship?\n\nStep 3. Conduct the correlation analysis.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the cor.test()function in combination with tidy().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variables names.\nresults &lt;- cor.test(DATA$X, \n                    DATA$Y, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nresults &lt;- cor.test(data$hau, \n                    data$imp, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\n\nresults\n\n\n\nQuestion 3a: What is the correlation coefficient (Pearson’s r)?\nQuestion 3b: What is the p value?\nQuestion 3c: Is the correlation significant at the p &lt; .05 level?\nQuestion 3d: What are the degrees of freedom you need to report?\nQuestion 3e: How much variance in ‘impulsivity’ can be accounted for by ‘hazardous alcohol use’?\nQuestion 3f: Give three logically possible directions of causality, indicating for each direction whether it is a plausible explanation in light of the variables involved (and why). No, this is not a trick question —-I know that correlation does not infer causation, but think critically! New studies/ideas are constructed by thinking what the previous study doesn’t tell us about what could be happening with the variables of interest.\n\nStep 4. Write a few sentences in which you report this result, following APA guidelines.\n\nJob completed — Well done!",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#answers",
    "href": "PSYC122/Week11.html#answers",
    "title": "1. Week 11 - Correlation",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at code written by someone else…\n\n\nLab activity 1: Interpreting correlation\n\nBelow are scatterplots that show the relationship between ‘how much you know about correlation and how attractive you appear to members of the opposite (&/or same) sex’. Choose the type of correlation (strength and direction) displayed in each graph.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nstrong positive correlation\nnull correlation\nmoderate positive correlation\nperfect negative correlation\n\n\n\n\n\nSuppose it was observed that there is a correlation of r = -.81 between a driver’s age and the cost of car insurance. This correlation would mean that, in general, older people pay more for car insurance.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFALSE Explanation: The correlation coefficient is negative and therefore infers a negative correlation. As such, older people pay less for car insurance: as age increases, car insurance costs decrease.\n\n\n\n\nSuppose that there is a correlation of r = .87 between the length of time a person is in prison and the amount of aggression the person displays on a psychological inventory administered at release. This means that spending a longer amount of time in prison causes people to become more aggressive.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFALSE Explanation: This is a bit of trick question as it has the sneaky ‘cause’ word in. The correlation coefficient is a positive number, suggesting a positive relationship between length of time in prison and aggression. However, causation cannot be inferred from correlation and therefore we cannot know whether time spent in prison CAUSES aggression, and rather we suggest a relationship between the two: as length of time in prison increases, aggression increases.\n\n\n\n\nA significant correlation was found between having great hair and performance in correlation labs. The correlation coefficient was .7. How much variance in correlation lab performance can the ‘greatness’ of your hair explain?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nc 49% The ‘coefficient of determination’ or ‘R-squared’ tells us the proportion or variance in one variable that can be predicted if we know the other variable. We can determine this by squaring the r. Therefore, .72 = .49, R2 = .49.\n\n\n\n\n\nLab activity 2: Constructing scatterplots and calculating correlations\nYou can download the RMd-script that contains the code to complete lab activities 2 and 3 here: 122_wk11_labActivities2_3.Rmd.\nQuestion 3a: What can you tell from the scatterplot about the direction of the relationship?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is a negative association between ‘Home’ and ‘TV’. This means that the longer a child spends watching TV, the shorter they will read at home.\n\n\n\nQuestion 4a: What is the correlation coefficient (Pearson’s r)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nr = -.65\n\n\n\nQuestion 4b: What is the p value?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\np &lt; .001\n\n\n\nQuestion 4c: Is the correlation significant at the p &lt; .05 level?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes, because the p-value is smaller than .005\n\n\n\nQuestion 4d: What are the degrees of freedom you need to report?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n23\n\n\n\nStep 5. How much variance in ‘time spent reading’ can be accounted for by ‘time spent watching TV’?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n42%\n\n\n\nStep 6. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSomething along the lines of: A Pearson’s correlation coefficient was used to assess the relationship between time spent reading at home and time spent watching TV at home. There was a significant negative correlation, r(23) = -.65, p &lt; .001. As time spent watching TV increased, time spent reading at home decreased.\n\n\n\n\n\nLab activity 3: Hazardous alcohol use and impulsivity\nQuestion 1a: How many variables does it have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n3\n\n\n\nQuestion 2a: What can you tell from the scatterplot about the direction of the relationship?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is a positive association between ‘hazardous alcohol use’ and ‘impulsivity’. This means that as a participant’s score on ‘hazardous alcohol use’ goes up, their score on ‘impulsivity’ also goes up.\n\n\n\nQuestion 3a: What is the correlation coefficient (Pearson’s r)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nr = .54\n\n\n\nQuestion 3b: What is the p value?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\np = .014\n\n\n\nQuestion 3c: Is the correlation significant at the p &lt; .05 level?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes\n\n\n\nQuestion 3d: What are the degrees of freedom you need to report?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n18\n\n\n\nQuestion 3e: How much variance in ‘impulsivity’ can be accounted for by ‘hazardous alcohol use’?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n29%\n\n\n\nQuestion 3f:. Give three logically possible directions of causality, indicating for each direction whether it is a plausible explanation in light of the variables involved (and why). No, this is not a trick question —-I know that correlation does not infer causation, but think critically! New studies/ideas are constructed by thinking what the previous study doesn’t tell us about what could be happening with the variables of interest.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nJust really looking for reasoning here.\nExamples:\n\nBeing more impulsive may make people consume more alcohol.\nConsuming more alcohol may make people more impulsive.\nAn outgoing personality might influence both your level of impulsivity and you are more likely to be socialising in the pub and consuming alcohol. So the same ‘third factor’ may influence both our variables of interest.\n\n\n\n\nStep 4. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSomething along the lines of: A Pearson’s correlation coefficient was used to assess the relationship between alcohol use and impulsivity. There was a significant positive correlation, r(18) = .54, p &lt; .014. People who reported to consume more alcohol, scored higher on the impulsivity scale.",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#online-qa",
    "href": "PSYC122/Week11.html#online-qa",
    "title": "1. Week 11 - Correlation",
    "section": "Online Q&A",
    "text": "Online Q&A\nBelow is the recording of this week’s online Q&A.\n\nTranscript",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/data/week14/122_wk14_labAct2.html",
    "href": "PSYC122/data/week14/122_wk14_labAct2.html",
    "title": "122_wk13_labActivity2",
    "section": "",
    "text": "Aim: What we want to do is to run a chi-square analysis to determine whether those in the RTA condition were more likely to remember to return the paper-clips than those in the control condition."
  },
  {
    "objectID": "PSYC122/data/week14/122_wk14_labAct2.html#lab-activity-2---reminders-through-association",
    "href": "PSYC122/data/week14/122_wk14_labAct2.html#lab-activity-2---reminders-through-association",
    "title": "122_wk13_labActivity2",
    "section": "",
    "text": "Aim: What we want to do is to run a chi-square analysis to determine whether those in the RTA condition were more likely to remember to return the paper-clips than those in the control condition."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "",
    "text": "In Week 19, we aim to further develop skills in working with the linear model.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nIn this class, what is new is our focus on critically evaluating – comparing, reflecting on – the evidence from more than one relevant study.\n\nThis work simulates the kind of critical evaluation of evidence that psychologists must do in professional research.\n\n\n\nI will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this how-to guide, we use data from two 2020 studies of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nThe reason we are going to work with two datasets is that we will be comparing the results of analyses of the data to assess whether the results are robust.\nHere, our assessment of robustness focuses on whether similar results are found in two different studies.\nCheck out the PSYC122 Week 19 lecture for a discussion of how an assessment of robustness is important to psychological science."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#naming-things",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#naming-things",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "",
    "text": "In this how-to guide, we use data from two 2020 studies of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nThe reason we are going to work with two datasets is that we will be comparing the results of analyses of the data to assess whether the results are robust.\nHere, our assessment of robustness focuses on whether similar results are found in two different studies.\nCheck out the PSYC122 Week 19 lecture for a discussion of how an assessment of robustness is important to psychological science."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-1-set-up",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-1-set-up",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"ggeffects\")\nlibrary(\"patchwork\")\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-2-load-the-data",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data files we will be using\nThe data files are called:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data files into R:\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")  \n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data files in, give the data objects you create distinct name e.g. study.one.gen versus study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look at both datasets.\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\n\nNotice that study.two.gen was designed to be a replication of study.one.gen.\n\nWe use the same online survey methods to collect data in both studies.\nWe present different health information texts in the different studies and recorded responses from different groups of adults in the UK."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-3-compare-the-data-from-the-different-studies",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-3-compare-the-data-from-the-different-studies",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 3: Compare the data from the different studies",
    "text": "Step 3: Compare the data from the different studies\n\nRevise: practice to strengthen skills\n\n\nTask 5 – Compare the data distributions from the two studies\n\nQ.1. What is the mean of the mean.acc and SHIPLEY variables in the two studies?\nA.1. The means are:\nstudy one – mean.acc – mean = 0.8163\nstudy one – mean.self – mean = 6.906\nstudy two – mean.acc – mean = 0.7596\nstudy two – mean.self – mean = 7.101\nQ.2. Draw histograms of both mean.acc and mean.self for both studies.\nA.2. You can write the code as you have been shown to do e.g. in 2023-24-PSYC122-w17-how-to.Rmd:\n\n\nggplot(data = study.one.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = mean.self)) + \n  geom_histogram(binwidth = 1) +\n  theme_bw() +\n  labs(x = \"Mean self-rated accuracy (mean.self)\", y = \"frequency count\") +\n  xlim(0,10)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = mean.self)) + \n  geom_histogram(binwidth = 1) +\n  theme_bw() +\n  labs(x = \"Mean self-rated accuracy (mean.self)\", y = \"frequency count\") +\n  xlim(0,10)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\n\nTask 6 – Create grids of plots to make the comparison easier to do\n\n\nhint: Task 6 – What we are going to do is to create two histograms and then present them side by side to allow easy comparison of variable distributions\nWe need to make two changes to the coding approach you have been using until now.\nBefore we explain anything, let’s look at an example: run these line of code and check the result.\n\nMake sure you identify what is different about the plotting code, shown following, compared to what you have done before: there is a surprise in what is going to happen.\n\nFirst, create plot objects, give them names, but do not show them:\n\nplot.one &lt;- ggplot(data = study.one.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study One\") +\n  xlim(0, 1)\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study Two\") +\n  xlim(0, 1)\n\nSecond, show the plots, side-by-side:\n\nplot.one + plot.two\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nThis is what you are doing: check out the process, step-by-step. (And notice that you repeat the process for each of two (or more) plots.)\n\nggplot(...) tell R you want to make a plot using the ggplot() function;\nplot.one &lt;- tell R you want to give the plot a name; the name appears in the environment;\nggplot(data = study.one.gen ...) tell R you want to make a plot with the study.two data;\nggplot(..., aes(x = mean.acc)) tell R that you want to make a plot with the variable mean.acc;\n\n\nhere, specify the aesthetic mapping, x = mean.acc\n\n\ngeom_histogram() tell R you want to plot values of mean.acc as a histogram;\nbinwidth = .1 adjust the binwidth to show enough detail but not too much in the distribution;\ntheme_bw() tell R what theme you want, adjusting the plot appearance;\nlabs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study One\") fix the x-axis and y-axis labels;\n\n\nhere, add a title for the plot, so you can tell the two plots apart;\n\n\nxlim(0, 1) adjust the x-axis limits to show the full range of possible score values on this variable.\n\nDo this process twice, once for each dataset, creating two plots so that you can compare the distribution of mean.acc scores between the studies.\nFinally, having created the two plots, produce them for viewing:\n\nplot.one + plot.two having constructed – and named – both plots, you enter their names, separated by a +, to show them in a grid of two plots.\n\nNotice: until you get to step 10, nothing will appear.\nThis will be surprising but it is perfectly normal when we increase the level of complexity of the plots we build.\n\nYou first build the plots.\nYou are creating plot objects and you give these objects names.\nThe objects will appear in the Environment with the names you give them.\nYou then produce the plots for viewing, by using their names.\n\nUntil you complete the last step, you will not see any changes until you use the object names to produce them for viewing.\nThis is how you construct complex arrays of plots.\n\n\nTask 7 – Try this out for yourself, focusing now on the distribution of mean.self scores in the two studies\nFirst, create plot objects but do not show them.\n\nGive each plot a name. You will use the names next.\n\n\nplot.one &lt;- ggplot(data = study.one.gen, aes(x = mean.self)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Self-rated accuracy (mean.self)\", y = \"frequency count\", title = \"Study One\") +\n  xlim(0, 10)\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = mean.self)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Self-rated accuracy (mean.self)\", y = \"frequency count\", title = \"Study Two\") +\n  xlim(0, 10)\n\nSecond produce the plots for viewing, side-by-side, by naming them.\n\nplot.one + plot.two\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nQ.3. Now use the plots to do some data analysis work: how do the mean.self distributions compare, when you compare the mean.self of study.one.gen versus `mean.self of study.two.gen?\nA.3. When you compare the plots side-by-side you can see that the mean.self distributions are similar in the two studies: most people have high mean.self scores. This means that they rated the accuracy of their understanding at a high level, on average.\nQ.4. Is the visual impression you get from comparing the distributions consistent with the statistics you see in the summary?\nA.4. Yes: If you go back to the summary of mean.self, comparing the two studies datasets, then you can see that the median and mean are similar (around 7) in both study.one.gen and study.two.gen datasets."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-4-now-use-scatterplots-and-correlation-to-examine-associations-between-variables",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-4-now-use-scatterplots-and-correlation-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 4: Now use scatterplots and correlation to examine associations between variables",
    "text": "Step 4: Now use scatterplots and correlation to examine associations between variables\n\nRevise: practice to strengthen skills\n\n\nTask 8 – Draw scatterplots to compare the potential association between mean.acc and mean.self in both study.one.gen and study.two.gen datasets\n\n\nhint: Task 8 – The plotting steps are explained in some detail in 2023-24-PSYC122-w17-how-to.Rmd\n\nggplot(data = study.one.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nTask 9 – Create a grid of plots to make the comparison easier to do\n\n\nhint: Task 9 – We follow the same steps as we used in tasks 6 and 7 to create the plots\nWe again:\n\nFirst construct the plot objects and give them names;\nThen create and show a grid of named plots.\n\nThough this time we are producing a grid of scatterplots.\nFirst, create plot objects – give them names but do not show them:\n\nplot.one &lt;- ggplot(data = study.one.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\", title = \"Study One\") +\n  xlim(0, 10) + ylim(0, 1)\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\", title = \"Study Two\") +\n  xlim(0, 10) + ylim(0, 1)\n\n\nNotice that in the plotting code we ask R to give each plot a title using labs().\n\nSecond name the plots, to show them side-by-side in the plot window:\n\nplot.one + plot.two\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNow use the plots to make comparison judgments.\n\nQ.5. How does the association, shown in the plots, between mean.self and mean.acc compare when you look at the study.one.gen versus the study.two.gen plot?\nhint: Q.5. When comparing evidence about associations in different studies, we are mostly going to focus on the slope – the angle – of the prediction lines, and the ways in which points do or do not cluster about the prediction lines.\nA.5. If you examine the study.one.gen versus the study.two.gen plots then you can see that in both plots higher mean.self scores appear to be associated with higher mean.acc scores. But the trend maybe is a bit stronger – the line is steeper – in study.two.gen compared to study.two.gen.\n\nWe are now in a position to answer one of our research questions:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nIf people can accurately evaluate whether they correctly understand written health information then mean.self (a score representing their evaluation) should be associated with mean.acc (a score representing their accuracy of understanding) for each person.\n\n\nRevise: practice to strengthen skills\n\n\nTask 10 – Can you estimate the association between mean.acc and mean.self in both datasets?\n\n\nhint: Task 10 – Use cor.test() as you have been shown how to do e.g. in 2023-24-PSYC122-w16-how-to.Rmd\nDo the correlation for both datasets.\nFirst, look at the correlation between mean.acc and mean.self in study.one.gen:\n\ncor.test(study.one.gen$mean.acc, study.one.gen$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one.gen$mean.acc and study.one.gen$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\nQ.6. What is r, the correlation coefficient?\nA.6. r = 0.4863771\nQ.7. Is the correlation significant?\nA.7. r is significant\nQ.8. What are the values for t and p for the significance test for the correlation?\nA.8. t = 7.1936, p-value = 2.026e-11\n\nSecond, look at the correlation between mean.acc and mean.self in study.two.gen:\n\ncor.test(study.two.gen$mean.acc, study.two.gen$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$mean.acc and study.two.gen$mean.self\nt = 8.4991, df = 170, p-value = 9.356e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4317217 0.6431596\nsample estimates:\n      cor \n0.5460792 \n\n\n\nQ.9. What is r, the correlation coefficient?\nA.9. r = 0.5460792\nQ.10. Is the correlation significant?\nA.10. r is significant\nQ.11. What are the values for t and p for the significance test for the correlation?\nA.11. t = 8.4991, p = 9.356e-15\n\nNow we can answer the research question:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nQ.12. What do the correlation estimates tell you is the answer to the research question?\nA.12.\n\n\nThe correlations are positive and significant, indicating that higher mean.self (evaluations) are associated with higher mean.acc (understanding), suggesting that people can judge their accuracy of understanding.\n\n\nQ.13. Can you compare the estimates, given the two datasets, to evaluate if the result in study.one.gen is replicated in study.two.gen?\nhint: Q.13. We can judge if the result in a study is replicated in another study by examining if – here – the correlation coefficient is significant in both studies and if the coefficient has the same size and sign in both studies.\nA.13. If you compare the correlation estimates from both study.one.gen and study.two.gen you can see:\nfirst, the correlation is significant in both studies;\nsecond, the correlation is positive in both studies,\nthird, the correlation is similar in magnitude, about \\(r = .5\\) in both studies.\n\nThis suggests that the association we see in study.one.gen is replicated in study.two.gen."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-5-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-5-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 5: Use a linear model to to answer the research questions – multiple predictors",
    "text": "Step 5: Use a linear model to to answer the research questions – multiple predictors\n\nRevise: practice to strengthen skills\n\n\nTask 11 – Examine the relation between outcome mean accuracy (mean.acc) and multiple predictors\nWe specify linear models including as predictors the variables:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\n\nhint: Task 11 – Use lm(), as you have done before, see e.g. 2023-24-PSYC122-w18-how-to.R\n\n\nTask 11 – Examine the predictors of mean accuracy (mean.acc), first, for the study.one.gen data\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40322 -0.05349  0.01152  0.07128  0.18434 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.302030   0.091257   3.310  0.00115 ** \nHLVA        0.017732   0.003923   4.521 1.17e-05 ***\nSHIPLEY     0.005363   0.002336   2.296  0.02291 *  \nFACTOR3     0.003355   0.001264   2.654  0.00872 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1033 on 165 degrees of freedom\nMultiple R-squared:  0.2474,    Adjusted R-squared:  0.2337 \nF-statistic: 18.08 on 3 and 165 DF,  p-value: 3.423e-10\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:\n\nQ.14. What is the estimate for the coefficient of the effect of the predictor SHIPLEY in this model?\nA.14. 0.005363\nQ.15. Is the effect significant?\nA.15. It is significant, p &lt; .05\nQ.16. What are the values for t and p for the significance test for the coefficient?\nA.16. t = 2.296, p = 0.02291\nQ.17. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.one.gen data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.17. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\nA.17.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 165) = 18.08, p &lt; .001, and explains 23% of variance (adjusted R2 = 0.23). Mean accuracy was predicted to be higher given higher scores in health literacy (HLVA estimate = .018, t = 4.52, p &lt; .001), vocabulary knowledge (SHIPLEY estimate = .005, t = 2.96, p &lt; .001), and reading strategy (FACTOR3 estimate = .003, t = 2.65, p = .009).\n\n\n\nTask 12 – Examine the predictors of mean accuracy (mean.acc), now, for the study.two.gen data\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,    Adjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: &lt; 2.2e-16\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:\n\nQ.18. What is the estimate for the coefficient of the effect of the predictor, SHIPLEY, in this model?\nA.18. 0.008397\nQ.19. Is the effect significant?\nA.19. It is significant, p &lt; .05\nQ.20. What are the values for t and p for the significance test for the coefficient?\nA.20. t = 4.533, p = 1.1e-05\nQ.21. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.two.gen data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.21. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\nA.21.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 168) = 31.99, p &lt; .001, and explains 35% of variance (adjusted R2 = 0.35). Mean accuracy was predicted to be higher given higher scores in health literacy (HLVA estimate = .018, t = 4.90, p &lt; .001), vocabulary knowledge (SHIPLEY estimate = .008, t = 4.53, p &lt; .001), and reading strategy (FACTOR3 estimate = .003, t = 2.68, p = .008).\n\n\nQ.22. Are the findings from study.one.gen replicated in study.two.gen?\nhint: Q.22. We can judge if the results in an earlier study are replicated in another study by examining if – here – the linear model estimates are significant in both studies and if the coefficient estimates have the same size and sign in both studies.\nA.22. If you compare the linear model coefficient estimates from both study.one.gen and study.two.gen you can see:\nfirst, the HLVA, SHIPLEY and FACTOR3 estimates are significant in both study.one.gen and study.two.gen;\nsecond, the estimates have the same sign – positive – in both studies.\n\nThis suggests that the results we see in study.one.gen are replicated in study.two.gen.\n\nQ.23. Are there any important differences between the results of the two studies?\nhint: Q.23. You can look at the estimates but you can also use the model prediction plotting code you used before, see example code in 2022-23-PSYC122-w18-how-to.R.\nhint: Q.23. – Let’s focus on comparing the study.one.gen and study.two.gen estimates for the effect of vocabulary knowledge in both models: we can plot model predictions for comparison:\n\nFirst: fit the models – using different names for the different models:\n\nmodel.one &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\nsummary(model.one)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40322 -0.05349  0.01152  0.07128  0.18434 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.302030   0.091257   3.310  0.00115 ** \nHLVA        0.017732   0.003923   4.521 1.17e-05 ***\nSHIPLEY     0.005363   0.002336   2.296  0.02291 *  \nFACTOR3     0.003355   0.001264   2.654  0.00872 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1033 on 165 degrees of freedom\nMultiple R-squared:  0.2474,    Adjusted R-squared:  0.2337 \nF-statistic: 18.08 on 3 and 165 DF,  p-value: 3.423e-10\n\nmodel.two &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model.two)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,    Adjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: &lt; 2.2e-16\n\n\nSecond, create prediction plots for the SHIPLEY effect for each model:\n\ndat.one &lt;- ggpredict(model.one, \"SHIPLEY\")\nplot.one &lt;- plot(dat.one) + labs(title = \"Study One\")\ndat.two &lt;- ggpredict(model.two, \"SHIPLEY\")\nplot.two &lt;- plot(dat.two) + labs(title = \"Study Two\")"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "In Week 17, we aim to further develop skills in visualizing and testing the associations between variables in psychological data.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like the linear model.\nWhen we do these analyses, we need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model;\nwe usually need to decide, is the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nand is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\nfocusing on how we edit ggplot() code to produce professional looking plots.\n\n\n\nI will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this activity, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\n\n\n\n\nTo begin, we set up our environment in R.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nThe data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.gen.\n\n\n\nUse the summary() or head() functions to take a look.\n\nhead(study.one.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNotice that:\n\nhead() will give you the top few rows of any dataset you have read into R.\nsummary() will give you either descriptive statistics for variable columns classified as numeric or will tell you that columns in the dataset are not numeric.\n\nPay attention to what you see, for the numeric variables, in the information about minimum (Min.) and maximum (Max.) values. You will use this informatio later when you engage in data visualization.\n\n\n\n\n\n\n\n\n\n\n\n\nUse ggplot() with geom_histogram().\nWhen we create a plot, we take things step-by-step.\nHere’s an example you have seen before: run the lines of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.one.gen, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.one.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\nNotice that the code works the same whether we have the different bits of code on the same line or in a series of lines.\n\n\n\n\n\n\nWe are going to revise editing:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\n\nWe proceed to revise:\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency count\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40) +\n  geom_vline(xintercept = mean(study.one.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\nIt is often useful to define the limits on the x-axis and on the y-axis:\n\nBecause we want to show the audience where the sample values are distributed compared to where they could be distributed, given the measure.\nThis makes sense e.g. if you want to see the relative age distribution of a sample compared to the population.\nBecause we want plots, shown side by side to be directly comparable.\nAnd because we want to give the audience a more accurate picture of the data.\n\nYou can see ggplot reference information on setting limits here:\nhttps://ggplot2.tidyverse.org/reference/lims.html\nNotice that we used the geom_vline() in:\ngeom_vline(xintercept = mean(study.one.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nto plot a vertical line at the location on the x-axis we define.\n\nWe do this in the steps:\n\ngeom_vline(...) draw a vertical line;\n...xintercept... draw the line so it hits the x-axis (intercepts the x-axis);\n...xintercept = mean(study.one.gen$SHIPLEY... defined by the mean of the variable mean(study.one.gen$SHIPLEY);\n...colour = \"red\", size = 1.5... make the line red and make the line one and a half times thicker than the default line thickness.\n\nSee ggplot() reference information for this new geom is here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRun a chunk of code to make the plot.\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThis plot shows:\n\nthe possible association between x-axis variable SHIPLEY and y-axis variable mean.acc.\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot;\nggplot(data = study.one.gen, ...) with the study.one.gen dataset;\nggplot(...aes(x = SHIPLEY, y = mean.acc)) using two aesthetic mappings\n\n\nx = SHIPLEY map SHIPLEY values to x-axis (horizontal, left to right) positions;\ny = mean.acc map mean.acc values to y-axis (vertical, bottom to top) positions;\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\n\n\n\nWe are going to revise making edits to:\n\nthe appearance of the points using alpha, size, shape, and colour;\nthe colour of the background using theme_bw();\nthe appearance of the labels using labs().\n\nWe are then going to try out some new moves:\n\nSet the x-axis and y-axis limits to the potential minimum-maximum ranges of the variables we plot.\n\nHere, “potential” references the fact that e.g. SHIPLEY scores can start at 0 (a person gets 0 responses correct) and has a maximum of 40 (a person could get all responses correct, for up to 40 items).\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\") \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\nNotice that I set the x-axis limits to the minimum (0) and maximum (40) possible values for the SHIPLEY variable. - I set the y-axis limits to the minimum (0) and maximum (1) possible values for the mean accuracy variable mean.acc.\n\n\n\nIt is generally a good idea to show the minimum value (the origin) for each variable. Not doing this i.e. showing a more narrow slice of the sample range is an easy way to exaggerate the strength of associations or to imply incorrectly the breadth in variation.\nYou can change the transparency (alpha), size, colour and shape of important parts of a plot.\n\nHere, we are changing the appearance of the points.\nBut you can also change the transparency (alpha), size, colour and shape of reference lines added to a plot.\n\nThe ggplot geom_point()reference information is here:\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\nwhere you can see some examples of the edits we have done.\n\nSome useful information about shape options is here:\nhttp://www.cookbook-r.com/Graphs/Shapes_and_line_types/\nSome useful information about colourons is here:\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\n\n\n\n\n\n\n\n\n\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\n\n\n\nFit the model and get a summary of the model statistics.\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\nNotice that we do the linear model in the steps:\n\nmodel &lt;- lm(...) fit the model using lm(...), give the model a name – here, we call it “model”;\n...lm(mean.acc ~ SHIPLEY...) tell R you want a model of the outcome mean.acc predicted (~) by the predictor SHIPLEY;\n...data = study.one.gen) tell R that the variables you name in the formula live in the study.one.gen dataset;\nsummary(model) ask R for a summary of the model you called “model”.\n\nNotice: R has a general formula syntax: outcome ~ predictor or y ~ x\n\nand uses the same format across a number of different functions;\neach time, the left of the tilde symbol ~ is some output or outcome;\nand the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\n\nIf you look at the model summary you can answer the following questions.\n\nQ.5. What is the estimate for the coefficient of the effect of the predictor, SHIPLEY?\nA.5. 0.01050\nQ.6. Is the effect significant?\nA.6. It is significant, p &lt; .05\nQ.7. What are the values for t and p for the significance test for the coefficient?\nA.7. t = 4.585, p = 8.85e-06\nQ.8. What do you conclude is the answer to the research question, given the linear model results?\nA.8. The model slope estimate suggests that as SHIPLEY scores increase so mean.acc scores increase also.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe line will show the model predictions, given the model intercept and effect coefficient estimates.\nFirst fit a model and get a summary: model the relationship between mean.acc and SHIPLEY\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\nQ.9. What is the coefficient estimate for the intercept?\nA.9. 0.44914\nQ.10. What is the coefficient estimate for the slope of SHIPLEY?\nA.10. 0.01050\n\nSecond, use the geom_abline() function to draw the line:\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  geom_abline(intercept = 0.44914, slope = 0.01050, colour = \"red\", size = 1.5) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\nYou can see that what we do is:\n\nadd the geom_abline(...) function;\nand into that function code, we add information about the intercept and the slope which we take from the model summary.\n\nYou can see reference information here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html\nNote that we can get the prediction line drawn for us automatically, as:\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  # geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = `square`)   +\n  geom_smooth(method = \"lm\", colour = \"purple\", alpha = .2, size = 2.5, se = FALSE) +\n  geom_abline(intercept = 0.44914, slope = 0.01050, colour = \"red\", size = 1) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)  \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nHere, I turned the points off by commenting them out, adding # to the start of the line.\nAnd I added geom_smooth(method = \"lm\", ...) to draw a prediction line.\nYou can compare the red prediction line I drew using the model estimates\nwith the purple line I used geom_smooth() to draw automatically to see that they are identical\n\nThis shows you something of what geom_smooth() does. It is very useful:\nhttps://ggplot2.tidyverse.org/reference/geom_smooth.html"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#naming-things",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#naming-things",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "In this activity, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-1-set-up",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-1-set-up",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "To begin, we set up our environment in R.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-2-load-the-data",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "The data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.gen.\n\n\n\nUse the summary() or head() functions to take a look.\n\nhead(study.one.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNotice that:\n\nhead() will give you the top few rows of any dataset you have read into R.\nsummary() will give you either descriptive statistics for variable columns classified as numeric or will tell you that columns in the dataset are not numeric.\n\nPay attention to what you see, for the numeric variables, in the information about minimum (Min.) and maximum (Max.) values. You will use this informatio later when you engage in data visualization."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "Use ggplot() with geom_histogram().\nWhen we create a plot, we take things step-by-step.\nHere’s an example you have seen before: run the lines of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.one.gen, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.one.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\nNotice that the code works the same whether we have the different bits of code on the same line or in a series of lines.\n\n\n\n\n\n\nWe are going to revise editing:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\n\nWe proceed to revise:\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency count\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40) +\n  geom_vline(xintercept = mean(study.one.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\nIt is often useful to define the limits on the x-axis and on the y-axis:\n\nBecause we want to show the audience where the sample values are distributed compared to where they could be distributed, given the measure.\nThis makes sense e.g. if you want to see the relative age distribution of a sample compared to the population.\nBecause we want plots, shown side by side to be directly comparable.\nAnd because we want to give the audience a more accurate picture of the data.\n\nYou can see ggplot reference information on setting limits here:\nhttps://ggplot2.tidyverse.org/reference/lims.html\nNotice that we used the geom_vline() in:\ngeom_vline(xintercept = mean(study.one.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nto plot a vertical line at the location on the x-axis we define.\n\nWe do this in the steps:\n\ngeom_vline(...) draw a vertical line;\n...xintercept... draw the line so it hits the x-axis (intercepts the x-axis);\n...xintercept = mean(study.one.gen$SHIPLEY... defined by the mean of the variable mean(study.one.gen$SHIPLEY);\n...colour = \"red\", size = 1.5... make the line red and make the line one and a half times thicker than the default line thickness.\n\nSee ggplot() reference information for this new geom is here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-4-now-draw-scatterplots-to-examine-associations-between-variables",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-4-now-draw-scatterplots-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "Run a chunk of code to make the plot.\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThis plot shows:\n\nthe possible association between x-axis variable SHIPLEY and y-axis variable mean.acc.\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot;\nggplot(data = study.one.gen, ...) with the study.one.gen dataset;\nggplot(...aes(x = SHIPLEY, y = mean.acc)) using two aesthetic mappings\n\n\nx = SHIPLEY map SHIPLEY values to x-axis (horizontal, left to right) positions;\ny = mean.acc map mean.acc values to y-axis (vertical, bottom to top) positions;\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\n\n\n\nWe are going to revise making edits to:\n\nthe appearance of the points using alpha, size, shape, and colour;\nthe colour of the background using theme_bw();\nthe appearance of the labels using labs().\n\nWe are then going to try out some new moves:\n\nSet the x-axis and y-axis limits to the potential minimum-maximum ranges of the variables we plot.\n\nHere, “potential” references the fact that e.g. SHIPLEY scores can start at 0 (a person gets 0 responses correct) and has a maximum of 40 (a person could get all responses correct, for up to 40 items).\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\") \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\nNotice that I set the x-axis limits to the minimum (0) and maximum (40) possible values for the SHIPLEY variable. - I set the y-axis limits to the minimum (0) and maximum (1) possible values for the mean accuracy variable mean.acc.\n\n\n\nIt is generally a good idea to show the minimum value (the origin) for each variable. Not doing this i.e. showing a more narrow slice of the sample range is an easy way to exaggerate the strength of associations or to imply incorrectly the breadth in variation.\nYou can change the transparency (alpha), size, colour and shape of important parts of a plot.\n\nHere, we are changing the appearance of the points.\nBut you can also change the transparency (alpha), size, colour and shape of reference lines added to a plot.\n\nThe ggplot geom_point()reference information is here:\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\nwhere you can see some examples of the edits we have done.\n\nSome useful information about shape options is here:\nhttp://www.cookbook-r.com/Graphs/Shapes_and_line_types/\nSome useful information about colourons is here:\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-5-use-a-linear-model-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-5-use-a-linear-model-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "One of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\n\n\n\nFit the model and get a summary of the model statistics.\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\nNotice that we do the linear model in the steps:\n\nmodel &lt;- lm(...) fit the model using lm(...), give the model a name – here, we call it “model”;\n...lm(mean.acc ~ SHIPLEY...) tell R you want a model of the outcome mean.acc predicted (~) by the predictor SHIPLEY;\n...data = study.one.gen) tell R that the variables you name in the formula live in the study.one.gen dataset;\nsummary(model) ask R for a summary of the model you called “model”.\n\nNotice: R has a general formula syntax: outcome ~ predictor or y ~ x\n\nand uses the same format across a number of different functions;\neach time, the left of the tilde symbol ~ is some output or outcome;\nand the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\n\nIf you look at the model summary you can answer the following questions.\n\nQ.5. What is the estimate for the coefficient of the effect of the predictor, SHIPLEY?\nA.5. 0.01050\nQ.6. Is the effect significant?\nA.6. It is significant, p &lt; .05\nQ.7. What are the values for t and p for the significance test for the coefficient?\nA.7. t = 4.585, p = 8.85e-06\nQ.8. What do you conclude is the answer to the research question, given the linear model results?\nA.8. The model slope estimate suggests that as SHIPLEY scores increase so mean.acc scores increase also."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-6-use-a-linear-model-to-generate-predictions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-6-use-a-linear-model-to-generate-predictions",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "The line will show the model predictions, given the model intercept and effect coefficient estimates.\nFirst fit a model and get a summary: model the relationship between mean.acc and SHIPLEY\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\nQ.9. What is the coefficient estimate for the intercept?\nA.9. 0.44914\nQ.10. What is the coefficient estimate for the slope of SHIPLEY?\nA.10. 0.01050\n\nSecond, use the geom_abline() function to draw the line:\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  geom_abline(intercept = 0.44914, slope = 0.01050, colour = \"red\", size = 1.5) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\nYou can see that what we do is:\n\nadd the geom_abline(...) function;\nand into that function code, we add information about the intercept and the slope which we take from the model summary.\n\nYou can see reference information here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html\nNote that we can get the prediction line drawn for us automatically, as:\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  # geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = `square`)   +\n  geom_smooth(method = \"lm\", colour = \"purple\", alpha = .2, size = 2.5, se = FALSE) +\n  geom_abline(intercept = 0.44914, slope = 0.01050, colour = \"red\", size = 1) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)  \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nHere, I turned the points off by commenting them out, adding # to the start of the line.\nAnd I added geom_smooth(method = \"lm\", ...) to draw a prediction line.\nYou can compare the red prediction line I drew using the model estimates\nwith the purple line I used geom_smooth() to draw automatically to see that they are identical\n\nThis shows you something of what geom_smooth() does. It is very useful:\nhttps://ggplot2.tidyverse.org/reference/geom_smooth.html"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "In Week 16, we aim to develop skills in visualizing and testing the associations between variables in psychological data.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like correlation and linear models.\nWe will consolidate and extend learning on data visualization:\n\nUse histograms to examine the distributions of variables;\nUse scatterplots to examine the relationships we may observe or predict.\n\n\n\nThis guide is designed to help you work out:\n\nhow to write or edit R code to do things like visualization or analysis;\nhow to identify key information for interpretation and reporting.\n\n\n\n\nI will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nI will split .Rmd scripts by steps, tasks and questions:\n\ndifferent steps for different phases of the analysis workflow;\ndifferent tasks for different things you need to do;\ndifferent questions to examine different ideas or coding challenges\n\n\n\n\nIn this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\n\nNotice that this dataset is different from the data you use to complete the Week 16 lab activity tasks or questions.\n\n\n\nTo begin, we set up our environment in R.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nThe data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.\n\n\n\nUse the summary() or head() functions to take a look\n\nhead(study.one)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNote that head() will give you the top few rows of any dataset you have read into R.\n\nhead(...) is a function, and you put the name of the dataset inside the brackets to view it.\nsummary() will give you either descriptive statistics for variable columns classified as numeric or will tell you that columns in the dataset are not numeric\nsummary() is also a function and, again, you put the name of the dataset inside the brackets to view it\n\nUse the information in the summary view to answer the following questions.\n\nQ.1. What is the mean of mean.acc?\nA.1. 0.8163\nQ.2. What class is the variable study?\nA.2. character\nQ.3. – Does the summary indicate if any variable has missing values (NA)?\nQ.3. – No\n\n\n\n\n\n\n\nstudy.one$study &lt;- as.factor(study.one$study)\n\n\n\n\n\nQ.4. After you have done this, what information does summary() give you about the variable study?\n\n\nsummary(study.one)\n\n participant_ID        mean.acc        mean.self          study    \n Length:169         Min.   :0.3600   Min.   :3.440   studyone:169  \n Class :character   1st Qu.:0.7600   1st Qu.:6.080                 \n Mode  :character   Median :0.8400   Median :7.080                 \n                    Mean   :0.8163   Mean   :6.906                 \n                    3rd Qu.:0.9000   3rd Qu.:7.920                 \n                    Max.   :0.9900   Max.   :9.000                 \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\n\nA.4. We can see the number 169 beside the word studyone: this tells us that there are 169 observations, in the column, each one is a value: the word or character string studyone.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse ggplot() with geom_histogram().\nThe first time we do this, we take things step-by-step.\nHere’s an example: run the line of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.one ...) you tell R you want to make a plot with the study.one data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc\nhere, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\n\n\n\n\nQ.5. Did you get a message in the Console window in R-Studio: what does it say?\nA.5. The message says:\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nQ.6. What does binwidth refer to?\nhint: Q.6. You need to do a search online (e.g., using Google) with the keywords: “ggplot reference geom_histogram”\nA.6. If your search gets you to this page:\n\nhttps://ggplot2.tidyverse.org/reference/geom_histogram.html\n\nThen you will first see a technical definition “The width of the bins. Can be specified as a numeric value …”\nYou will second see examples of the use of the term e.g.\n\nggplot(diamonds, aes(carat)) + geom_histogram(binwidth = 0.01)\n\nIf you run the example code, it will produce a plot. Do it.\n\nIt is a very good idea to get get some experience doing searches online for information about working with data analysis tasks.\n\nYou will find that there is a lot of useful information, written in different ways for people with different levels of expertise\n\nHere, we are interested in working with binwidth in geom_histogram().\n\nThe example gives us a hint at what we can do: we can change the appearance of the bars in the histogram.\nThe bars in the histogram represent how often we observe, in a dataset, a grouping of similar values in a variable.\nLarger (wider) bins count more different values as similar.\nSo increasing binwidth will give you fewer wider bars in a histogram. Check it out.\n\n\n\n\n\n\n\nNote that binwidth needs to take into account the scale of the x variable:\n\nIt won’t work for mean.acc if you make binwidth = 100.\nThe number will need to be something between 0 and 1 (the min and max for mean.acc).\nTry a few different numbers, like this:\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram(binwidth = 0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we break the plot code into steps, it will make it easier to read, and it will make it easier to add edits e.g.\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nIf you run the selection of both lines, you get the code to work.\nHere, we are going to edit:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\n\nTake a look at how the code changes and how the plot changes with each edit to the code.\n\nThe appearance of the bars using binwidth\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2)\n\n\n\n\n\n\n\n\n\nThe colour of the background using theme_bw()\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe appearance of the labels using labs()\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency count\")\n\n\n\n\n\n\n\n\nNotice how each line – except the last one – ends in a +\n\nWhat we are doing is telling R we want this + this + this …\nEach line then adds an extra step.\n\n\n\n\n\nYou can break this code by not adding a + at the end of each bit (except the last line) Try it.\nggplot(data = study.one, aes(x = mean.acc))\n  geom_histogram(binwidth = 0.2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency\")\n\nQ.7. You will get an error message in the console window, orange and grey, if you omit a + like in the example: what is the error message?\nA.7. The message will read:\n\nError: Cannot add ggproto objects together. Did you forget to add this object to a ggplot object?\n\nRun `rlang::last_error()` to see where the error occurred.  \n\nQ.8. Copy and then paste the error message into Google: click on one of the results: do you see any useful information?\nA.8. An explanation of the problem is shown e.g. \n\nhttps://community.rstudio.com/t/could-anybody-help-me-cannot-add-ggproto-objects-together/11271\nR will give you hints – often in red – in error messages if something has gone wrong. This can be a bit frightening but usually you can fix a problem by:\n\nUsing trial and error: try changing things to see what happens;\nCopying the error message into an online search: usually, that will get you to a blog or discussion that is helpful.\n\nThe R community has many millions of people in it. The huge value of the community means that for every problem you encounter, someone else has already met that problem, solved it, and posted a blog online about how to fix it\n\n\n\n\n\n\n\nYou have seen these code moves before, in previous classes: we are strengthening skills by practising coding in different contexts\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.self, y = mean.acc)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nThis plot shows the possible association between x-axis variable mean.self and y-axis variable mean.acc\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot\nggplot(data = study.one, ...) with the study.one dataset\nggplot(...aes(x = mean.self, y = mean.acc)) using two aesthetic mappings\n\n\nx = mean.self map mean.self values to x-axis (horizontal, left to right) positions\ny = mean.acc- map mean.acc values to y-axis (vertical, bottom to top) positions\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\n\n\n\nggplot(data = study.one, aes(y = mean.self, x = mean.acc)) +\n    geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = AGE, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = SHIPLEY, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe appearance of the points using alpha and size;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\nThe appearance of the points using alpha and size\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2) \n\n\n\n\n\n\n\n\n\nThe colour of the background using theme_bw()\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2)  +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe appearance of the labels using labs()\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2)  +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean self rated accuracy\")\n\n\n\n\n\n\n\n\nThe arguments alpha and size can change the appearance of most geometric objects (geoms) in ggplot:\n\nIn the code example, here, we vary the alpha number to change how opaque or transparent the points are\nAnd we vary the size number to vary the size of the points.\n\n\n\n\n\n\n\n\nQ.9. – Can you find the ggplot reference page?\nhint: Q.9 – Do a search with the keywords “ggplot reference geom_point”\nA.9. – It is here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\nQ.10. – Can you change the colour of the points to a colour you like?\nhint: Q.10. – Useful information on colour can be found here:\n\nhttps://r-graphics.org/recipe-colors-setting\nSee also:\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\nA.10. – Here is how you do it:\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"hotpink\")  +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean self rated accuracy\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrevision: make sure you are confident about doing these things\n\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe can answer this question by examining whether mean self-rated accuracy of understanding correlates with mean accuracy of understanding. The logic is that if we can accurately rate our own understanding (from bad to good) then that rating should be associated – should be correlated with how accurately we can actually respond to questions that test that understanding.\n\n\n\n\n\ncor.test(study.one$mean.acc, study.one$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one$mean.acc and study.one$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\nQ.11. – What is r, the correlation coefficient?\nA.11. – r = 0.4863771\nQ.12. – Is the correlation significant?\nA.12. – r is significant\nQ.13. – What are the values for t and p for the significance test for the correlation?\nA.13. – t = 7.1936, p = 2.026e-11\nQ.14. – What do you conclude, given the correlation results?\nhint: Q.6 – Review the scatterplot you drew earlier to examine the shape of the association between these variables\nA.14. – mean.acc and mean.self are positively correlated suggesting that as mean.acc scores increase so also do mean.self scores"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#this-how-to-guide",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#this-how-to-guide",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "This guide is designed to help you work out:\n\nhow to write or edit R code to do things like visualization or analysis;\nhow to identify key information for interpretation and reporting."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#naming-things",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#naming-things",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#we-will-take-things-step-by-step",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#we-will-take-things-step-by-step",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "I will split .Rmd scripts by steps, tasks and questions:\n\ndifferent steps for different phases of the analysis workflow;\ndifferent tasks for different things you need to do;\ndifferent questions to examine different ideas or coding challenges"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "In this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\n\nNotice that this dataset is different from the data you use to complete the Week 16 lab activity tasks or questions."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-1-set-up",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-1-set-up",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "To begin, we set up our environment in R.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-2-load-the-data",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "The data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.\n\n\n\nUse the summary() or head() functions to take a look\n\nhead(study.one)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNote that head() will give you the top few rows of any dataset you have read into R.\n\nhead(...) is a function, and you put the name of the dataset inside the brackets to view it.\nsummary() will give you either descriptive statistics for variable columns classified as numeric or will tell you that columns in the dataset are not numeric\nsummary() is also a function and, again, you put the name of the dataset inside the brackets to view it\n\nUse the information in the summary view to answer the following questions.\n\nQ.1. What is the mean of mean.acc?\nA.1. 0.8163\nQ.2. What class is the variable study?\nA.2. character\nQ.3. – Does the summary indicate if any variable has missing values (NA)?\nQ.3. – No\n\n\n\n\n\n\n\nstudy.one$study &lt;- as.factor(study.one$study)\n\n\n\n\n\nQ.4. After you have done this, what information does summary() give you about the variable study?\n\n\nsummary(study.one)\n\n participant_ID        mean.acc        mean.self          study    \n Length:169         Min.   :0.3600   Min.   :3.440   studyone:169  \n Class :character   1st Qu.:0.7600   1st Qu.:6.080                 \n Mode  :character   Median :0.8400   Median :7.080                 \n                    Mean   :0.8163   Mean   :6.906                 \n                    3rd Qu.:0.9000   3rd Qu.:7.920                 \n                    Max.   :0.9900   Max.   :9.000                 \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\n\nA.4. We can see the number 169 beside the word studyone: this tells us that there are 169 observations, in the column, each one is a value: the word or character string studyone."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#revise-consolidate-what-you-know",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#revise-consolidate-what-you-know",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "Use ggplot() with geom_histogram().\nThe first time we do this, we take things step-by-step.\nHere’s an example: run the line of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.one ...) you tell R you want to make a plot with the study.one data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc\nhere, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\n\n\n\n\nQ.5. Did you get a message in the Console window in R-Studio: what does it say?\nA.5. The message says:\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nQ.6. What does binwidth refer to?\nhint: Q.6. You need to do a search online (e.g., using Google) with the keywords: “ggplot reference geom_histogram”\nA.6. If your search gets you to this page:\n\nhttps://ggplot2.tidyverse.org/reference/geom_histogram.html\n\nThen you will first see a technical definition “The width of the bins. Can be specified as a numeric value …”\nYou will second see examples of the use of the term e.g.\n\nggplot(diamonds, aes(carat)) + geom_histogram(binwidth = 0.01)\n\nIf you run the example code, it will produce a plot. Do it.\n\nIt is a very good idea to get get some experience doing searches online for information about working with data analysis tasks.\n\nYou will find that there is a lot of useful information, written in different ways for people with different levels of expertise\n\nHere, we are interested in working with binwidth in geom_histogram().\n\nThe example gives us a hint at what we can do: we can change the appearance of the bars in the histogram.\nThe bars in the histogram represent how often we observe, in a dataset, a grouping of similar values in a variable.\nLarger (wider) bins count more different values as similar.\nSo increasing binwidth will give you fewer wider bars in a histogram. Check it out.\n\n\n\n\n\n\n\nNote that binwidth needs to take into account the scale of the x variable:\n\nIt won’t work for mean.acc if you make binwidth = 100.\nThe number will need to be something between 0 and 1 (the min and max for mean.acc).\nTry a few different numbers, like this:\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram(binwidth = 0.2)"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#extend-make-some-new-moves",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#extend-make-some-new-moves",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "If we break the plot code into steps, it will make it easier to read, and it will make it easier to add edits e.g.\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nIf you run the selection of both lines, you get the code to work.\nHere, we are going to edit:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\n\nTake a look at how the code changes and how the plot changes with each edit to the code.\n\nThe appearance of the bars using binwidth\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2)\n\n\n\n\n\n\n\n\n\nThe colour of the background using theme_bw()\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe appearance of the labels using labs()\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency count\")\n\n\n\n\n\n\n\n\nNotice how each line – except the last one – ends in a +\n\nWhat we are doing is telling R we want this + this + this …\nEach line then adds an extra step.\n\n\n\n\n\nYou can break this code by not adding a + at the end of each bit (except the last line) Try it.\nggplot(data = study.one, aes(x = mean.acc))\n  geom_histogram(binwidth = 0.2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency\")\n\nQ.7. You will get an error message in the console window, orange and grey, if you omit a + like in the example: what is the error message?\nA.7. The message will read:\n\nError: Cannot add ggproto objects together. Did you forget to add this object to a ggplot object?\n\nRun `rlang::last_error()` to see where the error occurred.  \n\nQ.8. Copy and then paste the error message into Google: click on one of the results: do you see any useful information?\nA.8. An explanation of the problem is shown e.g. \n\nhttps://community.rstudio.com/t/could-anybody-help-me-cannot-add-ggproto-objects-together/11271\nR will give you hints – often in red – in error messages if something has gone wrong. This can be a bit frightening but usually you can fix a problem by:\n\nUsing trial and error: try changing things to see what happens;\nCopying the error message into an online search: usually, that will get you to a blog or discussion that is helpful.\n\nThe R community has many millions of people in it. The huge value of the community means that for every problem you encounter, someone else has already met that problem, solved it, and posted a blog online about how to fix it"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#revision-make-sure-you-are-confident-about-doing-these-things",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#revision-make-sure-you-are-confident-about-doing-these-things",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "You have seen these code moves before, in previous classes: we are strengthening skills by practising coding in different contexts\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.self, y = mean.acc)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nThis plot shows the possible association between x-axis variable mean.self and y-axis variable mean.acc\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot\nggplot(data = study.one, ...) with the study.one dataset\nggplot(...aes(x = mean.self, y = mean.acc)) using two aesthetic mappings\n\n\nx = mean.self map mean.self values to x-axis (horizontal, left to right) positions\ny = mean.acc- map mean.acc values to y-axis (vertical, bottom to top) positions\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\n\n\n\nggplot(data = study.one, aes(y = mean.self, x = mean.acc)) +\n    geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = AGE, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = SHIPLEY, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe appearance of the points using alpha and size;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\nThe appearance of the points using alpha and size\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2) \n\n\n\n\n\n\n\n\n\nThe colour of the background using theme_bw()\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2)  +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe appearance of the labels using labs()\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2)  +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean self rated accuracy\")\n\n\n\n\n\n\n\n\nThe arguments alpha and size can change the appearance of most geometric objects (geoms) in ggplot:\n\nIn the code example, here, we vary the alpha number to change how opaque or transparent the points are\nAnd we vary the size number to vary the size of the points.\n\n\n\n\n\n\n\n\nQ.9. – Can you find the ggplot reference page?\nhint: Q.9 – Do a search with the keywords “ggplot reference geom_point”\nA.9. – It is here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\nQ.10. – Can you change the colour of the points to a colour you like?\nhint: Q.10. – Useful information on colour can be found here:\n\nhttps://r-graphics.org/recipe-colors-setting\nSee also:\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\nA.10. – Here is how you do it:\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"hotpink\")  +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean self rated accuracy\")"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-6-use-correlation-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-6-use-correlation-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "revision: make sure you are confident about doing these things\n\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe can answer this question by examining whether mean self-rated accuracy of understanding correlates with mean accuracy of understanding. The logic is that if we can accurately rate our own understanding (from bad to good) then that rating should be associated – should be correlated with how accurately we can actually respond to questions that test that understanding.\n\n\n\n\n\ncor.test(study.one$mean.acc, study.one$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one$mean.acc and study.one$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\nQ.11. – What is r, the correlation coefficient?\nA.11. – r = 0.4863771\nQ.12. – Is the correlation significant?\nA.12. – r is significant\nQ.13. – What are the values for t and p for the significance test for the correlation?\nA.13. – t = 7.1936, p = 2.026e-11\nQ.14. – What do you conclude, given the correlation results?\nhint: Q.6 – Review the scatterplot you drew earlier to examine the shape of the association between these variables\nA.14. – mean.acc and mean.self are positively correlated suggesting that as mean.acc scores increase so also do mean.self scores"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "",
    "text": "In Week 18, we aim to further develop skills in working with the linear model.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like the linear model.\nWhen we do these analyses, we need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model.\n\nWe usually need to decide:\n\nis the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nand is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\nfocusing on how we edit ggplot() code to produce professional looking plots.\n\n\n\nI will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#naming-things",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#naming-things",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "",
    "text": "In this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-1-set-up",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-1-set-up",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"ggeffects\")\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-2-load-the-data",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")\n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look.\n\nhead(study.one.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nEven though you have done this before, you will want to do it again, here, and pay particular attention to:\n\nsummary information about the numeric variables;\nsummary information about variables of class: character."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-3-use-a-linear-model-to-to-answer-the-research-questions-one-predictor",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-3-use-a-linear-model-to-to-answer-the-research-questions-one-predictor",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 3: Use a linear model to to answer the research questions – one predictor",
    "text": "Step 3: Use a linear model to to answer the research questions – one predictor\n\nRevise: Practice to strengthen skills\nWe start by revising how to use lm() with one predictor.\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\nTask 5 – Examine the relation between outcome mean accuracy (mean.acc) and health literacy (HLVA)\n\n\nHint: Task 5\nWe can use lm() to estimate whether variation in health literacy (HLVA) predicts outcome mean accuracy (mean.acc) of understanding.\n\nmodel &lt;- lm(mean.acc ~ HLVA, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40848 -0.05304  0.01880  0.07608  0.19968 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.61399    0.03387  18.128  &lt; 2e-16 ***\nHLVA         0.02272    0.00369   6.158 5.31e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1068 on 167 degrees of freedom\nMultiple R-squared:  0.1851,    Adjusted R-squared:  0.1802 \nF-statistic: 37.92 on 1 and 167 DF,  p-value: 5.307e-09\n\n\nIn R analysis code, we write method(outcome ~ predictor) so:\nlm(mean.acc ~ HLVA, data = study.one.gen)\n\ngets us an analysis of whether or how HLVA predicts variation in outcome mean.acc.\n\nIf you look at the model summary you can answer the following questions.\n\nQuestions: Task 5\n\nQ.1. What is the estimate for the coefficient of the effect of the predictor, HLVA?\nA.1. 0.02272\nQ.2. Is the effect significant?\nA.2. It is significant, p &lt; .05\nQ.3. What are the values for t and p for the significance test for the coefficient?\nA.3. t = 6.158, p = 5.31e-09\nQ.4. What do you conclude is the answer to the research question, given the linear model results?\nA.4. The model slope estimate suggests that as HLVA scores increase so also do mean.acc scores\nQ.5. What is the F-statistic for the regression? Report F, DF and the p-value.\nA.5. F-statistic: 37.92 on 1 and 167 DF, p-value: 5.307e-09\nQ.6. Is the regression significant?\nA.6. Yes: the regression is significant.\nQ.7. What is the Adjusted R-squared?\nA.7. Adjusted R-squared: 0.1802\nQ.8. Explain in words what this R-squared value indicates?\nA.8. The R-squared suggests that 18% of outcome variance can be explained by the model"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-4-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-4-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 4: Use a linear model to to answer the research questions – multiple predictors",
    "text": "Step 4: Use a linear model to to answer the research questions – multiple predictors\n\nIntroduce: make some new moves\n\n\nTask 6 – Examine the relation between outcome mean accuracy (mean.acc) and multiple predictors\nHere, the predictors will include:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\nHint: Task 6\nWe use lm(), as before, but now specify each variable listed here by variable name\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40322 -0.05349  0.01152  0.07128  0.18434 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.302030   0.091257   3.310  0.00115 ** \nHLVA        0.017732   0.003923   4.521 1.17e-05 ***\nSHIPLEY     0.005363   0.002336   2.296  0.02291 *  \nFACTOR3     0.003355   0.001264   2.654  0.00872 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1033 on 165 degrees of freedom\nMultiple R-squared:  0.2474,    Adjusted R-squared:  0.2337 \nF-statistic: 18.08 on 3 and 165 DF,  p-value: 3.423e-10\n\n\nNotice that we do the linear model in the steps:\n\nmodel &lt;- lm(...) fit the model using lm(...), giving the model a name; here, we call it model;\n...lm(mean.acc ~ HLVA...) tell R you want a model of the outcome mean.acc predicted (~) by the predictors listed, HLVA, SHIPLEY, and FACTOR3.\n...data = study.one.gen) tell R that the variables you name in the formula are in the study.one.gen dataset.\nsummary(model) ask R for a summary of the model you called model.\n\nNotice: that we use the variable names as they appear in the dataset, and that each predictor variable is separated from the next by a plus (+) sign.\nNotice: R has a general formula syntax: outcome ~ predictor or y ~ x and uses the same format across a number of different analysis functions.\n\nEach time, the left of the tilde symbol ~ is some output or outcome and the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\nQuestions: Task 6\nIf you look at the model summary you can answer the following questions\nQ.9. What is the estimate for the coefficient of the effect of the predictor HLVA in this model?\nA.9. 0.017732\nQ.10. Is the effect significant?\nA.10. It is significant, p &lt; .05\nQ.11. What are the values for t and p for the significance test for the coefficient?\nA.11. t = 4.521, p = 1.17e-05\nQ.12. What do you conclude is the answer to the research question, given the linear model results?\nA.12. The model slope estimate 0.017732 suggests that as HLVA scores increase so also do mean.acc scores.\nQ.13. How is the coefficient estimate for the HLVA slope similar or different, comparing this model with multiple predictors to the previous model with one predictor?\nA.13. It can be seen that the HLVA estimate in the two models is different in that it is a bit smaller in the model with multiple predictors compared to the model with one predictor. The HLVA estimate is similar in that it remains positive, it is about the same size.\nNotice that:-\n\nThe estimate of the coefficient of any one predictor can be expected to vary depending on the presence of other predictors.\nThis is one reason why we need to be transparent about why we choose to use the predictors we include in our model.\n\nQ.14. Can you report the estimated effect of SHIPLEY (the measure of vocabulary) using the kind of language you are shown in lecture week 18?\nA.14. The answer to the question can be written like this:\n\nThe effect of vocabulary knowledge (SHIPLEY) on mean accuracy of understanding is significant (estimate = 0.005, t = 2.296, p &lt; .001) indicating that increasing vocabulary knowledge is associated with increasing accuracy of understanding.\n\nQ.15. Can you report the model and the model fit statistics?\nA.15. The answer to the question can be written like this:\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 165) = 18.08, p&lt; .001, and explains 23% of variance (adjusted R2 = 0.23)."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-5-plot-predictions-from-linear-models-with-multiple-predictors",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-5-plot-predictions-from-linear-models-with-multiple-predictors",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 5: Plot predictions from linear models with multiple predictors",
    "text": "Step 5: Plot predictions from linear models with multiple predictors\n\nIntroduce: make some new moves\n\n\nTask 7 – Plot linear model predictions for one of the predictors\n\nHint: Task 7\nPreviously, we used geom_abline(), specifying intercept and slope estimates, to draw model predictions.\nHere, we use functions that are very helpful when we need to plot model predictions, for models where we have multiple predictors\nWe do this in four steps:\n\nWe first fit a linear model of the outcome, given our predictors.\nWe save information about the model.\nWe use the ggpredict() function from the {ggeffects} library to take the information about the model and create a set of predictions we can use for plotting.\nWe plot the model prediction plots.\n\nThese steps proceed as follows:\n\nWe first fit a linear model of the outcome, given our predictors.\n\nLike this:\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nThe code involves these key bits:\n\nmodel &lt;- lm(...) we fit the model using lm(...), giving the model a name; here, we call it model.\n...lm(mean.acc ~ HLVA...) we tell R we want a model of the outcome mean.acc predicted (~) by the predictors HLVA, SHIPLEY, and FACTOR3.\n\nNotice: when we use lm() to fit the model, R creates a set of information about the model, including estimates.\nWe give that set of information a name model, and we use that name, next, to access that information in the plotting step.\n\nWe use the ggpredict() function from the {ggeffects} library to take the information about the model and create a set of predictions we can use for plotting.\n\n\ndat &lt;- ggpredict(model, \"HLVA\")\n\nNotice:\n\ndat &lt;- ggpredict(...) asks R to create a set of predictions, and we give that set of predictions a name dat.\n... ggpredict(model, \"HLVA\") tells R what model information it should use (from model) and which predictor variable we need predictions for \"HLVA\".\n\n\nWe plot the model predictions with:\n\n\nplot(dat)\n\n\n\n\n\n\n\n\n\n\n\nTask 8 – Now produce plots that show the predictions for all the predictor variables in the model"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-6-now-draw-boxplots-to-examine-associations-between-variables",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-6-now-draw-boxplots-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 6: Now draw boxplots to examine associations between variables",
    "text": "Step 6: Now draw boxplots to examine associations between variables\n\nConsolidation: practice to strengthen skills\n\n\nTask 9 – Create boxplots to examine the association between a continuous numeric outcome variable like mean.acc and a categorical variable like ETHNICITY\nHere, we use geom_boxplot().\n\nHint: Task 9 – We can see where variables are not numeric using summary()\nThe boxplot can be produced using code like this:\n\nggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc)) +\n  geom_boxplot() +\n  theme_bw() +\n  labs(x = \"Ethnicity, ONS categories\", \n       y = \"Mean accuracy of understanding ('mean.acc')\") +\n  ylim(0, 1.1)\n\n\n\n\n\n\n\n\nThe plotting code works bit-by-bit, as described following.\n\nggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc)) defines two aesthetic mappings:\n\n\nx = ETHNICITY, the x variable has to be categorical or nominal, a factor like ETHNICITY with different levels.\ny = mean.acc, the y variable has to be numeric, a set of numbers like mean.acc with different values.\n\n\ngeom_boxplot() then uses that information about category (x = ...) and outcome (y = ...) to draw a box to represent the distribution of outcome scores for each group.\n\nNotice that when you draw the plot:\n\nThe middle line in each box represents the median outcome (here mean.acc) score for each group.\nThe shape of the box represents the distribution or spread of scores.\nThe top of the box represents the 75th percentile, what the score is for the people who are at the top 75% of the sample.\nThe bottom of the box represents the 25th percentile, what the score is for the people at the 25% level of outcomes for the sample.\n\nMore information about boxplots can be found here:\nhttps://ggplot2.tidyverse.org/reference/geom_boxplot.html\nHere is an edit of the plot to make it a bit more effective:\n\nggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc)) +\n  geom_jitter(alpha = .5) +\n  geom_boxplot(outlier.shape = NA, colour = \"red\", alpha = .1) +\n  theme_bw() +\n  labs(x = \"Ethnicity, ONS categories\", \n       y = \"Mean accuracy of understanding ('mean.acc')\") +\n  ylim(0, 1.1)\n\n\n\n\n\n\n\n\nThe plot shows:\n\nboxplots to indicate the average (median) and spread (percentiles) in mean.acc scores for each group;\nplus, with points, individual mean.acc scores for the people in each group.\n\n\n\nWhy are we learning how to do this?\nDrawing plots which show both summaries (like boxplots) and raw data (scores as points) is a common (advanced) professional visualization technique.\n\nIt is effective because these kinds of plots help you to see the pattern or trend and the nature of the underlying sample.\n\nNow you can use the plots to answer questions like the following\n\n\nQuestions: Task 9\nQ.16. What do you notice about the distribution of scores in different groups?\nA.16. The average accuracy of understanding appears to be similar between groups.\nQ.17. Does anything in the plots give you reason to question the nature of the participant sample?\nA.17. This is a leading question: there is plenty in the plots to cause concern.\n\nThe scatter of points shows that we have many more White participants in the sample than participants from other ethnicities.\nBecause we have very few people in the study from ethnic minority (often classed as BAME) groups, we might be concerned about whether the results from our models are representative of what you would see in these groups, or whether the results are representative of the wider population in general.\n\nQ.18. Can you use the ggplot() reference information – see the webpage link – to see how and why I made the code edits I did?\nA.18. You can see example code for each edit in the webpage.\nQ.19. Do you understand what geom_jitter() is doing? – and why I would use it?\nA.19. What the function does, and why I would use it can be found in the reference information webpage:\nhttps://ggplot2.tidyverse.org/reference/geom_jitter.html"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-6-estimate-the-effects-of-factors-as-well-as-numeric-variables",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-6-estimate-the-effects-of-factors-as-well-as-numeric-variables",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 6: Estimate the effects of factors as well as numeric variables",
    "text": "Step 6: Estimate the effects of factors as well as numeric variables\n\nIntroduce: make some new moves\nWe have not yet included any categorical or nominal variables as predictors but we can, and should:\n\nlm() can cope with any kind of variable as a predictor.\n\n\n\nTask 10 – Fit a linear model including both numeric variables and categorical variables as predictors\n\nHint: Task 12\nWe can inspect the data to check what variables are categorical or nominal variables – factors – using summary().\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNotice that R shows categorical variables in the summary as having: Class: character.\n\nQ.20. Can you report the estimated effect of ETHNICITY: differences in outcome for people in different self-reported ethnicity groups?\nHint: Q.20. Include the factor ETHNICITY as a predictor:\n\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n            data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n    data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40261 -0.05322  0.01168  0.07124  0.18391 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     0.302764   0.095806   3.160  0.00188 ** \nHLVA            0.017391   0.003980   4.370 2.22e-05 ***\nSHIPLEY         0.005249   0.002380   2.206  0.02882 *  \nFACTOR3         0.003495   0.001289   2.711  0.00744 ** \nETHNICITYBlack  0.016600   0.065962   0.252  0.80163    \nETHNICITYMixed -0.016080   0.048371  -0.332  0.74000    \nETHNICITYOther  0.083201   0.108382   0.768  0.44381    \nETHNICITYWhite -0.001006   0.028308  -0.036  0.97168    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1043 on 161 degrees of freedom\nMultiple R-squared:  0.2514,    Adjusted R-squared:  0.2188 \nF-statistic: 7.723 on 7 and 161 DF,  p-value: 4.841e-08\n\n\n\nA.20. The effect of ethnicity (ETHNICITY) on mean accuracy of understanding is not significant.\nQ.21. Can you report the model and the model fit statistics?\nA.21. You can report the model and model statistics like this.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), vocabulary (SHIPLEY), reading strategy (FACTOR3), and ethnicity (ETHNICITY) as predictors. The model is significant overall, with F(7, 161) = 7.72, p&lt; .001, and explains 22% of variance (adjusted R2 = 0.22).\n\n\nQ.22. What changes, when you compare the models with versus without ETHNICITY?\nA.22. If you compare the summaries, for the last two models, you can see that the proportion of variance explained, R-sq, decreases slightly to 22% (Adjusted R-squared = 0.2188), suggesting that adding ETHNICITY as a predictor does not help to predict response accuracy in tests of comprehension of health advice.\n\n\n\nWhy are we learning how to do this?\nR handles factors, by default, by picking one level (here, Asian) as the reference level (or baseline) and comparing outcomes to that baseline, for each other factor level (here, Other).\n\nThus, in this model, the effect of ETHNICITY is estimated as the difference in mean.acc outcome for Asian compared to participants coded as Black, Mixed, Other, White (BAME).\n\nThere are different ways to code factors for analysis. You will learn about these in second year classes.\n\n\n\nTask 13 – Fit a linear model including both numeric variables and categorical variables as predictors, and then plot the predicted effect of the factor (the categorical variable)\n\nHint: Task 12 – We first fit the model, including ETHNICITY, then use the ggpredict() function to get the predictions\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n            data = study.one.gen)\n\ndat &lt;- ggpredict(model, \"ETHNICITY\")\n\nSome of the focal terms are of type `character`. This may lead to\n  unexpected results. It is recommended to convert these variables to\n  factors before fitting the model.\n  The following variables are of type character: `ETHNICITY`\n\nplot(dat)\n\n\n\n\n\n\n\n\n\nQ.23. Compare the model summary and the prediction plot: what do they show you about the effect of ETHNICITY?\nA.23. If you compare the summary and the plot you can see that:\nthere are some differences in accuracy between people coded as belonging to different ethnic groups;\nbut these differences are very small and are not significant.\n\nNotice that the points in the plot represent model predictions of the average mean.acc accuracy of response for each group.\n\nThe vertical lines on the point represent uncertainty about those estimates and that uncertainty can be seen to be substantial.\nLonger lines represent more uncertainty."
  }
]