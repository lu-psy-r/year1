[
  {
    "objectID": "PSYC122/Week16.html",
    "href": "PSYC122/Week16.html",
    "title": "5. Week 16 – Hypotheses, associations",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.",
    "crumbs": [
      "Home",
      "PSYC122",
      "5. Week 16 -- Hypotheses, associations"
    ]
  },
  {
    "objectID": "PSYC122/Week16.html#sec-wk16-introduction",
    "href": "PSYC122/Week16.html#sec-wk16-introduction",
    "title": "5. Week 16 – Hypotheses, associations",
    "section": "Week 16: Introduction",
    "text": "Week 16: Introduction\nWelcome to your overview of our work together.\nWe will complete four classes in weeks 16-19.\n\n\n\n\n\n\nTip\n\n\n\nPutting it all together\n\nThese classes are designed to help you to revise and to put into practice some of the key ideas and skills you have been developing in the first year research methods modules PSYC121, PSYC123 and PSYC124.\nWe will do this in the context of a live research project with potential real world impacts: the Clearly Understood project.\n\n\n\nWe will present our PSYC122 lessons in the context of a real research project because we think that this context will help you to make sense of the data, and it will help you to see why we ask you to practice the skills we are teaching.\nWe will be revisiting some of the ideas and techniques you have seen introduced in previous classes. This will give you the opportunity to revise and consolidate your learning. We will extend your development with some new ideas, to help you to strengthen your skills.\nWe will observe real scientific findings using the data we will collect together. These new findings will ultimately show health providers how to communicate their advice more effectively.\n\nOur learning goals\n\n\n\n\n\n\nTip\n\n\n\nIn Week 16, we will ask you to do three things.\n\nFirst we will ask you to do a pre-lab activity that involves completing a survey.\nSecond we will ask you to do a set of practical tasks in the lab activity that are designed to consolidate your learning on data visualization.\nThird we will ask you to think critically about potential associations between measures of individual differences and measures of how well people understand health information.\n\n\n\nCompleting the survey will help you to understand the numbers you will be working with in the activities: where they come from, and what they show about the people tested. It will also help to teach you about the challenges of measurement: this is one of the key challenges in psychological science.\nWe will build practice in using correlations to test predictions about associations and thus to answer research questions.",
    "crumbs": [
      "Home",
      "PSYC122",
      "5. Week 16 -- Hypotheses, associations"
    ]
  },
  {
    "objectID": "PSYC122/Week16.html#sec-wk16-lectures",
    "href": "PSYC122/Week16.html#sec-wk16-lectures",
    "title": "5. Week 16 – Hypotheses, associations",
    "section": "Lectures",
    "text": "Lectures\n\n\n\n\n\n\nTip\n\n\n\nBefore you go on to the activities, watch the lectures:\n\n\nThe lecture for this week is presented in four short parts. You can view video recordings of the lectures using Panopto, by clicking on the links shown following.\n\nOverview (15 minutes): What we are doing in weeks 16-20, and how and why you will develop your critical thinking skills.\n\n\n\nThinking critically (11 minutes): A summary of the health communication project, and the ideas we assume to develop our hypotheses.\n\n\n\nThinking about associations in research (22 minutes): How we visualize and think about distributions and associations.\n\n\n\nInterpreting, reporting and visualizing correlations (11 minutes): How we use R to estimate and test correlations.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe slides presented in the videos can be downloaded either as a web page or as a Word document.\n\n\n\nThe slides exactly as presented (36 MB).\nThe slides converted to a Word .docx (24 MB).\n\nYou can download the web page .html file and click on it to open it in any browser (e.g., Chrome, Edge or Safari). The slide images are high quality so the file is quite big and may take a few seconds to download.\nYou can download the .docx file and click on it to open it as a Word document that you can then edit. Converting the slides to a .docx distorts some images but the benefit of the conversion is that it makes it easier for you to add your notes.",
    "crumbs": [
      "Home",
      "PSYC122",
      "5. Week 16 -- Hypotheses, associations"
    ]
  },
  {
    "objectID": "PSYC122/Week16.html#reading-links-to-other-classes",
    "href": "PSYC122/Week16.html#reading-links-to-other-classes",
    "title": "5. Week 16 – Hypotheses, associations",
    "section": "Reading: Links to other classes",
    "text": "Reading: Links to other classes\nWe do not provide further reading for this class but you will find it helpful to revise some of the key ideas you have been learning about PSYC122 and in other modules.\n\nThe lectures in PSYC123 on: the scientific method; reliability and validity; experimental design, especially between-subjects studies; hypothesis testing; and precise hypotheses.\nThe lecture in PSYC122 on correlations.",
    "crumbs": [
      "Home",
      "PSYC122",
      "5. Week 16 -- Hypotheses, associations"
    ]
  },
  {
    "objectID": "PSYC122/Week16.html#sec-wk16-prelab-activities",
    "href": "PSYC122/Week16.html#sec-wk16-prelab-activities",
    "title": "5. Week 16 – Hypotheses, associations",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\n\nPre-lab activity 1\nIn weeks 16-19, we will be working together on a research project to investigate how people vary in their response to health advice.\nCompleting the project involves collecting responses from PSYC122 students: you.\nTo enter your responses, we invite you to complete a short survey.\nComplete the survey by clicking on the link here\n\n\n\n\n\n\nTip\n\n\n\nIn our week 19 class activity, we will analyze the data we collect here.\n\n\nThe survey should take about 20 minutes to complete.\nTaking part in the survey is completely voluntary. You can stop at any time without completing the survey if you do not want to finish it. If you do not want to do the survey, you can do an alternative activity (see below).\nAll responses will be recorded completely anonymously.\n\n\nPre-lab activity alternative option\nIf you do not want to complete the survey, we invite you to read the pre-registered research plan for the PSYC122 health advice research project.\nRead the project pre-registration",
    "crumbs": [
      "Home",
      "PSYC122",
      "5. Week 16 -- Hypotheses, associations"
    ]
  },
  {
    "objectID": "PSYC122/Week16.html#sec-wk16-lab-activities",
    "href": "PSYC122/Week16.html#sec-wk16-lab-activities",
    "title": "5. Week 16 – Hypotheses, associations",
    "section": "Lab activities",
    "text": "Lab activities\n\nIntroduction\nWe will do our practical lab work to develop your skills in the context of the Clearly Understood project.\n\nOur focus will be on what makes it easy or difficult for people to understand written health information.\n\nWhy are we doing this?\nWe encounter written health information all the time: in warnings signs, on medication labels, in clinics when we go to see the doctor, and online when we research things we are worried about. It is not always easy to understand this information. The problem is that it is unclear how health information should be communicated: even this is important, there is not much evidence.\nAs psychologists, we can help.\n\n\n\n\n\n\nImportant\n\n\n\nIn these classes, we will complete a research project to answer the research questions:\n\nWhat person attributes predict success in understanding health information?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\n\n\n\nGet ready\n\nDownload the data\nClick on the link: 122_week16_for_students.zip to download the data files folder. Then upload the contents to the new folder you created in RStudio Server.\nThe downloadable .zip folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand the R Markdown .Rmd:\n\n2023-24-PSYC122-w16-how-to.Rmd\n\nIf you can’t upload these files to the server – this affects some students – you can use some code to get R to do it for you: uncover the code box below to reveal the code to do this.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nYou can use the code below to directly download the file you need in this lab activity to the server.\nRemember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\nGet the study-one-general-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week16/study-one-general-participants.csv?raw=true\", destfile = \"study-one-general-participants.csv\")\n\n\nGet the study-two-general-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week16/study-two-general-participants.csv?raw=true\", destfile = \"study-two-general-participants.csv\")\n\n\nGet the 2023-24-PSYC122-w16-how-to.Rmd how-to guide\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week16/2023-24-PSYC122-w16-how-to.Rmd?raw=true\", destfile = \"2023-24-PSYC122-w16-how-to.Rmd\")\n\n\n\n\n\n\nCheck: What is in the data files?\nEach of the data files we will work with has a similar structure, as you can see in this extract.\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\n\n\n\n\n\nYou can use the scroll bar at the bottom of the data window to view different columns.\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n\n\n\n\nTip\n\n\n\nIt is always a good idea to view the dataset – click on the name of the dataset in the R-Studio Environment window, and check out the columns, scroll through the rows – to get a sense of what you are working with.\n\n\n\n\n\nLab activity 1: Work with the How-to guide\nThe how-to guide comprises an .Rmd file:\n\n2023-24-PSYC122-w16-how-to.Rmd\n\nIt is full of advice and example code.\nThe code in the how-to guide was written to work with the data file:\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\nTip\n\n\n\nWe show you how to do everything you need to do in the lab activity (Section 5.4, next) in the how-to guide.\n\nStart by looking at the how-to guide to understand what steps you need to follow in the lab activity.\n\n\n\nWe will take things step-by-step.\nWe split .Rmd scripts by steps, tasks and questions:\n\ndifferent steps for different phases of the analysis workflow;\ndifferent tasks for different things you need to do;\ndifferent questions to examine different ideas or coding challenges\n\n\n\n\n\n\n\nTip\n\n\n\n\nMake sure you start at the top of the .Rmd file and work your way, in order, through each task.\nComplete each task before you move on to the next task.\n\n\n\nIn the activity Section 5.4, we are going to work through the following tasks.\nStep 1: Set-up\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\n\nStep 2: Load the data\n\nRead in the data file – using read_csv()\nInspect the data – using head() and summary()\nChange the type classification of a variable in the data – using as.factor()\n\nStep 3: Use histograms to examine the distributions of variables\n\nDraw histograms to examine the distributions of variables – using ggplot() and geom_histogram()\n\nStep 4: Edit your plots to make them look good\n\nEdit the appearance of one histogram plot step-by-step\n\nStep 5: Now draw scatterplots to examine associations between variables\n\nDraw scatterplots to examine the associations between some variables – using ggplot() and geom_point()\nDraw scatterplots to examine different variables\n\nStep 6: Edit the scatterplots to make them look good\n\nEdit the appearance of a plot step-by-step\n\nStep 7: Use correlation to to answer the research questions\n\nExamine associations between variables using correlation.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are unsure about what you need to do, look at the advice in 2023-24-PSYC122-w16-how-to.Rmd on how to do the tasks, with examples on how to write the code.\n\n\nYou will see that you can match a task in the activity Section 5.4 to the same task in the how-to guide. The how-to shows you what function you need and how you should write the function code.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in modern psychological science.\n\n\n\n\n\n\nWarning\n\n\n\nDon’t forget: You will need to change the names of the dataset or the variables to complete the tasks in the activity.\n\n\n\n\nLab activity 2\n\n\nOK: now let’s do it!\nIn the following, we will guide you through the tasks and questions step by step. You will learn more if you follow this advice:\n\n\n\n\n\n\nTip\n\n\n\n\nWe will hide the code to do some tasks behind a drop-down button. Try to write and run the code for yourself first.\nWe won’t always give you the code required to do something: this gives you the chance to check what you have learned by trying out your code without the answer in front of you.\nWe will not at first give you the answers to questions about the data or about the results of analyses.\nAn answers version of the workbook will be provided after the last lab session (check the answers then in Section 6) so that you can check whether your independent work has been correct.\n\n\n\n\nQuestions\n\n\nStep 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"tidyverse\")\n\n\n\n\nStep 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file for the workbook is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")\n\n\n\n\nWhen you code this, you can choose your own file name, but be sure to give the data object you create a distinct name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nsummary(study.two.gen)\n\n\n\n\n\nQ.1. What is the median of AGE?\n\n\n\nQ.2. What class is the variable ETHNICITY?\n\n\n\nQ.3. Does the summary indicate if any variable has missing values (NAs)?\n\n\n\n\nTask 5 – Change the class or type of the variable ETHNICITY to factor\nYou can use the as.factor() function you have used before: how do you write the code for these data? Try it for yourself before revealing the code.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nstudy.two.gen$ETHNICITY &lt;- as.factor(study.two.gen$ETHNICITY)\n\n\n\n\n\nQ.4. After you have done this, what information does summary() give you about the variable ETHNICITY?\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nsummary(study.two.gen)\n\n\n\n\n\n\n\n\n\n\n\n\nStep 3: Use histograms to examine the distributions of variables\n\nTask 6 – Draw histograms to examine the distributions of variables\n\n\nHint: Task 6\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse ggplot() with geom_histogram().\nThe first time we do this, we can take things one step at a time.\nHere’s an example: run the line of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + geom_histogram()\n\nThese are the steps, set out one step at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.two.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\n\n\n\n\n\nQuestions: Task 6\n\nQ.5. Did you get a message in the Console window in R-Studio: what does it say?\n\n\n\n\nQ.6. Draw two different histograms to examine the distributions of two different variables: SHIPLEY and HLVA\n\nTry it for yourself before revealing the code: can you do it?\nClick on the button to see the code for drawing the histogram of SHIPLEY scores.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + geom_histogram()\n\n\n\n\nFigure 1 shows you what you are aiming to produce for the second plot: a histogram of HLVA scores? What code do you need to write?\n\n\n\n\n\n\n\n\nFigure 1: Histogram showing the distribution of HLVA scores in the Study Two dataset\n\n\n\n\n\n\nQ.7. Now edit the code for both plots: can you change the binwidth in geom_histogram() to make the bars wider?\n\nIf you are going to change binwidth the number you use needs to be a number larger than the minimum and smaller than the maximum for the variable.\nRemember, min and max values are given for each numeric variable in summary().\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + geom_histogram(binwidth = 2)\nggplot(data = study.two.gen, aes(x = HLVA)) + geom_histogram(binwidth = 2)\n\n\n\n\nWe adjust binwidth typically to improve the appearance of the plot.\nThis is a bit subjective so try different numbers and see how you feel about the changes in appearance.\nWe want histograms that show us enough detail about the frequency of occurrence of groupings (bins) of values for each variable.\nBut we do not want histograms that show us so much detail it is difficult to see the pattern for the distribution.\n\nQ.8. – How would you describe the distributions – in a sentence – of the distributions of the SHIPLEY and HLVA variable values for our sample?\n\n\n\n\n\n\nStep 4: Edit your plots to make them look good\n\nTask 7 – Edit the appearance of a histogram plot for one numeric variable\nNote that ggplot() code does not all have to be on the same line.\nYou can create a new plot for each edit so you can see what difference your edits make.\n\nQ.9. Edit the appearance of the bars using binwidth\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) +\n  geom_histogram(binwidth = 2)\n\n\n\n\n\nQ.10. Edit the colour of the background using theme_bw()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) +\n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\nQ.11. Edit the appearance of the labels using labs()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) +\n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"count\")\n\n\n\n\nNotice how, if you are doing edits in steps, one line at a time, each line in your code except the last one ends in a +.\nWhat we are doing is telling R we want this + and this + and this … Each line then adds an extra step.\nYou can break this code by not adding a + at the end of each bit (except the last line).\nNotice that how to break the code, and how to figure out how to fix the break, are discussed in the how-to guide.\n\n\n\nStep 5: Now draw scatterplots to examine associations between variables\n\nTask 8 – Create a scatterplot to examine the association between some variables\nWe are working with geom_point() and you need x and y aesthetic mappings\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\nFigure 2: Scatterplot showing the potential association between health literacy (HLVA) scores and how accurately people understand health information in the Study Two dataset\n\n\n\n\n\nThis plot shows the possible association between x-axis variable HLVA and y-axis variable mean.acc.\nThe plot code moves through the following steps:\n\nggplot(...) make a plot\nggplot(data = study.two.gen, ...) with the study.two.gen dataset\nggplot(...aes(x = HLVA, y = mean.acc)) using two aesthetic mappings:\n\n\nx = HLVA map HLVA values to x-axis (horizontal, left to right) positions\ny = mean.acc map mean.acc values to y-axis (vertical, bottom to top) positions\n\n\ngeom_point() show the mappings as points\n\n\n\nTask 9 – Now do scatterplots with every numeric predictor variable in the study.two.gen dataset\nYou always want to use the outcome mean.acc as the y-axis variable so:\n\ny = mean.acc\n\nThen you can use each numeric predictor variable as the x-axis variable so:\n\nx = mean.self\n\n\n\n\n\n\n\nTip\n\n\n\nRemember what we saw with summary(): not every variable consists of numbers\nIf the summary() does not show you a mean for a variable, then R does not think that variable is numeric\n\n\nIt can be hard to decide what an association looks like so make a decision based on what you see\nRight now, we are working to build your intuitions so: reflect, trust your intuition, and make a decision.\n\n\nDraw the plot, answer the question\n\nQ.12. What is the shape (direction) of the association between mean.self and mean.acc?\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\nDraw the plot, answer the question\n\nQ.13. What is the shape (direction) of the association between AGE and mean.acc?\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\nDraw the plot, answer the question\n\nQ.14. What is the shape (direction) of the association between SHIPLEY and mean.acc?\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\nDraw the plot, answer the question\n\nQ.15. What is the shape (direction) of the association between HLVA and mean.acc?\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\nDraw the plot, answer the question\n\nQ.16. What is the shape (direction) of the association between FACTOR3 and mean.acc?\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = FACTOR3, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\nDraw the plot, answer the question\n\nQ.17. What is the shape (direction) of the association between QRITOTAL and mean.acc?\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = QRITOTAL, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\nStep 6: Edit the scatterplots to make them look good\n\nTask 10 – Edit the appearance of one plot step-by-step\nLearn how to edit your plotting code so that you can make plots with a professional appearance.\n\n\n\n\n\n\nTip\n\n\n\n\nWe teach this because we know that some of our alumni get jobs after they develop pro visualization skills with us.\nWe will do this learning as part of PSYC122.\n\n\n\nIn doing this work, you will learn about:\n\ncoding – how to do the edits;\nvisualization – how to look at and read plots;\npresentation – what works and what doesn’t for your audience.\n\nWe get started here.\n\n\nHint: Task 10 – We are going to edit a scatterplot to adjust\n\nthe appearance of the points using alpha, size and colour;\nthe colour of the background using theme_bw();\nthe appearance of the labels using labs().\n\nIn the following, we ask you to edit one plot element at a time. You can work out what to do.\nThere is helpful ggplot reference information that you can use: here.\nYou can visit the find the ggplot reference webpages, find some example code, and come back here.\nYou can click on the reveal button, for each question, to get our example code.\n\n\n\n\n\n\nTip\n\n\n\n\nYou do not have to stick with our choices on colour, size etc.\nExperiment change the options and see what happens.\n\n\n\n\n\n\nQuestions: Task 10\n\nQ.18. Change the appearance of the points using alpha, size and colour:\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\")\n\n\n\n\n\nQ.19. Edit the colour of the background using theme_bw()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\")   +\n  theme_bw()\n\n\n\n\n\nQ.20. Edit the appearance of the labels using labs()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\")   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\")\n\n\n\n\n\nQ.21. Can you find the ggplot reference page?\n\nTry doing a search with the keywords: ggplot reference geom_point\n\n\n\nNow it’s your turn: experiment!\n\nWhat about different colour words? Replace \"red\" with \"...\"?\nWhat about a different size? Replace size = 2 with size =  ... using a different number.\nWhat about a different level of transparency (alpha)? Replace alpha = 0.5 with alpha =  ... using a different fraction.\n\n\n\n\nStep 7: Use correlation to to answer the research questions\n\nTask 11 – Examine the correlation between mean accuracy (mean.acc) and some numeric predictor variables\nWe use cor.test() for the questions that follow.\n\n\n\n\n\n\nTip\n\n\n\n\nWe take a slightly different approach to the approach you have seen in previous weeks see here\nYou have seen the code before.\nHere, we use cor.test() on its own because we want to focus your attention on the statistics\n\n\n\n\nQ.22. What is r (given as cor in the output) for the correlation between HLVA and mean.acc?\n\n\nCan you figure out the code to do the calculation?\n\n\n\n\n\n\nCode\n\n\n\n\n\n\ncor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n\n\n\nQ.23. Is the correlation significant?\n\n\n\nQ.24. What are the values for t and p for the significance test for the correlation?\n\n\n\nQ.25. What do you conclude, given the correlation results?\n\nMaybe draw a scatterplot to examine the shape of the association.\n\n\nQ.26. What is r (given as cor in the output) for the correlation between mean.self and mean.acc?\n\n\nCan you figure out the code to do the calculation?\n\n\n\n\n\n\nCode\n\n\n\n\n\n\ncor.test(study.two.gen$mean.self, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n\n\n\nQ.27. Is the correlation between AGE and mean.acc significant?\n\n\nCan you figure out the code to do the calculation?\n\n\n\n\n\n\nCode\n\n\n\n\n\n\ncor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n\n\n\nQ.28. What are the values for t and p for the significance test for the correlation between QRITOTAL and mean.acc?\n\n\nCan you figure out the code to do the calculation?\n\n\n\n\n\n\nCode\n\n\n\n\n\n\ncor.test(study.two.gen$QRITOTAL, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n\n\n\nQ.29. What do you conclude, given the correlation results, about the association between SHIPLEY and mean.acc?\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\ncor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")",
    "crumbs": [
      "Home",
      "PSYC122",
      "5. Week 16 -- Hypotheses, associations"
    ]
  },
  {
    "objectID": "PSYC122/Week16.html#sec-wk16-lab-activities-answers",
    "href": "PSYC122/Week16.html#sec-wk16-lab-activities-answers",
    "title": "5. Week 16 – Hypotheses, associations",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week.\n\n\n\n\n\n\nTip\n\n\n\nThe .Rmd script containing all code and all answers for each task and each question will be made available after the final lab session has taken place.\n\nYou can download the script 2023-24-PSYC122-w16-workbook-answers.Rmd when it is available.\n\n\n\nWe set out the Week 16 Hypotheses, associations questions below. We focus on the Lab activity 2 questions where we ask you to interpret something or say something.\nYou can see all the code and all the answers in 2023-24-PSYC122-w16-workbook-answers.Rmd.\n\nAnswers\n\n\n\n\n\n\nTip\n\n\n\nClick on a box to reveal the answer.\n\n\n\nQuestions\n\nQ.1. What is the median of AGE?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.1. 32.50\n\n\n\n\n\nQ.2. What class is the variable ETHNICITY?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.2. character\n\n\n\n\n\nQ.3. Does the summary indicate if any variable has missing values (NAs)?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nQ.3. No\n\n\n\n\n\nQ.4. After you have done this [change ETHNICITY to a factor], what information does summary() give you about the variable ETHNICITY?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.4. We can see that ETHNICITY lists observations following UK Office National Statistics ethnicity grouping:\nAsian: 15\nBlack: 5\nMixed: 7\nWhite: 145\n\n\n\n\n\nQ.5. Did you get a message in the Console window in R-Studio [when you produced a histogram]: what does it say?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.5. The message says:\nstat_bin() using bins = 30. Pick better value with binwidth.\n\n\n\n\n\nQ.6. Draw two different histograms to examine the distributions of two different variables: SHIPLEY and HLVA\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + geom_histogram()\nggplot(data = study.two.gen, aes(x = HLVA)) + geom_histogram()\n\n\n\n\n\nQ.7. Now edit the code for both plots: can you change the binwidth in geom_histogram() to make the bars wider?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + geom_histogram(binwidth = 2)\nggplot(data = study.two.gen, aes(x = HLVA)) + geom_histogram(binwidth = 2)\n\n\n\n\n\nQ.8. – How would you describe the distributions – in a sentence – of the distributions of the SHIPLEY and HLVA variable values for our sample?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.8. The SHIPLEY values lie between about 25 and 40, and are skewed towards high scores.\nA.8. The HLVA values lie between 4 and about 14, and peak in the middle (near 7).\n\n\n\n\n\nQ.12. What is the shape (direction) of the association between mean.self and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.12. Increase in mean.self is associated with increase in mean.acc\n\n\n\n\n\nQ.13. What is the shape (direction) of the association between AGE and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.13. There is no clear association between AGE and mean.acc\n\n\n\n\n\nQ.14. What is the shape (direction) of the association between SHIPLEY and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.14. Increase in SHIPLEY is associated with increase in mean.acc\n\n\n\n\n\nQ.15. What is the shape (direction) of the association between HLVA and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.15. Increase in HLVA is associated with increase in mean.acc\n\n\n\n\n\nQ.16. What is the shape (direction) of the association between FACTOR3 and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.16. Increase in FACTOR3 is associated with increase in mean.acc\n\n\n\n\n\nQ.17. What is the shape (direction) of the association between QRITOTAL and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.17. Increase in QRITOTAL is associated with increase in mean.acc\n\n\n\n\n\nQ.21. Can you find the ggplot reference page?\n\nTry doing a search with the keywords: ggplot reference geom_point\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.21. – It is here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\n\n\n\nQ.22. What is r (given as cor in the output) for the correlation between HLVA and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.22. r = 0.5000559\n\n\n\n\n\nQ.23. Is the correlation significant?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.23. r is significant\n\n\n\n\n\nQ.24. What are the values for t and p for the significance test for the correlation?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.24. t = 7.5288, p = 2.866e-12\n\n\n\n\n\nQ.25. What do you conclude, given the correlation results?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.25. HLVA and mean.acc are positively correlated suggesting that as HLVA scores increase so also do mean.acc scores\n\n\n\n\n\nQ.26. What is r (given as cor in the output) for the correlation between mean.self and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.26. r = 0.5460792\n\n\n\n\n\nQ.27. Is the correlation between AGE and mean.acc significant?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.27. r is not significant\n\n\n\n\n\nQ.28. What are the values for t and p for the significance test for the correlation between QRITOTAL and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.28. t = 6.4711, p = 9.993e-10\n\n\n\n\n\nQ.29. What do you conclude, given the correlation results, about the association between SHIPLEY and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.29. SHIPLEY and mean.acc are positively correlated suggesting that as HLVA scores increase so also do mean.acc scores",
    "crumbs": [
      "Home",
      "PSYC122",
      "5. Week 16 -- Hypotheses, associations"
    ]
  },
  {
    "objectID": "PSYC122/Week16.html#sec-wk16-lab-Q-and-A",
    "href": "PSYC122/Week16.html#sec-wk16-lab-Q-and-A",
    "title": "5. Week 16 – Hypotheses, associations",
    "section": "Online Q&A",
    "text": "Online Q&A\nYou will find, below, a link to the video recording of the week 16 online Q&A after it has been completed.",
    "crumbs": [
      "Home",
      "PSYC122",
      "5. Week 16 -- Hypotheses, associations"
    ]
  },
  {
    "objectID": "PSYC122/Week14.html",
    "href": "PSYC122/Week14.html",
    "title": "4. Week 14 - Chi-Square",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.\nThis week we will focus on Chi-square as a measure of association between categorical variables.",
    "crumbs": [
      "Home",
      "PSYC122",
      "4. Week 14 - Chi-Square"
    ]
  },
  {
    "objectID": "PSYC122/Week14.html#sec-wk14-lectures",
    "href": "PSYC122/Week14.html#sec-wk14-lectures",
    "title": "4. Week 14 - Chi-Square",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week is presented in two parts:\n\nTheory - Associations between categorical variables (~23 min) Watch this part before you complete the reading and the pre-lab activities. The video has captions, in case you find that helpful. You can download the slides and a transcript from the links below the video.\n\n\nSlides Transcript\n\nHow to - How to do Chi-square in R (~19 min) Watch this part after you’ve completed the reading and before you attend the lab session. You can download the slides, a transcript and the example scritps from the links below the video.\n\n\nTranscript Example script",
    "crumbs": [
      "Home",
      "PSYC122",
      "4. Week 14 - Chi-Square"
    ]
  },
  {
    "objectID": "PSYC122/Week14.html#sec-wk14-reading",
    "href": "PSYC122/Week14.html#sec-wk14-reading",
    "title": "4. Week 14 - Chi-Square",
    "section": "Reading",
    "text": "Reading\nThe reading that accompanies the lectures this week is Chapter 19: Chi-square of the core text by Howell (2017). Please note that I might mention an alternative textbook in the lectures. The content is highly similar, but this year, we’ve decided to use Howell (2017) as the core text for PSYC121 and PSYC122. So no need to look at the book by Greene & D’Oliveira (2006).",
    "crumbs": [
      "Home",
      "PSYC122",
      "4. Week 14 - Chi-Square"
    ]
  },
  {
    "objectID": "PSYC122/Week14.html#sec-wk14-pre-pab-activities",
    "href": "PSYC122/Week14.html#sec-wk14-pre-pab-activities",
    "title": "4. Week 14 - Chi-Square",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapter you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Calculating Chi-square by hand and interpreting the results\nIs there a relationship between the number of people who smoke and the number of people who drink? Please note that the question is the number of people (frequency) and not how much people drink/smoke. Also not that these are fictitious data. You’ll need a table of critical values for Chi-square. This can be found in the ‘Week 14 – resources’ folder on Moodle.\n\nPre-lab activity questions:\n\nComplete the Pearson’s Chi-square test by hand using the data above and fill in the blanks:\n\n\\(\\chi 2\\) ( , N = ) = , p\n\nCan you reject the null hypothesis?\n\n\n\nPre-lab activity 2: Data visualisation - Creating a bar chart\nWe’ve mostly been using the ggplot2 package for visualising data. You can read a great overview of the ggplot2 package here. It also links to a ‘cheatsheet’ that you can download as a .pdf document. Lots of useful info on there!\nWith regard to visualising relations between categorical variables, the geom_bar() function is important. The following ‘recipe’ summarises what it does and how to use it.\n\nTASK Have a look at the ‘recipe’ and read through it. Try to understand each step. Going through the example is particularly helpful.\n\n\n\n\n\n\n\nRecipes - how to use them\n\n\n\nEach ‘recipe’ has the same structure.\n\nFirst, it summarises what it is that you want to achieve when using that specific function. In the case of select() it says “You want to extract specific columns from a data frame and return them as a new, smaller data frame.”\nThen, it outlines a number of steps that you need to carry out when using this function. For select() it outlines 2 steps: 1. Pass the dataframe to the function. 2. List the column(s) to return.\nFinally, there is an example talks you through using the function with some data. For select() it uses an example with data on the weather.\nAdditional information appears in extra boxes with a light-bulb icon. If you find those confusing, don’t worry about them at this stage.\n\n\n\n\ngeom_bar() - create a bar chart - recipe\n\n\n\nPre-lab activity 3: Getting ready for the lab class\n\nGet your files ready\nDownload the 122_week14_forStudents.zip file and upload it into the new folder in RStudio Server you created.\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below.",
    "crumbs": [
      "Home",
      "PSYC122",
      "4. Week 14 - Chi-Square"
    ]
  },
  {
    "objectID": "PSYC122/Week14.html#sec-wk14-lab-activities",
    "href": "PSYC122/Week14.html#sec-wk14-lab-activities",
    "title": "4. Week 14 - Chi-Square",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nconducting Pearson’s Chi-square in R\ninterpreting Pearson’s Chi-square in R\nreporting the results in APA format\nwhen and why to apply Pearson’s Chi-square to answer questions in psychological science\n\n\nLab activity 1: Understanding the application of the Chi-square test\n\nQUESTION 1\nHow does Pearson’s chi-square differ from Pearson’s correlation?\n\n\nQUESTION 2\nChi-square test of independence would be appropriate when testing the following questions:\n\n\nWhat is the relationship between gender and soft drink preference? True or False?\n\nb.How do males and females compare in terms of wanting to be a psychologist when they leave school? True or False?\n\n\n\nQUESTION 3\nWrite the chi-square formula below.\n\n\nQUESTION 4\nWhat were your answers to the pre-lab activity 1 questions? Please compare them with other students at your table.\n+a. Complete the Pearson’s Chi-square test by hand using the data above and fill in the blanks:\n\\(\\chi 2\\) ( , N = ) = , p\n+b. Can you reject the null hypothesis?\n\n\nQUESTION 5\nWhy is it recommended to opt for multiple 2 x 2 chi-squares instead of chi-squares larger than 2 x 2?\n\n\nQUESTION 6\nHow could you ‘modify’ the contingency table below for chi-square analysis to aid subsequent interpretation of the data/results?\n\n\n\n\nLab activity 2: Reminders through association\nFor this lab, we’re going to use data from Rogers, T. & Milkman, K. L. (2016). Reminders through association. Psychological Science, 27, 973-986. You can read the full paper online but the short version is that the authors looked at how people remember to follow through with the intention of doing something.\nAlthough there are lots of potential reasons (e.g., some people may lack the self-control resources), Rogers and Milkman (2016) propose that some people fail to follow through simply because they forget about their good intentions. If this is the case, the authors argue, then having visual reminders to follow through on their intentions may help people remember to keep them. For example, a person may choose to put a sticker for their gym on their car window, so that every time they get in the car they remember to go to the gym.\nIn Study 1 by Rogers and colleagues, participants took part in an unrelated experiment but at the start of the task they were asked to return a small stack of paper clips to the reception of the building at the end of the study and if they did so the researchers would donate $1 to a charity. They were then asked if they intended to do this. Those in the reminder-through-association (RTA) condition read “Thank you! To remind you to pick up a paper clip, an elephant statuette will be sitting on the counter as you collect your payment.” This message was followed by a picture of the elephant statuette. Those in the control condition simply read “Thank you!”.\nWhat we want to do is to run a chi-square analysis to determine whether those in the RTA condition were more likely to remember to return the paper-clips than those in the control condition.\n\n\n\n\n\n\nBefore we begin\n\n\n\nLet’s put the basics in place:\n\nMake sure you have started a new R Markdown script. If you need a reminder of how to do that, please revisit week 6 of PSYC121 (here).\nYou’ll need the data file RTA_study1.csv you downloaded when completing Pre-lab activity 3. If you experienced issues with uploading files to the server, follow the instructions below.\nWhen starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one.\nFinally, make sure your working directory is set to the folder in which you have stored the data files (RTA_study1.csv).\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week14/RTA_study1.csv?raw=true\", destfile = \"RTA_study1.csv\")\n\n\n\n\n\n\n\nCleaning the R environment\n\n\n\n\n\nYou can clean the R environment by clicking on the broom icon at the top right of the environment window, or you can use the code below.\n\nrm(list=ls())\n\n\n\n\n\n\n\n\n\n\nChecking your working directory\n\n\n\n\n\nUse the code below to check what you working directory is currently set to. This is the folder that R will use to look for files. Is the file path that is written to the Console after you run the code snippet the one that contains the data file? You can check by nativating to the path you can see in the Console in the ‘Files’ pane on the right. Does it contain the data files?\n\ngetwd()\n\nIf your working directory is not set to the folder that contains the data file, navigate to folder that contains the data file in the ‘Files’ pane, click ‘More’ and then on ‘Set as working directory’.\n\n\n\n\nStep 1. Add the code to load the relevant libraries in a new code chunk. We need the following ones: lsr and tidyverse. If you are unsure, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library()function. Remember to put it inside a ‘code chunk’ in your R Markdown script.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(lsr)\nlibrary(tidyverse)\n\n\n\n\nStep 2. Read in the data, have a look at the layout of the data and familiarise yourself with it.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function to read in the data and the head() function to have a quick look at each data frame.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nintent_data &lt;- read_csv(\"RTA_study1.csv\")                                 # Read in the data file\n\nhead(intent_data)                                                         # Look at the table\n\n\n\nIt is a fairly simple data file that contains four variables for 87 participants:\n\ncondition: this variable indicates which condition participants were in (1 = reminder-through-association condition, 2 = control condition)\nintend: this variable indicates whether participants said they were intending to return the paper-clips (1 = yes, 0 = no)\nactualdonate: this variable indicates whether participants actually ended up returning the paper-clips and therefore donating to charity (1 = yes, 0 = no)\nid: this variable indicates the participant ID number\n\n\nQuestion 2a: What do the numbers in the first row across the four columns refer to?\n\n\nStep 3. Getting the data ready. We need to do a little bit of wrangling to get our data into the format we need: First, we need to remove all the participants who said that they did not intend to return the paper-clips (intend = 0) as we are only interested in whether people follow through on an intention. Second, to make the output easier to read, we’re going to recode condition to have text labels rather than numerical values.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use filter() to remove all participants who said that they did not intend to return the paper-clips. You can use mutate() and recode() to recode the values in condition to make ‘1 = rta’ and ‘2 = control’, and the values in actualdonate to ‘1 = donated’ and ‘0 = no_donation’. Finally, save the output to a new object.\nYou can do this in two separate steps, or you can use pipes. Also, note that you will need to put both sides of each recode argument (i.e., 1 and rta) in quotation marks, even though 1 and 2 are numbers, they actually represent categories rather than numerical data.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nintent_recode &lt;- intent_data %&gt;%\n  filter(intend == 1) %&gt;%\n  mutate(condition = recode(condition, \"1\" = \"rta\", \"2\" = \"control\"),\n         actualdonate = recode(actualdonate, \"1\" = \"donated\", \"0\" = \"no_donation\"))\n\nhead(intent_recode)\n\n\n\n\nQuestion 3a: How many participants were removed because they didn’t intend to return the paper-clips?\n\n\nStep 4. Next you need to calculate descriptive statistics. For frequency data these are simply counts so we can use the function count() rather than having to use the summarise() function. We want to know how many participants are in each group (rta - donated, rta - didn’t donate, control - donated, control - didn’t donate) so we will need to use group_by() to display the results for all combinations of condition and actualdonate.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the code template below to develop the code. You need to replace the various bits in CAPITALS.\nNEW_OBJECT &lt;- DATA_TO_USE %&gt;%\ngroup_by(FIRST_GROUPING_VARIABLE, SECOND_GROUPING_VARIABLE) %&gt;%\n  count()\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nintent_counts &lt;- intent_recode %&gt;%\ngroup_by(condition, actualdonate) %&gt;%\n  count()\n\nintent_counts\n\n\n\n\nQuestion 4a: How many participants in the control condition didn’t donate?\n\n\nQuestion 4b: How many participants in the control condition donated?\n\n\nQuestion 4c: How many participants in the rta condition didn’t donate?\n\n\nQuestion 4d: How many participants in the rta condition donated?\n\nYou may also want to calculate the percentages of participants in each condition. Run this code to do this. Make sure to replace RECODED_DATA with the name of your dataframe in which you have recoded the original data values with string labels (in Step 3).\n\nintent_percent &lt;- intent_recode %&gt;%\n  group_by(condition, actualdonate) %&gt;%\n  count() %&gt;%\n  ungroup() %&gt;% # ungroups the data\n  group_by(condition) %&gt;% # then groups it again but just by condition\n  mutate(percent_condition = n/sum(n) * 100)\n\nintent_percent\n\n\nStep 5. Data visualiation. We want to create a simple bar plot of our count data. We’ll use ggplot() for this in combination with the geom_bar() function. Use the code template below and make sure to fill in the relevant bits.\n\n\nggplot(data = , aes(x = , fill = )) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nggplot(data = intent_recode, aes(x = condition, fill = actualdonate)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\nQuestion 5a: What does position = \"dodge\" do? Remove it and rerun the code to find out.\n\nAs you can see, the plot makes it much easier to visualise the data - participants in the RTA condition appear to have been more likely to remember to donate than those in the control condition.\nThe ggplot2() package allows you to customise all aspects of your plots, so let’s tidy ours up a little bit. We’re going to do the following:\n\nEdit the labels on the x-axis, y-axis and fill.\nChange the colours of the bars by using scale_fill_manual() and specifying the colours we want in the values argument\nChange the theme of the plot to change how it looks\n\nThe code below does this.\n\nTASK Add a comment to each line to indicate what that line does.\n\n\nggplot(data = intent_recode, aes(x = condition, fill = actualdonate)) +\n  geom_bar(position = \"dodge\") +\n  scale_x_discrete(name = \"Condition\", labels = c(\"Control\", \"RTA\")) +\n  scale_y_continuous(name = \"Count\") +\n  scale_fill_manual(name = \"Behaviour\", labels = c(\"Donated\", \"Did not donate\"), values = c(\"blue\", \"grey\"))+\n  theme_classic()\n\nThere are a few things to note about the code we just added on:\n\nIf you use simple colour names then you are restricted in the options you can choose, however, if you want more flexibility you can use hexadecimal colour codes, see here.\nThere are multiple themes that you can apply. Have a look at the ggplot2() cheatsheet for an overview (here. Try out a few and see which one you prefer.\n\n\nStep 6. Now let’s run that chi-square analysis to see whether our impression from the plot holds up and there is a significant association between the grouping variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the chisq.test() function. Remember to use the recoded data to make the output easier to read.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nresults &lt;- chisq.test(x = intent_recode$condition,        # the first grouping variable\n                      y = intent_recode$actualdonate,     # the second grouping variable\n                      correct = FALSE)                    # whether we want to apply the continuity correction (use if any of the expected cell frequencies &lt; 10 in 2 x 2 table)\nresults\n\n\n\n\nQuestion 6a: What do you conclude from the output?\n\n\nStep 7. Check the assumptions.\n\nThe assumptions for chi-square are as follows:\n\nThe data in the cells should be frequencies, or counts of cases rather than percentages.\nThe levels (or categories) of the variables are mutually exclusive. That is, a particular participant fits into one and only one group of each of the variables.\nEach participant may contribute data to one and only one cell. If, for example, the same participants are tested over time such that the comparisons are of the same subjects at Time 1, Time 2, Time 3, etc., then Chi-square may not be used.\nThe study groups must be independent. This means that a different test must be used if the two groups are related. For example, a different test must be used if the researcher’s data consists of paired samples, such as in studies in which a parent is paired with his or her child.\nThere are 2 variables, and both are measured as categories, usually at the nominal level. While Chi-square has no rule about limiting the number of cells (by limiting the number of categories for each variable), a very large number of cells (over 20) can make it difficult to meet assumption #6 below, and to interpret the meaning of the results.\nThe expected cell frequencies should be greater than 5.\n\nAssumptions 1) to 5) should be evaluated by reviewing the design of the study. The only assumption that we need to check with R is whether all expected frequencies are greater than 5.\n\nTASK Write the code to check that all expected frequencies are greater than 5.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe information we need is in the object in which your stored the results of the Chi-square test.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nresults$expected\n\n\n\n\nQuestion 7a: What do you conclude from the output?\n\n\nStep 8. The last step before writing up the results is to calculate an effect size so that we have a standardised measure of how large the association between our grouping variables is, the effect size measure for chi-square is Cramer’s V. To calculate Cramer’s V we’re going to use the function cramersv() from the lsr package. The code mirrors the code used for the Chi-square test itself:\n\n\neff_size &lt;- cramersV(x = intent_recode$condition,     # the first grouping variable\n                     y = intent_recode$actualdonate,  # the second grouping variable\n                     correct = FALSE)                  # whether we want to apply the continuity correction (use if any of the expected cell frequencies &lt; 10 in 2 x 2 table)\neff_size\n\nWe can square the effect size (or multiple it by itself) to see how much variance in one variable is accounted for by the other variable. Use the code snippet below to square the effect size.\n\npercentageAccountedFor &lt;- eff_size * eff_size *100\npercentageAccountedFor\n\n\nQuestion 8a: How large is the effect and how much variance is accounted for?\n\n\nStep 9. To help with interpreting the relationships, it is useful to look at the standardised residuals. These are z-scores that indicate how many standard deviations above or below the expected count, an observed count is (thus indicating how much they differ). Remember, for z-scores the following holds: +/- 1.96, p &lt;.05, +/- 2.58 p &lt;.01, +/-3.29 p &lt; .001\n\n\nresults$residuals   # check the standardised residuals\n\n\nQuestion 9a: What do you conclude from the output?\n\n\nStep 10. Write up the results following APA guidelines.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe Purdue writing lab website is helpful for guidance on punctuating statistics.",
    "crumbs": [
      "Home",
      "PSYC122",
      "4. Week 14 - Chi-Square"
    ]
  },
  {
    "objectID": "PSYC122/Week14.html#sec-wk14-answers",
    "href": "PSYC122/Week14.html#sec-wk14-answers",
    "title": "4. Week 14 - Chi-Square",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\n\nLab activity 1\n\nHow does Pearson’s Chi-square differ from Pearson’s correlation?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nPearson’s Chi-square assesses whether there is a relationship between categorical (or nominal) variables. Pearson’s correlation assesses whether there is a relationship between continuous (or interval/ratio) variables.\n\n\n\n\nChi-square test of independence would be appropriate when testing the following questions:\n\n\nWhat is the relationship between gender and soft drink preference?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTrue\n\n\n\n\nHow do males and females compare in terms of wanting to be a psychologist when they leave school?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTrue\n\n\n\n\nWrite the chi-square formula below.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\nWhat were your answers to the pre-lab activity 1 questions? Please compare them with other students at your table. Complete the Pearson’s chi-square test by hand using the data above and fill in the blanks:\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nFirst determine expected frequencies: Smoke/drink: (70 x 65) / 110 = 41.36 Smoke/don’t drink (70 x 45) / 110 = 28.63 Don’t smoke/drink (40 x 65) / 110 = 23.63 Don’t smoke/don’t drink (40 x 45) / 110 = 16.36\nThen calculate chi-square: Smoke/drink: (50-41.36)2 / 41.36 = 1.80 Smoke/don’t drink: (20-28.63)2 / 28.63 = 2.60 Don’t smoke/drink: (15-23.63)2 / 23.63 = 3.15 Don’t smoke/don’t drink: (25-16.36)2 / 16.36 = 4.56 1.80+2.60+3.15+4.56 = 12.11\n\\(\\chi 2\\) (1, N = 110) = 12.11, p &lt; .001\nCan you reject the null hypothesis? Yes\n\n\n\n\nWhy is it recommended to opt for multiple 2 x 2 chi-squares instead of chi-squares larger than 2 x 2?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIt is easier to interpret and such a design requires a smaller sample size.\n\n\n\n\nHow could you ‘modify’ the contingency table below for chi-square analysis to aid subsequent interpretation of the data/results?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nBy combining ‘interested’ and ‘somewhat interested’ or by partitioning (doing multiple 2 x 2 chi-squares, while using Bonferroni correction to account for running multiple tests\n\n\n\n\n\nLab activity 2\n\nQuestion 2a: What do the numbers in the first row across the four columns refer to?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\ncondition = 1, intend = 1, actualdonate = 1 and id = 1 shows us that participant 1 was in the ‘reminder-through-assocation’ condition, reported that they intended to donate and also actually donated.\n\n\n\n\nQuestion 3a: How many participants were removed because they didn’t intend to return the paper-clips?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n10 participants. The table ‘intent_data’ contains 87 observations, after we have applied the filter() function to include only those participants who did intend to return the paper-clips, the intent_recode table contains 77 observations.\n\n\n\n\nQuestion 4a: How many participants in the control condition didn’t donate?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n22\n\n\n\n\nQuestion 4b: How many participants in the control condition donated?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n16\n\n\n\n\nQuestion 4c: How many participants in the rta condition didn’t donate?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n10\n\n\n\n\nQuestion 4d: How many participants in the rta condition donated?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n29\n\n\n\n\nQuestion 5a: What does position = \"dodge\" do?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n“dodge” places the bars next to each other, rather than on top of each other.\n\n\n\n\nQuestion 6a: What do you conclude from the output?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is a significnat association between the grouping variables.\n\n\n\n\nQuestion 7a: What do you conclude from the output?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe expected frequencies in all cells are greater than 5.\n\n\n\n\nQuestion 8a: How large is the effect and how much variance is accounted for?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe effect size (Cramer’s V) = 0.33 and the percentage variance accounted for = 11%.\n\n\n\n\nQuestion 9a: What do you conclude from the output?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe standardised residuals in the 4 cells are all of a roughly similar size (and below 1.96), which suggests that the statistically significant Chi-square tests is not driven by one or two cells, but reflects the pattern across all cells.\n\n\n\n\nWrite up:\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThose in the reminder-through-association condition performed the intended behaviour at a significantly higher rate (74%, 29 out of 39) than did those in the control condition (42%, 16 out of 38)), χ2(1, N = 77) = 8.24, p = 0.004, V = 0.33. The analysis showed that 11% of variance in intended behaviour could be accounted for by condition (reminder-through-association vs. control).",
    "crumbs": [
      "Home",
      "PSYC122",
      "4. Week 14 - Chi-Square"
    ]
  },
  {
    "objectID": "PSYC122/Week14.html#online-qa",
    "href": "PSYC122/Week14.html#online-qa",
    "title": "4. Week 14 - Chi-Square",
    "section": "Online Q&A",
    "text": "Online Q&A\nBelow is the recording of this week’s online Q&A.",
    "crumbs": [
      "Home",
      "PSYC122",
      "4. Week 14 - Chi-Square"
    ]
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "",
    "text": "In Week 18, we aim to further develop skills in working with the linear model.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like the linear model.\nWhen we do these analyses, we need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model.\n\nWe usually need to decide:\n\nis the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nand is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\nfocusing on how we edit ggplot() code to produce professional looking plots.\n\n\n\nI will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#naming-things",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#naming-things",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "",
    "text": "In this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-1-set-up",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-1-set-up",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"ggeffects\")\n\nWarning: package 'ggeffects' was built under R version 4.2.3\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-2-load-the-data",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")\n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look.\n\nhead(study.one.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nEven though you have done this before, you will want to do it again, here, and pay particular attention to:\n\nsummary information about the numeric variables;\nsummary information about variables of class: character."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-3-use-a-linear-model-to-to-answer-the-research-questions-one-predictor",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-3-use-a-linear-model-to-to-answer-the-research-questions-one-predictor",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 3: Use a linear model to to answer the research questions – one predictor",
    "text": "Step 3: Use a linear model to to answer the research questions – one predictor\n\nRevise: Practice to strengthen skills\nWe start by revising how to use lm() with one predictor.\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\nTask 5 – Examine the relation between outcome mean accuracy (mean.acc) and health literacy (HLVA)\n\n\nHint: Task 5\nWe can use lm() to estimate whether variation in health literacy (HLVA) predicts outcome mean accuracy (mean.acc) of understanding.\n\nmodel &lt;- lm(mean.acc ~ HLVA, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40848 -0.05304  0.01880  0.07608  0.19968 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.61399    0.03387  18.128  &lt; 2e-16 ***\nHLVA         0.02272    0.00369   6.158 5.31e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1068 on 167 degrees of freedom\nMultiple R-squared:  0.1851,    Adjusted R-squared:  0.1802 \nF-statistic: 37.92 on 1 and 167 DF,  p-value: 5.307e-09\n\n\nIn R analysis code, we write method(outcome ~ predictor) so:\nlm(mean.acc ~ HLVA, data = study.one.gen)\n\ngets us an analysis of whether or how HLVA predicts variation in outcome mean.acc.\n\nIf you look at the model summary you can answer the following questions.\n\nQuestions: Task 5\n\nQ.1. What is the estimate for the coefficient of the effect of the predictor, HLVA?\nA.1. 0.02272\nQ.2. Is the effect significant?\nA.2. It is significant, p &lt; .05\nQ.3. What are the values for t and p for the significance test for the coefficient?\nA.3. t = 6.158, p = 5.31e-09\nQ.4. What do you conclude is the answer to the research question, given the linear model results?\nA.4. The model slope estimate suggests that as HLVA scores increase so also do mean.acc scores\nQ.5. What is the F-statistic for the regression? Report F, DF and the p-value.\nA.5. F-statistic: 37.92 on 1 and 167 DF, p-value: 5.307e-09\nQ.6. Is the regression significant?\nA.6. Yes: the regression is significant.\nQ.7. What is the Adjusted R-squared?\nA.7. Adjusted R-squared: 0.1802\nQ.8. Explain in words what this R-squared value indicates?\nA.8. The R-squared suggests that 18% of outcome variance can be explained by the model"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-4-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-4-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 4: Use a linear model to to answer the research questions – multiple predictors",
    "text": "Step 4: Use a linear model to to answer the research questions – multiple predictors\n\nIntroduce: make some new moves\n\n\nTask 6 – Examine the relation between outcome mean accuracy (mean.acc) and multiple predictors\nHere, the predictors will include:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\nHint: Task 6\nWe use lm(), as before, but now specify each variable listed here by variable name\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40322 -0.05349  0.01152  0.07128  0.18434 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.302030   0.091257   3.310  0.00115 ** \nHLVA        0.017732   0.003923   4.521 1.17e-05 ***\nSHIPLEY     0.005363   0.002336   2.296  0.02291 *  \nFACTOR3     0.003355   0.001264   2.654  0.00872 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1033 on 165 degrees of freedom\nMultiple R-squared:  0.2474,    Adjusted R-squared:  0.2337 \nF-statistic: 18.08 on 3 and 165 DF,  p-value: 3.423e-10\n\n\nNotice that we do the linear model in the steps:\n\nmodel &lt;- lm(...) fit the model using lm(...), giving the model a name; here, we call it model;\n...lm(mean.acc ~ HLVA...) tell R you want a model of the outcome mean.acc predicted (~) by the predictors listed, HLVA, SHIPLEY, and FACTOR3.\n...data = study.one.gen) tell R that the variables you name in the formula are in the study.one.gen dataset.\nsummary(model) ask R for a summary of the model you called model.\n\nNotice: that we use the variable names as they appear in the dataset, and that each predictor variable is separated from the next by a plus (+) sign.\nNotice: R has a general formula syntax: outcome ~ predictor or y ~ x and uses the same format across a number of different analysis functions.\n\nEach time, the left of the tilde symbol ~ is some output or outcome and the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\nQuestions: Task 6\nIf you look at the model summary you can answer the following questions\nQ.9. What is the estimate for the coefficient of the effect of the predictor HLVA in this model?\nA.9. 0.017732\nQ.10. Is the effect significant?\nA.10. It is significant, p &lt; .05\nQ.11. What are the values for t and p for the significance test for the coefficient?\nA.11. t = 4.521, p = 1.17e-05\nQ.12. What do you conclude is the answer to the research question, given the linear model results?\nA.12. The model slope estimate 0.017732 suggests that as HLVA scores increase so also do mean.acc scores.\nQ.13. How is the coefficient estimate for the HLVA slope similar or different, comparing this model with multiple predictors to the previous model with one predictor?\nA.13. It can be seen that the HLVA estimate in the two models is different in that it is a bit smaller in the model with multiple predictors compared to the model with one predictor. The HLVA estimate is similar in that it remains positive, it is about the same size.\nNotice that:-\n\nThe estimate of the coefficient of any one predictor can be expected to vary depending on the presence of other predictors.\nThis is one reason why we need to be transparent about why we choose to use the predictors we include in our model.\n\nQ.14. Can you report the estimated effect of SHIPLEY (the measure of vocabulary) using the kind of language you are shown in lecture week 18?\nA.14. The answer to the question can be written like this:\n\nThe effect of vocabulary knowledge (SHIPLEY) on mean accuracy of understanding is significant (estimate = 0.005, t = 2.296, p &lt; .001) indicating that increasing vocabulary knowledge is associated with increasing accuracy of understanding.\n\nQ.15. Can you report the model and the model fit statistics?\nA.15. The answer to the question can be written like this:\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 165) = 18.08, p&lt; .001, and explains 23% of variance (adjusted R2 = 0.23)."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-5-plot-predictions-from-linear-models-with-multiple-predictors",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-5-plot-predictions-from-linear-models-with-multiple-predictors",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 5: Plot predictions from linear models with multiple predictors",
    "text": "Step 5: Plot predictions from linear models with multiple predictors\n\nIntroduce: make some new moves\n\n\nTask 7 – Plot linear model predictions for one of the predictors\n\nHint: Task 7\nPreviously, we used geom_abline(), specifying intercept and slope estimates, to draw model predictions.\nHere, we use functions that are very helpful when we need to plot model predictions, for models where we have multiple predictors\nWe do this in four steps:\n\nWe first fit a linear model of the outcome, given our predictors.\nWe save information about the model.\nWe use the ggpredict() function from the {ggeffects} library to take the information about the model and create a set of predictions we can use for plotting.\nWe plot the model prediction plots.\n\nThese steps proceed as follows:\n\nWe first fit a linear model of the outcome, given our predictors.\n\nLike this:\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nThe code involves these key bits:\n\nmodel &lt;- lm(...) we fit the model using lm(...), giving the model a name; here, we call it model.\n...lm(mean.acc ~ HLVA...) we tell R we want a model of the outcome mean.acc predicted (~) by the predictors HLVA, SHIPLEY, and FACTOR3.\n\nNotice: when we use lm() to fit the model, R creates a set of information about the model, including estimates.\nWe give that set of information a name model, and we use that name, next, to access that information in the plotting step.\n\nWe use the ggpredict() function from the {ggeffects} library to take the information about the model and create a set of predictions we can use for plotting.\n\n\ndat &lt;- ggpredict(model, \"HLVA\")\n\nNotice:\n\ndat &lt;- ggpredict(...) asks R to create a set of predictions, and we give that set of predictions a name dat.\n... ggpredict(model, \"HLVA\") tells R what model information it should use (from model) and which predictor variable we need predictions for \"HLVA\".\n\n\nWe plot the model predictions with:\n\n\nplot(dat)\n\n\n\n\n\n\n\n\n\n\n\nTask 8 – Now produce plots that show the predictions for all the predictor variables in the model"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-6-now-draw-boxplots-to-examine-associations-between-variables",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-6-now-draw-boxplots-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 6: Now draw boxplots to examine associations between variables",
    "text": "Step 6: Now draw boxplots to examine associations between variables\n\nConsolidation: practice to strengthen skills\n\n\nTask 9 – Create boxplots to examine the association between a continuous numeric outcome variable like mean.acc and a categorical variable like ETHNICITY\nHere, we use geom_boxplot().\n\nHint: Task 9 – We can see where variables are not numeric using summary()\nThe boxplot can be produced using code like this:\n\nggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc)) +\n  geom_boxplot() +\n  theme_bw() +\n  labs(x = \"Ethnicity, ONS categories\", \n       y = \"Mean accuracy of understanding ('mean.acc')\") +\n  ylim(0, 1.1)\n\n\n\n\n\n\n\n\nThe plotting code works bit-by-bit, as described following.\n\nggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc)) defines two aesthetic mappings:\n\n\nx = ETHNICITY, the x variable has to be categorical or nominal, a factor like ETHNICITY with different levels.\ny = mean.acc, the y variable has to be numeric, a set of numbers like mean.acc with different values.\n\n\ngeom_boxplot() then uses that information about category (x = ...) and outcome (y = ...) to draw a box to represent the distribution of outcome scores for each group.\n\nNotice that when you draw the plot:\n\nThe middle line in each box represents the median outcome (here mean.acc) score for each group.\nThe shape of the box represents the distribution or spread of scores.\nThe top of the box represents the 75th percentile, what the score is for the people who are at the top 75% of the sample.\nThe bottom of the box represents the 25th percentile, what the score is for the people at the 25% level of outcomes for the sample.\n\nMore information about boxplots can be found here:\nhttps://ggplot2.tidyverse.org/reference/geom_boxplot.html\nHere is an edit of the plot to make it a bit more effective:\n\nggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc)) +\n  geom_jitter(alpha = .5) +\n  geom_boxplot(outlier.shape = NA, colour = \"red\", alpha = .1) +\n  theme_bw() +\n  labs(x = \"Ethnicity, ONS categories\", \n       y = \"Mean accuracy of understanding ('mean.acc')\") +\n  ylim(0, 1.1)\n\n\n\n\n\n\n\n\nThe plot shows:\n\nboxplots to indicate the average (median) and spread (percentiles) in mean.acc scores for each group;\nplus, with points, individual mean.acc scores for the people in each group.\n\n\n\nWhy are we learning how to do this?\nDrawing plots which show both summaries (like boxplots) and raw data (scores as points) is a common (advanced) professional visualization technique.\n\nIt is effective because these kinds of plots help you to see the pattern or trend and the nature of the underlying sample.\n\nNow you can use the plots to answer questions like the following\n\n\nQuestions: Task 9\nQ.16. What do you notice about the distribution of scores in different groups?\nA.16. The average accuracy of understanding appears to be similar between groups.\nQ.17. Does anything in the plots give you reason to question the nature of the participant sample?\nA.17. This is a leading question: there is plenty in the plots to cause concern.\n\nThe scatter of points shows that we have many more White participants in the sample than participants from other ethnicities.\nBecause we have very few people in the study from ethnic minority (often classed as BAME) groups, we might be concerned about whether the results from our models are representative of what you would see in these groups, or whether the results are representative of the wider population in general.\n\nQ.18. Can you use the ggplot() reference information – see the webpage link – to see how and why I made the code edits I did?\nA.18. You can see example code for each edit in the webpage.\nQ.19. Do you understand what geom_jitter() is doing? – and why I would use it?\nA.19. What the function does, and why I would use it can be found in the reference information webpage:\nhttps://ggplot2.tidyverse.org/reference/geom_jitter.html"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-6-estimate-the-effects-of-factors-as-well-as-numeric-variables",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-how-to.html#step-6-estimate-the-effects-of-factors-as-well-as-numeric-variables",
    "title": "2023-24-PSYC122-w18-how-to",
    "section": "Step 6: Estimate the effects of factors as well as numeric variables",
    "text": "Step 6: Estimate the effects of factors as well as numeric variables\n\nIntroduce: make some new moves\nWe have not yet included any categorical or nominal variables as predictors but we can, and should:\n\nlm() can cope with any kind of variable as a predictor.\n\n\n\nTask 10 – Fit a linear model including both numeric variables and categorical variables as predictors\n\nHint: Task 12\nWe can inspect the data to check what variables are categorical or nominal variables – factors – using summary().\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNotice that R shows categorical variables in the summary as having: Class: character.\n\nQ.20. Can you report the estimated effect of ETHNICITY: differences in outcome for people in different self-reported ethnicity groups?\nHint: Q.20. Include the factor ETHNICITY as a predictor:\n\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n            data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n    data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40261 -0.05322  0.01168  0.07124  0.18391 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     0.302764   0.095806   3.160  0.00188 ** \nHLVA            0.017391   0.003980   4.370 2.22e-05 ***\nSHIPLEY         0.005249   0.002380   2.206  0.02882 *  \nFACTOR3         0.003495   0.001289   2.711  0.00744 ** \nETHNICITYBlack  0.016600   0.065962   0.252  0.80163    \nETHNICITYMixed -0.016080   0.048371  -0.332  0.74000    \nETHNICITYOther  0.083201   0.108382   0.768  0.44381    \nETHNICITYWhite -0.001006   0.028308  -0.036  0.97168    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1043 on 161 degrees of freedom\nMultiple R-squared:  0.2514,    Adjusted R-squared:  0.2188 \nF-statistic: 7.723 on 7 and 161 DF,  p-value: 4.841e-08\n\n\n\nA.20. The effect of ethnicity (ETHNICITY) on mean accuracy of understanding is not significant.\nQ.21. Can you report the model and the model fit statistics?\nA.21. You can report the model and model statistics like this.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), vocabulary (SHIPLEY), reading strategy (FACTOR3), and ethnicity (ETHNICITY) as predictors. The model is significant overall, with F(7, 161) = 7.72, p&lt; .001, and explains 22% of variance (adjusted R2 = 0.22).\n\n\nQ.22. What changes, when you compare the models with versus without ETHNICITY?\nA.22. If you compare the summaries, for the last two models, you can see that the proportion of variance explained, R-sq, decreases slightly to 22% (Adjusted R-squared = 0.2188), suggesting that adding ETHNICITY as a predictor does not help to predict response accuracy in tests of comprehension of health advice.\n\n\n\nWhy are we learning how to do this?\nR handles factors, by default, by picking one level (here, Asian) as the reference level (or baseline) and comparing outcomes to that baseline, for each other factor level (here, Other).\n\nThus, in this model, the effect of ETHNICITY is estimated as the difference in mean.acc outcome for Asian compared to participants coded as Black, Mixed, Other, White (BAME).\n\nThere are different ways to code factors for analysis. You will learn about these in second year classes.\n\n\n\nTask 13 – Fit a linear model including both numeric variables and categorical variables as predictors, and then plot the predicted effect of the factor (the categorical variable)\n\nHint: Task 12 – We first fit the model, including ETHNICITY, then use the ggpredict() function to get the predictions\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n            data = study.one.gen)\n\ndat &lt;- ggpredict(model, \"ETHNICITY\")\nplot(dat)\n\n\n\n\n\n\n\n\n\nQ.23. Compare the model summary and the prediction plot: what do they show you about the effect of ETHNICITY?\nA.23. If you compare the summary and the plot you can see that:\nthere are some differences in accuracy between people coded as belonging to different ethnic groups;\nbut these differences are very small and are not significant.\n\nNotice that the points in the plot represent model predictions of the average mean.acc accuracy of response for each group.\n\nThe vertical lines on the point represent uncertainty about those estimates and that uncertainty can be seen to be substantial.\nLonger lines represent more uncertainty."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "In Week 16, we aim to develop skills in visualizing and testing the associations between variables in psychological data.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like correlation and linear models.\nWe will consolidate and extend learning on data visualization:\n\nUse histograms to examine the distributions of variables;\nUse scatterplots to examine the relationships we may observe or predict.\n\n\n\nThis guide is designed to help you work out:\n\nhow to write or edit R code to do things like visualization or analysis;\nhow to identify key information for interpretation and reporting.\n\n\n\n\nI will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nI will split .Rmd scripts by steps, tasks and questions:\n\ndifferent steps for different phases of the analysis workflow;\ndifferent tasks for different things you need to do;\ndifferent questions to examine different ideas or coding challenges\n\n\n\n\nIn this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\n\nNotice that this dataset is different from the data you use to complete the Week 16 lab activity tasks or questions.\n\n\n\nTo begin, we set up our environment in R.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\n\n\n\n\nThe data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.\n\n\n\nUse the summary() or head() functions to take a look\n\nhead(study.one)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNote that head() will give you the top few rows of any dataset you have read into R.\n\nhead(...) is a function, and you put the name of the dataset inside the brackets to view it.\nsummary() will give you either descriptive statistics for variable columns classified as numeric or will tell you that columns in the dataset are not numeric\nsummary() is also a function and, again, you put the name of the dataset inside the brackets to view it\n\nUse the information in the summary view to answer the following questions.\n\nQ.1. What is the mean of mean.acc?\nA.1. 0.8163\nQ.2. What class is the variable study?\nA.2. character\nQ.3. – Does the summary indicate if any variable has missing values (NA)?\nQ.3. – No\n\n\n\n\n\n\n\nstudy.one$study &lt;- as.factor(study.one$study)\n\n\n\n\n\nQ.4. After you have done this, what information does summary() give you about the variable study?\n\n\nsummary(study.one)\n\n participant_ID        mean.acc        mean.self          study    \n Length:169         Min.   :0.3600   Min.   :3.440   studyone:169  \n Class :character   1st Qu.:0.7600   1st Qu.:6.080                 \n Mode  :character   Median :0.8400   Median :7.080                 \n                    Mean   :0.8163   Mean   :6.906                 \n                    3rd Qu.:0.9000   3rd Qu.:7.920                 \n                    Max.   :0.9900   Max.   :9.000                 \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\n\nA.4. We can see the number 169 beside the word studyone: this tells us that there are 169 observations, in the column, each one is a value: the word or character string studyone.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse ggplot() with geom_histogram().\nThe first time we do this, we take things step-by-step.\nHere’s an example: run the line of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.one ...) you tell R you want to make a plot with the study.one data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc\nhere, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\n\n\n\n\nQ.5. Did you get a message in the Console window in R-Studio: what does it say?\nA.5. The message says:\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nQ.6. What does binwidth refer to?\nhint: Q.6. You need to do a search online (e.g., using Google) with the keywords: “ggplot reference geom_histogram”\nA.6. If your search gets you to this page:\n\nhttps://ggplot2.tidyverse.org/reference/geom_histogram.html\n\nThen you will first see a technical definition “The width of the bins. Can be specified as a numeric value …”\nYou will second see examples of the use of the term e.g.\n\nggplot(diamonds, aes(carat)) + geom_histogram(binwidth = 0.01)\n\nIf you run the example code, it will produce a plot. Do it.\n\nIt is a very good idea to get get some experience doing searches online for information about working with data analysis tasks.\n\nYou will find that there is a lot of useful information, written in different ways for people with different levels of expertise\n\nHere, we are interested in working with binwidth in geom_histogram().\n\nThe example gives us a hint at what we can do: we can change the appearance of the bars in the histogram.\nThe bars in the histogram represent how often we observe, in a dataset, a grouping of similar values in a variable.\nLarger (wider) bins count more different values as similar.\nSo increasing binwidth will give you fewer wider bars in a histogram. Check it out.\n\n\n\n\n\n\n\nNote that binwidth needs to take into account the scale of the x variable:\n\nIt won’t work for mean.acc if you make binwidth = 100.\nThe number will need to be something between 0 and 1 (the min and max for mean.acc).\nTry a few different numbers, like this:\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram(binwidth = 0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we break the plot code into steps, it will make it easier to read, and it will make it easier to add edits e.g.\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nIf you run the selection of both lines, you get the code to work.\nHere, we are going to edit:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\n\nTake a look at how the code changes and how the plot changes with each edit to the code.\n\nThe appearance of the bars using binwidth\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2)\n\n\n\n\n\n\n\n\n\nThe colour of the background using theme_bw()\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe appearance of the labels using labs()\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency count\")\n\n\n\n\n\n\n\n\nNotice how each line – except the last one – ends in a +\n\nWhat we are doing is telling R we want this + this + this …\nEach line then adds an extra step.\n\n\n\n\n\nYou can break this code by not adding a + at the end of each bit (except the last line) Try it.\nggplot(data = study.one, aes(x = mean.acc))\n  geom_histogram(binwidth = 0.2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency\")\n\nQ.7. You will get an error message in the console window, orange and grey, if you omit a + like in the example: what is the error message?\nA.7. The message will read:\n\nError: Cannot add ggproto objects together. Did you forget to add this object to a ggplot object?\n\nRun `rlang::last_error()` to see where the error occurred.  \n\nQ.8. Copy and then paste the error message into Google: click on one of the results: do you see any useful information?\nA.8. An explanation of the problem is shown e.g. \n\nhttps://community.rstudio.com/t/could-anybody-help-me-cannot-add-ggproto-objects-together/11271\nR will give you hints – often in red – in error messages if something has gone wrong. This can be a bit frightening but usually you can fix a problem by:\n\nUsing trial and error: try changing things to see what happens;\nCopying the error message into an online search: usually, that will get you to a blog or discussion that is helpful.\n\nThe R community has many millions of people in it. The huge value of the community means that for every problem you encounter, someone else has already met that problem, solved it, and posted a blog online about how to fix it\n\n\n\n\n\n\n\nYou have seen these code moves before, in previous classes: we are strengthening skills by practising coding in different contexts\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.self, y = mean.acc)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nThis plot shows the possible association between x-axis variable mean.self and y-axis variable mean.acc\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot\nggplot(data = study.one, ...) with the study.one dataset\nggplot(...aes(x = mean.self, y = mean.acc)) using two aesthetic mappings\n\n\nx = mean.self map mean.self values to x-axis (horizontal, left to right) positions\ny = mean.acc- map mean.acc values to y-axis (vertical, bottom to top) positions\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\n\n\n\nggplot(data = study.one, aes(y = mean.self, x = mean.acc)) +\n    geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = AGE, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = SHIPLEY, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe appearance of the points using alpha and size;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\nThe appearance of the points using alpha and size\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2) \n\n\n\n\n\n\n\n\n\nThe colour of the background using theme_bw()\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2)  +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe appearance of the labels using labs()\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2)  +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean self rated accuracy\")\n\n\n\n\n\n\n\n\nThe arguments alpha and size can change the appearance of most geometric objects (geoms) in ggplot:\n\nIn the code example, here, we vary the alpha number to change how opaque or transparent the points are\nAnd we vary the size number to vary the size of the points.\n\n\n\n\n\n\n\n\nQ.9. – Can you find the ggplot reference page?\nhint: Q.9 – Do a search with the keywords “ggplot reference geom_point”\nA.9. – It is here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\nQ.10. – Can you change the colour of the points to a colour you like?\nhint: Q.10. – Useful information on colour can be found here:\n\nhttps://r-graphics.org/recipe-colors-setting\nSee also:\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\nA.10. – Here is how you do it:\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"hotpink\")  +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean self rated accuracy\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrevision: make sure you are confident about doing these things\n\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe can answer this question by examining whether mean self-rated accuracy of understanding correlates with mean accuracy of understanding. The logic is that if we can accurately rate our own understanding (from bad to good) then that rating should be associated – should be correlated with how accurately we can actually respond to questions that test that understanding.\n\n\n\n\n\ncor.test(study.one$mean.acc, study.one$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one$mean.acc and study.one$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\nQ.11. – What is r, the correlation coefficient?\nA.11. – r = 0.4863771\nQ.12. – Is the correlation significant?\nA.12. – r is significant\nQ.13. – What are the values for t and p for the significance test for the correlation?\nA.13. – t = 7.1936, p = 2.026e-11\nQ.14. – What do you conclude, given the correlation results?\nhint: Q.6 – Review the scatterplot you drew earlier to examine the shape of the association between these variables\nA.14. – mean.acc and mean.self are positively correlated suggesting that as mean.acc scores increase so also do mean.self scores"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#this-how-to-guide",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#this-how-to-guide",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "This guide is designed to help you work out:\n\nhow to write or edit R code to do things like visualization or analysis;\nhow to identify key information for interpretation and reporting."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#naming-things",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#naming-things",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#we-will-take-things-step-by-step",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#we-will-take-things-step-by-step",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "I will split .Rmd scripts by steps, tasks and questions:\n\ndifferent steps for different phases of the analysis workflow;\ndifferent tasks for different things you need to do;\ndifferent questions to examine different ideas or coding challenges"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "In this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\n\nNotice that this dataset is different from the data you use to complete the Week 16 lab activity tasks or questions."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-1-set-up",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-1-set-up",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "To begin, we set up our environment in R.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-2-load-the-data",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "The data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.\n\n\n\nUse the summary() or head() functions to take a look\n\nhead(study.one)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNote that head() will give you the top few rows of any dataset you have read into R.\n\nhead(...) is a function, and you put the name of the dataset inside the brackets to view it.\nsummary() will give you either descriptive statistics for variable columns classified as numeric or will tell you that columns in the dataset are not numeric\nsummary() is also a function and, again, you put the name of the dataset inside the brackets to view it\n\nUse the information in the summary view to answer the following questions.\n\nQ.1. What is the mean of mean.acc?\nA.1. 0.8163\nQ.2. What class is the variable study?\nA.2. character\nQ.3. – Does the summary indicate if any variable has missing values (NA)?\nQ.3. – No\n\n\n\n\n\n\n\nstudy.one$study &lt;- as.factor(study.one$study)\n\n\n\n\n\nQ.4. After you have done this, what information does summary() give you about the variable study?\n\n\nsummary(study.one)\n\n participant_ID        mean.acc        mean.self          study    \n Length:169         Min.   :0.3600   Min.   :3.440   studyone:169  \n Class :character   1st Qu.:0.7600   1st Qu.:6.080                 \n Mode  :character   Median :0.8400   Median :7.080                 \n                    Mean   :0.8163   Mean   :6.906                 \n                    3rd Qu.:0.9000   3rd Qu.:7.920                 \n                    Max.   :0.9900   Max.   :9.000                 \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\n\nA.4. We can see the number 169 beside the word studyone: this tells us that there are 169 observations, in the column, each one is a value: the word or character string studyone."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#revise-consolidate-what-you-know",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#revise-consolidate-what-you-know",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "Use ggplot() with geom_histogram().\nThe first time we do this, we take things step-by-step.\nHere’s an example: run the line of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.one ...) you tell R you want to make a plot with the study.one data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc\nhere, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\n\n\n\n\nQ.5. Did you get a message in the Console window in R-Studio: what does it say?\nA.5. The message says:\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nQ.6. What does binwidth refer to?\nhint: Q.6. You need to do a search online (e.g., using Google) with the keywords: “ggplot reference geom_histogram”\nA.6. If your search gets you to this page:\n\nhttps://ggplot2.tidyverse.org/reference/geom_histogram.html\n\nThen you will first see a technical definition “The width of the bins. Can be specified as a numeric value …”\nYou will second see examples of the use of the term e.g.\n\nggplot(diamonds, aes(carat)) + geom_histogram(binwidth = 0.01)\n\nIf you run the example code, it will produce a plot. Do it.\n\nIt is a very good idea to get get some experience doing searches online for information about working with data analysis tasks.\n\nYou will find that there is a lot of useful information, written in different ways for people with different levels of expertise\n\nHere, we are interested in working with binwidth in geom_histogram().\n\nThe example gives us a hint at what we can do: we can change the appearance of the bars in the histogram.\nThe bars in the histogram represent how often we observe, in a dataset, a grouping of similar values in a variable.\nLarger (wider) bins count more different values as similar.\nSo increasing binwidth will give you fewer wider bars in a histogram. Check it out.\n\n\n\n\n\n\n\nNote that binwidth needs to take into account the scale of the x variable:\n\nIt won’t work for mean.acc if you make binwidth = 100.\nThe number will need to be something between 0 and 1 (the min and max for mean.acc).\nTry a few different numbers, like this:\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.acc)) + geom_histogram(binwidth = 0.2)"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#extend-make-some-new-moves",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#extend-make-some-new-moves",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "If we break the plot code into steps, it will make it easier to read, and it will make it easier to add edits e.g.\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nIf you run the selection of both lines, you get the code to work.\nHere, we are going to edit:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\n\nTake a look at how the code changes and how the plot changes with each edit to the code.\n\nThe appearance of the bars using binwidth\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2)\n\n\n\n\n\n\n\n\n\nThe colour of the background using theme_bw()\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe appearance of the labels using labs()\n\n\nggplot(data = study.one, aes(x = mean.acc)) + \n  geom_histogram(binwidth = 0.2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency count\")\n\n\n\n\n\n\n\n\nNotice how each line – except the last one – ends in a +\n\nWhat we are doing is telling R we want this + this + this …\nEach line then adds an extra step.\n\n\n\n\n\nYou can break this code by not adding a + at the end of each bit (except the last line) Try it.\nggplot(data = study.one, aes(x = mean.acc))\n  geom_histogram(binwidth = 0.2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency\")\n\nQ.7. You will get an error message in the console window, orange and grey, if you omit a + like in the example: what is the error message?\nA.7. The message will read:\n\nError: Cannot add ggproto objects together. Did you forget to add this object to a ggplot object?\n\nRun `rlang::last_error()` to see where the error occurred.  \n\nQ.8. Copy and then paste the error message into Google: click on one of the results: do you see any useful information?\nA.8. An explanation of the problem is shown e.g. \n\nhttps://community.rstudio.com/t/could-anybody-help-me-cannot-add-ggproto-objects-together/11271\nR will give you hints – often in red – in error messages if something has gone wrong. This can be a bit frightening but usually you can fix a problem by:\n\nUsing trial and error: try changing things to see what happens;\nCopying the error message into an online search: usually, that will get you to a blog or discussion that is helpful.\n\nThe R community has many millions of people in it. The huge value of the community means that for every problem you encounter, someone else has already met that problem, solved it, and posted a blog online about how to fix it"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#revision-make-sure-you-are-confident-about-doing-these-things",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#revision-make-sure-you-are-confident-about-doing-these-things",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "You have seen these code moves before, in previous classes: we are strengthening skills by practising coding in different contexts\n\n\n\n\n\nggplot(data = study.one, aes(x = mean.self, y = mean.acc)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nThis plot shows the possible association between x-axis variable mean.self and y-axis variable mean.acc\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot\nggplot(data = study.one, ...) with the study.one dataset\nggplot(...aes(x = mean.self, y = mean.acc)) using two aesthetic mappings\n\n\nx = mean.self map mean.self values to x-axis (horizontal, left to right) positions\ny = mean.acc- map mean.acc values to y-axis (vertical, bottom to top) positions\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\n\n\n\nggplot(data = study.one, aes(y = mean.self, x = mean.acc)) +\n    geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = AGE, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = SHIPLEY, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point()  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe appearance of the points using alpha and size;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\nThe appearance of the points using alpha and size\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2) \n\n\n\n\n\n\n\n\n\nThe colour of the background using theme_bw()\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2)  +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe appearance of the labels using labs()\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2)  +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean self rated accuracy\")\n\n\n\n\n\n\n\n\nThe arguments alpha and size can change the appearance of most geometric objects (geoms) in ggplot:\n\nIn the code example, here, we vary the alpha number to change how opaque or transparent the points are\nAnd we vary the size number to vary the size of the points.\n\n\n\n\n\n\n\n\nQ.9. – Can you find the ggplot reference page?\nhint: Q.9 – Do a search with the keywords “ggplot reference geom_point”\nA.9. – It is here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\nQ.10. – Can you change the colour of the points to a colour you like?\nhint: Q.10. – Useful information on colour can be found here:\n\nhttps://r-graphics.org/recipe-colors-setting\nSee also:\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\nA.10. – Here is how you do it:\n\n\nggplot(data = study.one, aes(x = HLVA, y = mean.self)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"hotpink\")  +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean self rated accuracy\")"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-6-use-correlation-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-how-to.html#step-6-use-correlation-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w16-how-to",
    "section": "",
    "text": "revision: make sure you are confident about doing these things\n\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe can answer this question by examining whether mean self-rated accuracy of understanding correlates with mean accuracy of understanding. The logic is that if we can accurately rate our own understanding (from bad to good) then that rating should be associated – should be correlated with how accurately we can actually respond to questions that test that understanding.\n\n\n\n\n\ncor.test(study.one$mean.acc, study.one$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one$mean.acc and study.one$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\nQ.11. – What is r, the correlation coefficient?\nA.11. – r = 0.4863771\nQ.12. – Is the correlation significant?\nA.12. – r is significant\nQ.13. – What are the values for t and p for the significance test for the correlation?\nA.13. – t = 7.1936, p = 2.026e-11\nQ.14. – What do you conclude, given the correlation results?\nhint: Q.6 – Review the scatterplot you drew earlier to examine the shape of the association between these variables\nA.14. – mean.acc and mean.self are positively correlated suggesting that as mean.acc scores increase so also do mean.self scores"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "In Week 17, we aim to further develop skills in visualizing and testing the associations between variables in psychological data.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like the linear model.\nWhen we do these analyses, we need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model;\nwe usually need to decide, is the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nand is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\nfocusing on how we edit ggplot() code to produce professional looking plots.\n\n\n\nI will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this activity, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\n\n\n\n\nTo begin, we set up our environment in R.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\n\n\n\n\nThe data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.gen.\n\n\n\nUse the summary() or head() functions to take a look.\n\nhead(study.one.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNotice that:\n\nhead() will give you the top few rows of any dataset you have read into R.\nsummary() will give you either descriptive statistics for variable columns classified as numeric or will tell you that columns in the dataset are not numeric.\n\nPay attention to what you see, for the numeric variables, in the information about minimum (Min.) and maximum (Max.) values. You will use this informatio later when you engage in data visualization.\n\n\n\n\n\n\n\n\n\n\n\n\nUse ggplot() with geom_histogram().\nWhen we create a plot, we take things step-by-step.\nHere’s an example you have seen before: run the lines of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.one.gen, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.one.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\nNotice that the code works the same whether we have the different bits of code on the same line or in a series of lines.\n\n\n\n\n\n\nWe are going to revise editing:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\n\nWe proceed to revise:\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency count\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40) +\n  geom_vline(xintercept = mean(study.one.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\nIt is often useful to define the limits on the x-axis and on the y-axis:\n\nBecause we want to show the audience where the sample values are distributed compared to where they could be distributed, given the measure.\nThis makes sense e.g. if you want to see the relative age distribution of a sample compared to the population.\nBecause we want plots, shown side by side to be directly comparable.\nAnd because we want to give the audience a more accurate picture of the data.\n\nYou can see ggplot reference information on setting limits here:\nhttps://ggplot2.tidyverse.org/reference/lims.html\nNotice that we used the geom_vline() in:\ngeom_vline(xintercept = mean(study.one.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nto plot a vertical line at the location on the x-axis we define.\n\nWe do this in the steps:\n\ngeom_vline(...) draw a vertical line;\n...xintercept... draw the line so it hits the x-axis (intercepts the x-axis);\n...xintercept = mean(study.one.gen$SHIPLEY... defined by the mean of the variable mean(study.one.gen$SHIPLEY);\n...colour = \"red\", size = 1.5... make the line red and make the line one and a half times thicker than the default line thickness.\n\nSee ggplot() reference information for this new geom is here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRun a chunk of code to make the plot.\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThis plot shows:\n\nthe possible association between x-axis variable SHIPLEY and y-axis variable mean.acc.\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot;\nggplot(data = study.one.gen, ...) with the study.one.gen dataset;\nggplot(...aes(x = SHIPLEY, y = mean.acc)) using two aesthetic mappings\n\n\nx = SHIPLEY map SHIPLEY values to x-axis (horizontal, left to right) positions;\ny = mean.acc map mean.acc values to y-axis (vertical, bottom to top) positions;\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\n\n\n\nWe are going to revise making edits to:\n\nthe appearance of the points using alpha, size, shape, and colour;\nthe colour of the background using theme_bw();\nthe appearance of the labels using labs().\n\nWe are then going to try out some new moves:\n\nSet the x-axis and y-axis limits to the potential minimum-maximum ranges of the variables we plot.\n\nHere, “potential” references the fact that e.g. SHIPLEY scores can start at 0 (a person gets 0 responses correct) and has a maximum of 40 (a person could get all responses correct, for up to 40 items).\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\") \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\nNotice that I set the x-axis limits to the minimum (0) and maximum (40) possible values for the SHIPLEY variable. - I set the y-axis limits to the minimum (0) and maximum (1) possible values for the mean accuracy variable mean.acc.\n\n\n\nIt is generally a good idea to show the minimum value (the origin) for each variable. Not doing this i.e. showing a more narrow slice of the sample range is an easy way to exaggerate the strength of associations or to imply incorrectly the breadth in variation.\nYou can change the transparency (alpha), size, colour and shape of important parts of a plot.\n\nHere, we are changing the appearance of the points.\nBut you can also change the transparency (alpha), size, colour and shape of reference lines added to a plot.\n\nThe ggplot geom_point()reference information is here:\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\nwhere you can see some examples of the edits we have done.\n\nSome useful information about shape options is here:\nhttp://www.cookbook-r.com/Graphs/Shapes_and_line_types/\nSome useful information about colourons is here:\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\n\n\n\n\n\n\n\n\n\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\n\n\n\nFit the model and get a summary of the model statistics.\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\nNotice that we do the linear model in the steps:\n\nmodel &lt;- lm(...) fit the model using lm(...), give the model a name – here, we call it “model”;\n...lm(mean.acc ~ SHIPLEY...) tell R you want a model of the outcome mean.acc predicted (~) by the predictor SHIPLEY;\n...data = study.one.gen) tell R that the variables you name in the formula live in the study.one.gen dataset;\nsummary(model) ask R for a summary of the model you called “model”.\n\nNotice: R has a general formula syntax: outcome ~ predictor or y ~ x\n\nand uses the same format across a number of different functions;\neach time, the left of the tilde symbol ~ is some output or outcome;\nand the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\n\nIf you look at the model summary you can answer the following questions.\n\nQ.5. What is the estimate for the coefficient of the effect of the predictor, SHIPLEY?\nA.5. 0.01050\nQ.6. Is the effect significant?\nA.6. It is significant, p &lt; .05\nQ.7. What are the values for t and p for the significance test for the coefficient?\nA.7. t = 4.585, p = 8.85e-06\nQ.8. What do you conclude is the answer to the research question, given the linear model results?\nA.8. The model slope estimate suggests that as SHIPLEY scores increase so mean.acc scores increase also.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe line will show the model predictions, given the model intercept and effect coefficient estimates.\nFirst fit a model and get a summary: model the relationship between mean.acc and SHIPLEY\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\nQ.9. What is the coefficient estimate for the intercept?\nA.9. 0.44914\nQ.10. What is the coefficient estimate for the slope of SHIPLEY?\nA.10. 0.01050\n\nSecond, use the geom_abline() function to draw the line:\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  geom_abline(intercept = 0.44914, slope = 0.01050, colour = \"red\", size = 1.5) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\nYou can see that what we do is:\n\nadd the geom_abline(...) function;\nand into that function code, we add information about the intercept and the slope which we take from the model summary.\n\nYou can see reference information here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html\nNote that we can get the prediction line drawn for us automatically, as:\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  # geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = `square`)   +\n  geom_smooth(method = \"lm\", colour = \"purple\", alpha = .2, size = 2.5, se = FALSE) +\n  geom_abline(intercept = 0.44914, slope = 0.01050, colour = \"red\", size = 1) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)  \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nHere, I turned the points off by commenting them out, adding # to the start of the line.\nAnd I added geom_smooth(method = \"lm\", ...) to draw a prediction line.\nYou can compare the red prediction line I drew using the model estimates\nwith the purple line I used geom_smooth() to draw automatically to see that they are identical\n\nThis shows you something of what geom_smooth() does. It is very useful:\nhttps://ggplot2.tidyverse.org/reference/geom_smooth.html"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#naming-things",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#naming-things",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "In this activity, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-1-set-up",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-1-set-up",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "To begin, we set up our environment in R.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-2-load-the-data",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "The data file is called:\n\nstudy-one-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.one.gen.\n\n\n\nUse the summary() or head() functions to take a look.\n\nhead(study.one.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\n\nNotice that:\n\nhead() will give you the top few rows of any dataset you have read into R.\nsummary() will give you either descriptive statistics for variable columns classified as numeric or will tell you that columns in the dataset are not numeric.\n\nPay attention to what you see, for the numeric variables, in the information about minimum (Min.) and maximum (Max.) values. You will use this informatio later when you engage in data visualization."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "Use ggplot() with geom_histogram().\nWhen we create a plot, we take things step-by-step.\nHere’s an example you have seen before: run the lines of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.one.gen, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.one.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\nNotice that the code works the same whether we have the different bits of code on the same line or in a series of lines.\n\n\n\n\n\n\nWe are going to revise editing:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using labs().\n\nWe proceed to revise:\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"mean accuracy\", y = \"frequency count\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40) +\n  geom_vline(xintercept = mean(study.one.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\nIt is often useful to define the limits on the x-axis and on the y-axis:\n\nBecause we want to show the audience where the sample values are distributed compared to where they could be distributed, given the measure.\nThis makes sense e.g. if you want to see the relative age distribution of a sample compared to the population.\nBecause we want plots, shown side by side to be directly comparable.\nAnd because we want to give the audience a more accurate picture of the data.\n\nYou can see ggplot reference information on setting limits here:\nhttps://ggplot2.tidyverse.org/reference/lims.html\nNotice that we used the geom_vline() in:\ngeom_vline(xintercept = mean(study.one.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nto plot a vertical line at the location on the x-axis we define.\n\nWe do this in the steps:\n\ngeom_vline(...) draw a vertical line;\n...xintercept... draw the line so it hits the x-axis (intercepts the x-axis);\n...xintercept = mean(study.one.gen$SHIPLEY... defined by the mean of the variable mean(study.one.gen$SHIPLEY);\n...colour = \"red\", size = 1.5... make the line red and make the line one and a half times thicker than the default line thickness.\n\nSee ggplot() reference information for this new geom is here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-4-now-draw-scatterplots-to-examine-associations-between-variables",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-4-now-draw-scatterplots-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "Run a chunk of code to make the plot.\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThis plot shows:\n\nthe possible association between x-axis variable SHIPLEY and y-axis variable mean.acc.\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot;\nggplot(data = study.one.gen, ...) with the study.one.gen dataset;\nggplot(...aes(x = SHIPLEY, y = mean.acc)) using two aesthetic mappings\n\n\nx = SHIPLEY map SHIPLEY values to x-axis (horizontal, left to right) positions;\ny = mean.acc map mean.acc values to y-axis (vertical, bottom to top) positions;\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\n\n\n\nWe are going to revise making edits to:\n\nthe appearance of the points using alpha, size, shape, and colour;\nthe colour of the background using theme_bw();\nthe appearance of the labels using labs().\n\nWe are then going to try out some new moves:\n\nSet the x-axis and y-axis limits to the potential minimum-maximum ranges of the variables we plot.\n\nHere, “potential” references the fact that e.g. SHIPLEY scores can start at 0 (a person gets 0 responses correct) and has a maximum of 40 (a person could get all responses correct, for up to 40 items).\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\") \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\nNotice that I set the x-axis limits to the minimum (0) and maximum (40) possible values for the SHIPLEY variable. - I set the y-axis limits to the minimum (0) and maximum (1) possible values for the mean accuracy variable mean.acc.\n\n\n\nIt is generally a good idea to show the minimum value (the origin) for each variable. Not doing this i.e. showing a more narrow slice of the sample range is an easy way to exaggerate the strength of associations or to imply incorrectly the breadth in variation.\nYou can change the transparency (alpha), size, colour and shape of important parts of a plot.\n\nHere, we are changing the appearance of the points.\nBut you can also change the transparency (alpha), size, colour and shape of reference lines added to a plot.\n\nThe ggplot geom_point()reference information is here:\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\n\nwhere you can see some examples of the edits we have done.\n\nSome useful information about shape options is here:\nhttp://www.cookbook-r.com/Graphs/Shapes_and_line_types/\nSome useful information about colourons is here:\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-5-use-a-linear-model-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-5-use-a-linear-model-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "One of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\n\n\n\nFit the model and get a summary of the model statistics.\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\nNotice that we do the linear model in the steps:\n\nmodel &lt;- lm(...) fit the model using lm(...), give the model a name – here, we call it “model”;\n...lm(mean.acc ~ SHIPLEY...) tell R you want a model of the outcome mean.acc predicted (~) by the predictor SHIPLEY;\n...data = study.one.gen) tell R that the variables you name in the formula live in the study.one.gen dataset;\nsummary(model) ask R for a summary of the model you called “model”.\n\nNotice: R has a general formula syntax: outcome ~ predictor or y ~ x\n\nand uses the same format across a number of different functions;\neach time, the left of the tilde symbol ~ is some output or outcome;\nand the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\n\nIf you look at the model summary you can answer the following questions.\n\nQ.5. What is the estimate for the coefficient of the effect of the predictor, SHIPLEY?\nA.5. 0.01050\nQ.6. Is the effect significant?\nA.6. It is significant, p &lt; .05\nQ.7. What are the values for t and p for the significance test for the coefficient?\nA.7. t = 4.585, p = 8.85e-06\nQ.8. What do you conclude is the answer to the research question, given the linear model results?\nA.8. The model slope estimate suggests that as SHIPLEY scores increase so mean.acc scores increase also."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-6-use-a-linear-model-to-generate-predictions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-how-to.html#step-6-use-a-linear-model-to-generate-predictions",
    "title": "2023-24-PSYC122-w17-how-to",
    "section": "",
    "text": "The line will show the model predictions, given the model intercept and effect coefficient estimates.\nFirst fit a model and get a summary: model the relationship between mean.acc and SHIPLEY\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\nQ.9. What is the coefficient estimate for the intercept?\nA.9. 0.44914\nQ.10. What is the coefficient estimate for the slope of SHIPLEY?\nA.10. 0.01050\n\nSecond, use the geom_abline() function to draw the line:\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = \"square\")   +\n  geom_abline(intercept = 0.44914, slope = 0.01050, colour = \"red\", size = 1.5) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\nYou can see that what we do is:\n\nadd the geom_abline(...) function;\nand into that function code, we add information about the intercept and the slope which we take from the model summary.\n\nYou can see reference information here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html\nNote that we can get the prediction line drawn for us automatically, as:\n\nggplot(data = study.one.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  # geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = `square`)   +\n  geom_smooth(method = \"lm\", colour = \"purple\", alpha = .2, size = 2.5, se = FALSE) +\n  geom_abline(intercept = 0.44914, slope = 0.01050, colour = \"red\", size = 1) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)  \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nHere, I turned the points off by commenting them out, adding # to the start of the line.\nAnd I added geom_smooth(method = \"lm\", ...) to draw a prediction line.\nYou can compare the red prediction line I drew using the model estimates\nwith the purple line I used geom_smooth() to draw automatically to see that they are identical\n\nThis shows you something of what geom_smooth() does. It is very useful:\nhttps://ggplot2.tidyverse.org/reference/geom_smooth.html"
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html",
    "title": "2023-24-PSYC122-w19-workbook-answers",
    "section": "",
    "text": "In Week 19, we aim to further develop skills in working with the linear model.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nIn Week 19, we use data contributed by PSYC122 students to figure out our answers to these questions.\nWe compare PSYC122 results to the results from a previous study so that we can assess the robustness of our findings.\nIn this class, what is new is our focus on critically evaluating – comparing, reflecting on – the evidence from more than one relevant study.\n\nThis work simulates the kind of critical evaluation of evidence that psychologists must do in professional research.\n\n\n\nI will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\n\nData from a study we conducted on the response of adults from a UK national participant sample:\n\n\nstudy-two-general-participants.csv\n\n\nData comprising the responses of PSYC122 students:\n\n\n2023-24_PSYC122-participants.csv\n\nNotice that study-two participants and the PSYC122 participants were given similar tests but different health information texts to read and respond to."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#naming-things",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#naming-things",
    "title": "2023-24-PSYC122-w19-workbook-answers",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w19-workbook-answers",
    "section": "",
    "text": "Data from a study we conducted on the response of adults from a UK national participant sample:\n\n\nstudy-two-general-participants.csv\n\n\nData comprising the responses of PSYC122 students:\n\n\n2023-24_PSYC122-participants.csv\n\nNotice that study-two participants and the PSYC122 participants were given similar tests but different health information texts to read and respond to."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-1-set-up",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-1-set-up",
    "title": "2023-24-PSYC122-w19-workbook-answers",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"ggeffects\")\n\nWarning: package 'ggeffects' was built under R version 4.2.3\n\nlibrary(\"patchwork\")\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-2-load-the-data",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w19-workbook-answers",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data files we will be using\nThe data files are called:\n\nstudy-two-general-participants.csv\n2023-24_PSYC122-participants.csv\n\nUse the read_csv() function to read the data files into R:\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")  \n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstudy.122 &lt;- read_csv(\"2023-24_PSYC122-participants.csv\")  \n\nRows: 65 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): ResponseId, GENDER, EDUCATION, ETHNICITY, NATIVE.LANGUAGE, OTHER.LA...\ndbl (8): AGE, EDUCATION.rating_1, ENGLISH.PROFICIENCY, SHIPLEY, HLVA, FACTOR...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data files in, give the data objects you create distinct name e.g. study.two.gen versus study.122.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look at both datasets.\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\nsummary(study.122)\n\n  ResponseId             AGE           GENDER           EDUCATION        \n Length:65          Min.   :18.00   Length:65          Length:65         \n Class :character   1st Qu.:18.00   Class :character   Class :character  \n Mode  :character   Median :19.00   Mode  :character   Mode  :character  \n                    Mean   :19.42                                        \n                    3rd Qu.:19.00                                        \n                    Max.   :56.00                                        \n                                                                         \n EDUCATION.rating_1  ETHNICITY         NATIVE.LANGUAGE    OTHER.LANGUAGE    \n Min.   :4.000      Length:65          Length:65          Length:65         \n 1st Qu.:7.000      Class :character   Class :character   Class :character  \n Median :7.000      Mode  :character   Mode  :character   Mode  :character  \n Mean   :7.077                                                              \n 3rd Qu.:8.000                                                              \n Max.   :9.000                                                              \n                                                                            \n ENGLISH.PROFICIENCY  OCCUPATION           SHIPLEY           HLVA       \n Min.   :1.000       Length:65          Min.   :10.00   Min.   : 1.000  \n 1st Qu.:2.500       Class :character   1st Qu.:30.00   1st Qu.: 7.000  \n Median :3.000       Mode  :character   Median :32.00   Median : 8.000  \n Mean   :2.571                          Mean   :32.31   Mean   : 8.508  \n 3rd Qu.:3.000                          3rd Qu.:36.00   3rd Qu.:10.000  \n Max.   :3.000                          Max.   :40.00   Max.   :14.000  \n NA's   :58                                                             \n    FACTOR3         mean.acc        mean.self   \n Min.   :28.00   Min.   :0.2500   Min.   :2.60  \n 1st Qu.:43.00   1st Qu.:0.7500   1st Qu.:6.20  \n Median :46.00   Median :0.8500   Median :7.00  \n Mean   :46.91   Mean   :0.8231   Mean   :6.92  \n 3rd Qu.:52.00   3rd Qu.:0.9500   3rd Qu.:7.80  \n Max.   :61.00   Max.   :1.0000   Max.   :9.00"
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-3-compare-the-data-from-the-different-studies",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-3-compare-the-data-from-the-different-studies",
    "title": "2023-24-PSYC122-w19-workbook-answers",
    "section": "Step 3: Compare the data from the different studies",
    "text": "Step 3: Compare the data from the different studies\n\nRevise: practice to strengthen skills\n\n\nTask 5 – Compare the data distributions from the two studies\n\nQ.1. What is the mean of the mean.acc and SHIPLEY variables in the two studies?\nA.1. The means are:\nstudy two – mean.acc: mean = 0.7596\nstudy two – SHIPLEY: mean = 35.13\nstudy PSYC122 – mean.acc: mean = 0.8231\nstudy PSYC122 – SHIPLEY: mean = 32.31\nQ.2. Draw histograms of both mean.acc and mean.self for both studies.\nA.2. You can write the code as you have been shown to do e.g. in 2023-24-PSYC122-w19-how-to.Rmd:\n\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0, 40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.122, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.122, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0, 40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\n\nTask 6 – Create grids of plots to make the comparison easier to do\n\n\nhint: Task 6 – What we are going to do is to create two histograms and then present them side by side to allow easy comparison of variable distributions\nWe need to make two changes to the coding approach you have been using until now.\nBefore we explain anything, let’s look at an example: run these line of code and check the result.\n\nMake sure you identify what is different about the plotting code, shown following, compared to what you have done before: there is a surprise in what is going to happen.\n\nFirst, create plot objects, give them names, but do not show them:\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study Two\") +\n  xlim(0, 1)\n\nplot.122 &lt;- ggplot(data = study.122, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study PSYC122\") +\n  xlim(0, 1)\n\nSecond, show the plots, side-by-side:\n\nplot.two + plot.122\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nThis is what you are doing: check out the process, step-by-step. (And notice that you repeat the process for each of two (or more) plots.)\n\nggplot(...) tell R you want to make a plot using the ggplot() function;\nplot.one &lt;- tell R you want to give the plot a name; the name appears in the environment;\nggplot(data = study.two.gen ...) tell R you want to make a plot with the study.two data;\nggplot(..., aes(x = mean.acc)) tell R that you want to make a plot with the variable mean.acc;\n\n\nhere, specify the aesthetic mapping, x = mean.acc\n\n\ngeom_histogram() tell R you want to plot values of mean.acc as a histogram;\nbinwidth = .1 adjust the binwidth to show enough detail but not too much in the distribution;\ntheme_bw() tell R what theme you want, adjusting the plot appearance;\nlabs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study Two\") fix the x-axis and y-axis labels;\n\n\nhere, add a title for the plot, so you can tell the two plots apart;\n\n\nxlim(0, 1) adjust the x-axis limits to show the full range of possible score values on this variable.\n\nDo this process twice, once for each dataset, creating two plots so that you can compare the distribution of mean.acc scores between the studies.\nFinally, having created the two plots, produce them for viewing:\n\nplot.two + plot.122 having constructed – and named – both plots, you enter their names, separated by a +, to show them in a grid of two plots.\n\nNotice: until you get to step 10, nothing will appear. This will be surprising but it is perfectly normal when we increase the level of complexity of the plots we build.\n\nYou first build the plots.\nYou are creating plot objects and you give these objects names.\nThe objects will appear in the Environment with the names you give them.\nYou then produce the plots for viewing, by using their names.\n\nUntil you complete the last step, you will not see any changes until you use the object names to produce them for viewing.\nThis is how you construct complex arrays of plots.\n\n\nTask 7 – Try this out for yourself, focusing now on the distribution of SHIPLEY scores in the two studies\nFirst, create plot objects but do not show them.\n\nGive each plot a name. You will use the names next.\n\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\", title = \"Study Two\") +\n  xlim(0, 40)\n\nplot.122 &lt;- ggplot(data = study.122, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\", title = \"PSYC122\") +\n  xlim(0, 40)\n\nSecond produce the plots for viewing, side-by-side, by naming them.\n\nplot.two + plot.122\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nQ.3. Now use the plots to do some data analysis work: how do the SHIPLEY distributions compare, when you compare the SHIPLEY of study.two.gen versus SHIPLEY of study.122?\nA.3. When you compare the plots side-by-side you can see that the SHIPLEY distributions are mostly similar: most people have high SHIPLEY scores.\n\nBut you can also see striking differences:\n\nThe peak of the distribution – where the tallest bar is – is at a higher SHIPLEY score in study.two.gen (around SHIPLEY = 37-38) than in study.122 (where is it around SHIPLEY = 30).\nThere appear to be fewer participants with lower SHIPLEY scores in study.122 than in study.two.\nQ.4. Is the visual impression you get from comparing the distributions consistent with the statistics you see in the summary?\nA.4. Yes: If you go back to the summary of SHIPLEY, comparing the two studies datasets, then you can see that the median and mean are higher in study.122 than in study.two.gen."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-4-now-use-scatterplots-and-correlation-to-examine-associations-between-variables",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-4-now-use-scatterplots-and-correlation-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w19-workbook-answers",
    "section": "Step 4: Now use scatterplots and correlation to examine associations between variables",
    "text": "Step 4: Now use scatterplots and correlation to examine associations between variables\n\nRevise: practice to strengthen skills\n\n\nTask 8 – Draw scatterplots to compare the potential association between mean.acc and mean.self in both study.two.gen and study.122 datasets\n\n\nhint: Task 8 – The plotting steps are explained in some detail in 2023-24-PSYC122-w17-how-to.Rmd and you can see example code in 2023-24-PSYC122-w19-how-to.Rmd\n\nggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(data = study.122, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nTask 9 – Create a grid of plots to make the comparison easier to do\n\n\nhint: Task 9 – We follow the same steps as we used in tasks 6 and 7 to create the plots\nWe again:\n\nFirst construct the plot objects and give them names;\ncreate and show a grid of named plots.\n\nThough this time we are producing a grid of scatterplots.\nFirst, create plot objects, give them names, but do not show them:\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\nplot.122 &lt;- ggplot(data = study.122, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\nSecond name the plots, to show them side-by-side in the plot window:\n\nplot.two + plot.122\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNow use the plots to make comparison judgments.\n\nQ.5. How does the association, shown in the plots, between mean.self and mean.acc compare when you look at the study.two.gen versus the study.122 plot?\nhint: Q.5. When comparing evidence about associations in different studies, we are mostly going to focus on the slope – the angle – of the prediction lines, and the ways in which points do or do not cluster about the prediction lines.\nA.5. If you examine the study.two.gen versus the study.122 plots then you can see that in both plots higher mean.self scores appear to be associated with higher mean.acc scores. But the trend maybe is a bit stronger – the line is steeper – in study.two.gen.\n\nWe are now in a position to answer one of our research questions:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nIf people can accurately evaluate whether they correctly understand written health information then mean.self (a score representing their evaluation) should be associated with mean.acc (a score representing their accuracy of understanding) for each person.\n\n\nRevise: practice to strengthen skills\n\n\nTask 10 – Can you estimate the association between mean.acc and mean.self in both datasets?\n\n\nhint: Task 10 – We use cor.test() as you have been shown how to do e.g. in 2023-24-PSYC122-w16-how-to.Rmd\nDo the correlation for both datasets.\nFirst, look at the correlation between mean.acc and mean.self in study.two:\n\ncor.test(study.two.gen$mean.acc, study.two.gen$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$mean.acc and study.two.gen$mean.self\nt = 8.4991, df = 170, p-value = 9.356e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4317217 0.6431596\nsample estimates:\n      cor \n0.5460792 \n\n\n\nQ.6. What is r, the correlation coefficient?\nA.6. r = 0.5460792\nQ.7. Is the correlation significant?\nA.7. r is significant\nQ.8. What are the values for t and p for the significance test for the correlation?\nA.8. t = 8.4991, p = 9.356e-15\n\nSecond, look at the correlation between mean.acc and mean.self in study.122:\n\ncor.test(study.122$mean.acc, study.122$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.122$mean.acc and study.122$mean.self\nt = 3.4924, df = 63, p-value = 0.0008808\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1761474 0.5888052\nsample estimates:\n      cor \n0.4027438 \n\n\n\nQ.9. What is r, the correlation coefficient?\nA.9. r = 0.4027438\nQ.10. Is the correlation significant?\nA.10. r is significant\nQ.11. What are the values for t and p for the significance test for the correlation?\nA.11. t = 3.4924, p = 0.0008808\n\nNow we can answer the research question:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nQ.12. What do the correlation estimates tell you is the answer to the research question?\nA.12.\n\n\nThe correlations are positive and significant, indicating that higher mean.self (evaluations) are associated with higher mean.acc (understanding), suggesting that people can judge their accuracy of understanding.\n\n\nQ.13. Can you compare the estimates, given the two datasets, to evaluate if the result in study.two.gen is replicated in study.122?\nhint: Q.13. We can judge if the result in a study is replicated in another study by examining if – here – the correlation coefficient is significant in both studies and if the coefficient has the same size and sign in both studies.\nA.13. If you compare the correlation estimates from both study.two.gen and study.122 you can see:\nfirst, the correlation is significant in both study.two.gen and study.122;\nsecond, the correlation is positive in both studies.\n\nBut, if you compare the correlation estimates, you can see that the coefficient estimate is smaller in study.122 (where r = .40) than in study.two.gen (where r = .55).\nThis may suggest that the association observed in study.two.gen is different from the association in study.122, for some reason.\n\n\nTask 11 – In working with R to do data analysis, we often work with libraries of function like {tidyverse} that enable us to do things (see the week 19 lecture for discussion).\nIn this way, we are using the {patchwork} library so that we can create plots and then present them in a grid.\nCan you find the online information about {patchwork} and use it to adjust the layout of the grids of plots you are using?\n\n\nhint: Task 11 – To find out more information about a function or a library in R, do a search for the keywords\nYou can do a search, using any search engine (e.g., Bing, Chrome, Google), by entering:\n\nin r …\n\nAnd pasting the words you want to know about to replace the ... e.g. “in r patchwork”.\nYou will then see a list of results including the link to the {patchwork} information:\nhttps://patchwork.data-imaginist.com"
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-5-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.html#step-5-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "title": "2023-24-PSYC122-w19-workbook-answers",
    "section": "Step 5: Use a linear model to to answer the research questions – multiple predictors",
    "text": "Step 5: Use a linear model to to answer the research questions – multiple predictors\n\nRevise: practice to strengthen skills\n\n\nTask 12 – Examine the relation between outcome mean accuracy (mean.acc) and multiple predictors\nWe specify linear models including as predictors the variables:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\n\nhint: Task 12 – We use lm(), as we have been doing before, see e.g. 2023-24-PSYC122-w18-how-to.R\n\n\nTask 12 – Examine the predictors of mean accuracy (mean.acc), first, for the study.two.gen data\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,    Adjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: &lt; 2.2e-16\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:\n\nQ.14. What is the estimate for the coefficient of the effect of the predictor SHIPLEY in this model?\nA.14. 0.008397\nQ.15. Is the effect significant?\nA.15. It is significant, p &lt; .05\nQ.16. What are the values for t and p for the significance test for the coefficient?\nA.16. t = 4.533, p = 1.1e-05\nQ.17. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.two.gen data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.17. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\nA.17.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 168) = 31.99, p&lt; .001, and explains 35% of variance (adjusted R2 = 0.35). Mean accuracy was predicted to be higher given higher scores in health literacy (HLVA estimate = .018, t = 4.90, p &lt; .001), vocabulary knowledge (SHIPLEY estimate = .008, t = 4.53, p &lt; .001), and reading strategy (FACTOR3 estimate = .003, t = 2.68, p = .008).\n\n\n\nTask 13 – Examine the predictors of mean accuracy (mean.acc), now, for the study.122 data\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.37214 -0.07143 -0.01102  0.07411  0.25329 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.3066150  0.1447265   2.119   0.0382 *  \nHLVA        0.0335342  0.0071332   4.701 1.52e-05 ***\nSHIPLEY     0.0062524  0.0034741   1.800   0.0768 .  \nFACTOR3     0.0006217  0.0024450   0.254   0.8001    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1162 on 61 degrees of freedom\nMultiple R-squared:  0.4158,    Adjusted R-squared:  0.3871 \nF-statistic: 14.47 on 3 and 61 DF,  p-value: 3.156e-07\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:\n\nQ.18. What is the estimate for the coefficient of the effect of the predictor, HLVA, in this model?\nA.18. 0.0335342\nQ.19. Is the effect significant?\nA.19. It is significant, p &gt; .05 because p = 1.52e-05\nQ.20. What are the values for t and p for the significance test for the coefficient?\nA.20. t = 4.701, p &lt; .001\nQ.21. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.122 data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.21. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\nA.21.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 61) = 14.47, p &lt; .001, and explains 39% of variance (adjusted R2 = .387). Mean accuracy was predicted to be higher given higher scores in health literacy (HLVA estimate = .034, t = 4.70, p &lt; .001). There were non-significant effects of individual differences in vocabulary knowledge (SHIPLEY estimate = .006, t = 1.80, p = .077) and reading strategy (FACTOR3 estimate = .001, t = .25, p = .800).\n\n\nAt this point, we can evaluate the evidence from the PSYC122 sample – based on your responses – to assess if the patterns, the estimates, we saw previously are repeated in analyses of PSYC122 responses.\nQ.22. Are the findings from study.two.gen replicated in study.122?\nhint: Q.22. We can judge if the results in an earlier study are replicated in another study by examining if – here – the linear model estimates are significant in both studies and if the coefficient estimates have the same size and sign in both studies.\nA.22. If you compare the linear model coefficient estimates from both the study.two.gen and study.122 models, you can see:\nfirst, that the HLVA effect estimate is significant in both study.two.gen and study.122;\nsecond, that the estimates of the HLVA effect have the same sign – positive – in both studies while the estimated coefficient is a bit bigger in the study.122 data (implying a stronger effect);\nbut, third that the estimates of the effects of variation in vocabulary knowledge (SHIPLEY) and reading strategy (FACTOR3) are significant in study.two.gen but not in study.122.\n\nThis suggests that the attributes – the set of abilities – that predict comprehension accuracy are similar but not the same in the study.two.gen participants compared to study.122 participants.\n\nQ.23. How would you describe the outstanding difference between the results of the two studies?\nhint: Q.23. We can look at the estimates but we can also use the model prediction plotting code you used before, see:\n2022-23-PSYC122-w18-how-to.R\n2022-23-PSYC122-w19-how-to.R\nhint: Q.23. Let’s focus on comparing the study.two.gen and study.122 estimates for the effect of HLVA in both models: we can plot model predictions, for comparison:\n\nFirst: fit the models – using different names for the different models:\n\nmodel.two &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model.two)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,    Adjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: &lt; 2.2e-16\n\nmodel.122 &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\nsummary(model.122)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.37214 -0.07143 -0.01102  0.07411  0.25329 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.3066150  0.1447265   2.119   0.0382 *  \nHLVA        0.0335342  0.0071332   4.701 1.52e-05 ***\nSHIPLEY     0.0062524  0.0034741   1.800   0.0768 .  \nFACTOR3     0.0006217  0.0024450   0.254   0.8001    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1162 on 61 degrees of freedom\nMultiple R-squared:  0.4158,    Adjusted R-squared:  0.3871 \nF-statistic: 14.47 on 3 and 61 DF,  p-value: 3.156e-07\n\n\nSecond, create prediction plots for the HLVA effect for each model:\n\ndat.two &lt;- ggpredict(model.two, \"HLVA\")\nplot.two &lt;- plot(dat.two) + labs(title = \"Study Two\")\ndat.122 &lt;- ggpredict(model.122, \"HLVA\")\nplot.122 &lt;- plot(dat.122) + labs(title = \"Study PSYC122\")\n\nThird, show the plots side-by-side:\n\nplot.two + plot.122\n\n\n\n\n\n\n\n\n\nA.23. If we compare the estimates for the coefficient of the HLVA effect in the study.two.gen and study.122 models we can see that:\n\n\nThe health literacy HLVA effect is significant in both study.two.gen and study.122.\nThe effect trends positive in both studies.\nThe coefficient estimate is bigger in study.122 than in study.two.gen.\nThe prediction plots suggest the prediction line slope is steeper in study.122.\nThe grey shaded area around the trend line (indicating our uncertainty about the estimated trend) is wider for study.two.gen than for study.122, suggesting we are more uncertain about the association for the study.two.gen data.\n\n\nThe breadth of the grey shaded area around the trend line is hard to compare between the two plots. You have to look carefully at the y-axis scale information to make a judgment about the relative width of these uncertainty ellipses.\n\nThe visualizations plus the model summaries suggests that the estimates of the effect of health literacy are different in the study.122 compared to the study.two.gen data. Why is that?\n\nWe can redraw the prediction plots to add in more information about our samples. This change, see following, will help us to interpret the results of the analyses we have done.\nAnd that will help you to see why data visualization and data analysis work well together.\n\n\n\nTask 14 – In producing prediction plots, we are using functions from the {ggefects} library. Can you locate online information about working with the library functions?\nTry doing a search with the key words: in r ggeffects.\nIf you do that, you will see links to the website:\nhttps://strengejacke.github.io/ggeffects/\n\n\nTask 15 – In the {ggeffects} online information, you can see links to practical examples. Can you use the information under “Practical examples” to adjust the appearance of the prediction plots: to make them black and white; to add points?\nFirst create the plots:\n\ndat.two &lt;- ggpredict(model.two, \"HLVA\")\nplot.two &lt;- plot(dat.two, colors = \"bw\", add.data = TRUE) + labs(title = \"Study Two\")\n\nData points may overlap. Use the `jitter` argument to add some amount of\n  random variation to the location of data points and avoid overplotting.\n\ndat.122 &lt;- ggpredict(model.122, \"HLVA\")\nplot.122 &lt;- plot(dat.122, colors = \"bw\", add.data = TRUE) + labs(title = \"Study PSYC122\")\n\nData points may overlap. Use the `jitter` argument to add some amount of\n  random variation to the location of data points and avoid overplotting.\n\n\nThen show the plots:\n\nplot.two + plot.122\n\n\n\n\n\n\n\n\n\nQ.24. Given the information in the adjusted plots, can you explain what is different about the HLVA effect estimate in the study.122 data compared to the ?\nA.24. Adding points allow us to see:\n\n\nThere are far fewer observations in the study.122 dataset than in the study.two.gen data: this means that our estimate of the effect will be more uncertain because we have less information when we look at the study.122 data.\nBut it is also clear that the effect of HLVA appears to be stronger in the study.122 data because observed scores are closer to model predictions: the HLVA effect explains more variation in the study.122 data than in the study.two.gen data."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#variable-types",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#variable-types",
    "title": "122_wk12_labActivity2",
    "section": "Variable types",
    "text": "Variable types\nQuestions 5a: What are the variable types for the implicit (IAT_RT) and the explicit (VapingQuestionnaireScore) attitude variables?\nBoth can be considered continuous variables and at least at interval level."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#missing-data",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#missing-data",
    "title": "122_wk12_labActivity2",
    "section": "Missing data",
    "text": "Missing data\n\ndat &lt;- dat %&gt;% \n  filter(!is.na(VapingQuestionnaireScore)) %&gt;% \n  filter(!is.na(IAT_RT))\n\nQuestion 5b How many people had missing data?\nBefore we removed participants with missing data, we had 104 observations, now we have 96. So there must have been 8 participants without a score on one or the other variable."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#normality",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#normality",
    "title": "122_wk12_labActivity2",
    "section": "Normality",
    "text": "Normality\n\nggplot(dat, aes(x = VapingQuestionnaireScore)) + \n  geom_histogram(binwidth = 10) +\n  theme_bw()\n\n\n\n\n\n\n\nqqPlot(x = dat$VapingQuestionnaireScore)\n\n\n\n\n\n\n\n\n[1] 35 95\n\nggplot(dat, aes(x = IAT_RT)) + \n  geom_histogram(binwidth = 10) +\n  theme_bw()\n\n\n\n\n\n\n\nqqPlot(x = dat$IAT_RT)\n\n\n\n\n\n\n\n\n[1] 25 54\n\n\nQuestion 5c What do you conclude from the histograms and the qq-plots? Are the VapingQuestionnaireScore and the IAT_RT normally distributed?\nYes. Both histograms resemble a normal distribution (bell curve) and the open circles in the qq-plots fall within the blue stripy lines."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#linearity-and-homoscedasticity",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#linearity-and-homoscedasticity",
    "title": "122_wk12_labActivity2",
    "section": "Linearity and homoscedasticity",
    "text": "Linearity and homoscedasticity\n\nggplot(dat, aes(x = IAT_RT, y = VapingQuestionnaireScore)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Implicit attitude\", y = \"Explicit attitude\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nQuestion 5d What do you conclude from the scatterplot in terms of the homoscedasticity of the data and the linearity, direction and strength of the relationship? What does the scatterplot tell you about possible issues (outliers, range restrictions)?\nThe data look like a cloud without a clear direction. This suggests the relationship might might be weak. In terms of linearity, the scatterplot doesn’t suggest any curvilinear relationships. Variance seems quite constant, but there do seem to be few people with negative IAT_RT (Implicit attitude) scores, suggesting few people held the view that vaping is positive."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#create-a-new-data-frame-that-only-includes-the-relevant-variables",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#create-a-new-data-frame-that-only-includes-the-relevant-variables",
    "title": "122_wk12_labActivity2",
    "section": "Create a new data frame that only includes the relevant variables",
    "text": "Create a new data frame that only includes the relevant variables\n\ndat_matrix &lt;- dat %&gt;%\n  select(Age, IAT_RT, VapingQuestionnaireScore) %&gt;%\n  as.data.frame() # Make sure tell R that dat is a data frame"
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#create-a-matrix-of-scatterplots",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#create-a-matrix-of-scatterplots",
    "title": "122_wk12_labActivity2",
    "section": "Create a matrix of scatterplots",
    "text": "Create a matrix of scatterplots\n\npairs(dat_matrix)\n\n\n\n\n\n\n\n\nQuestion 8a What do you conclude from the scatterplots?\nThe scatterplots with age suggest that age is highly skewed with only a few participants older than 25. For now, let’s say we’ll therefore calculate Spearman’s rho, rather than Pearson’s r. That is ok for now, but if you were analysing these data for a research project, you’d want to have a closer look at the age variable (think histogram, qq-plot, and think about either collecting more data from older participants or transforming the variable (more about that next year)."
  },
  {
    "objectID": "PSYC122/data/week12/122_wk12_labAct2.html#conduct-intercorrelation-multiple-correlations",
    "href": "PSYC122/data/week12/122_wk12_labAct2.html#conduct-intercorrelation-multiple-correlations",
    "title": "122_wk12_labActivity2",
    "section": "Conduct intercorrelation (multiple correlations)",
    "text": "Conduct intercorrelation (multiple correlations)\n\nintercor_results &lt;- correlate(x = dat_matrix, # our data\n                          test = TRUE, # compute p-values\n                          corr.method = \"spearman\", # run a spearman test \n                          p.adjust.method = \"bonferroni\") # use the bonferroni correction\nintercor_results\n\n\nCORRELATIONS\n============\n- correlation type:  spearman \n- correlations shown only when both variables are numeric\n\n                            Age    IAT_RT    VapingQuestionnaireScore   \nAge                           .     0.156                      -0.086   \nIAT_RT                    0.156         .                      -0.022   \nVapingQuestionnaireScore -0.086    -0.022                           .   \n\n---\nSignif. codes: . = p &lt; .1, * = p&lt;.05, ** = p&lt;.01, *** = p&lt;.001\n\n\np-VALUES\n========\n- total number of tests run:  3 \n- correction for multiple testing:  bonferroni \n- WARNING: cannot compute exact p-values with ties\n\n                           Age IAT_RT VapingQuestionnaireScore\nAge                          .  0.384                    1.000\nIAT_RT                   0.384      .                    1.000\nVapingQuestionnaireScore 1.000  1.000                        .\n\n\nSAMPLE SIZES\n============\n\n                         Age IAT_RT VapingQuestionnaireScore\nAge                       96     96                       96\nIAT_RT                    96     96                       96\nVapingQuestionnaireScore  96     96                       96\n\n\nQuestion 8b What do you conclude from the results of the correlation analysis?\nNo significant correlation with age was found."
  },
  {
    "objectID": "PSYC122/data/week13/122_wk13_labAct2.html",
    "href": "PSYC122/data/week13/122_wk13_labAct2.html",
    "title": "122_wk13_labActivity2",
    "section": "",
    "text": "Question 1a If our hypothesis is correct, what type of correlation (if any) should we observe between students’ mean anxiety levels and the variable n_weeks? A negative correlation"
  },
  {
    "objectID": "PSYC122/data/week13/122_wk13_labAct2.html#lab-activity-2---statistics-anxiety-and-engagement-in-module-activities",
    "href": "PSYC122/data/week13/122_wk13_labAct2.html#lab-activity-2---statistics-anxiety-and-engagement-in-module-activities",
    "title": "122_wk13_labActivity2",
    "section": "",
    "text": "Question 1a If our hypothesis is correct, what type of correlation (if any) should we observe between students’ mean anxiety levels and the variable n_weeks? A negative correlation"
  },
  {
    "objectID": "PSYC122/Week13.html",
    "href": "PSYC122/Week13.html",
    "title": "3. Week 13 - The Linear Model",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.\nThis week we will focus on the linear model and simple linear regression.",
    "crumbs": [
      "Home",
      "PSYC122",
      "3. Week 13 - The Linear Model"
    ]
  },
  {
    "objectID": "PSYC122/Week13.html#sec-wk13-lectures",
    "href": "PSYC122/Week13.html#sec-wk13-lectures",
    "title": "3. Week 13 - The Linear Model",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week is presented in two parts:\n\nTheory – The linear model (~25 min) Watch this part before you complete the reading and the pre-lab activities. The video has captions, in case you find that helpful. You can download the slides and a transcript from the links below the video.\n\n\nSlides Transcript\n\nHow to – How to build a linear model in R(~14 minutes) Watch this part after you’ve completed the reading and before you attend the lab session. You can download the slides, a transcript and the example scritps from the links below the video.\n\n\nSlides Transcript Example R-script",
    "crumbs": [
      "Home",
      "PSYC122",
      "3. Week 13 - The Linear Model"
    ]
  },
  {
    "objectID": "PSYC122/Week13.html#sec-wk13-reading",
    "href": "PSYC122/Week13.html#sec-wk13-reading",
    "title": "3. Week 13 - The Linear Model",
    "section": "Reading",
    "text": "Reading\nThe reading that accompanies the lectures this week is from chapter 10 of the core text by Howell (2017).",
    "crumbs": [
      "Home",
      "PSYC122",
      "3. Week 13 - The Linear Model"
    ]
  },
  {
    "objectID": "PSYC122/Week13.html#sec-wk13-prelab-activities",
    "href": "PSYC122/Week13.html#sec-wk13-prelab-activities",
    "title": "3. Week 13 - The Linear Model",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapter you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Visualising the regression line\nHave a look at this visualisation of the regression line by Ryan Safner.\nIn this shiny app, you see a randomly-generated set of data points (within specific parameters, to keep the graph scaled properly). You can choose a slope and intercept for the regression line by using the sliders. The graph also displays the residuals as dashed red lines. Moving the slope or the intercept too much causes the generated line to create much larger residuals. The shiny app also calculates the sum of squared errors (SSE) and the standard error of the regression (SER), which calculates the average size of the error (the red numbers). These numbers reflect how well the regression line fits the data, but you don’t need to worry about those for now.\nIn the app he uses the equation Y = aX + b in which b is the intercept and a is the slope.\nThis is slightly different from the equation you saw during the lecture. There we talked about Y = b0 + b1*X + e. Same equation, just different letters. So b0 in the lecture is equivalent to b in the app and b1 in the lecture is equivalent to a in the app.\nPre-lab activity questions:\n\nChange the slider for the intercept. How does it change the regression line?\nChange the slider for the slope. How does it change the regression line?\nWhat happens to the residuals (the red dashed lines) when you change the slope and the intercept of the regression line?\n\n\n\nPre-lab activity 2: Data visualisation - practice with ggplot2()\nWe’ve mostly been using the ggplot2 package for visualising data. You can read a great overview of the ggplot2 package here. It also links to a ‘cheatsheet’ that you can download as a .pdf document. Lots of useful info on there!\nWith regard to visualising relations between continuous variables, the geom_point() function in combination with the geom_line() function is important. Also remember that it always a good idea to make sure you’ve given you axes informative labels (using the labs() function). You’ve used these functions before, but the following ‘recipes’ summarise what each one does and how to use it.\n\nTASK Have a look at each ‘recipe’ and read through it. Try to understand each step.\n\n\n\n\n\n\n\nRecipes - how to use them\n\n\n\nEach ‘recipe’ has the same structure.\n\nFirst, it summarises what it is that you want to achieve when using that specific function. In the case of select() it says “You want to extract specific columns from a data frame and return them as a new, smaller data frame.”\nThen, it outlines a number of steps that you need to carry out when using this function. For select() it outlines 2 steps: 1. Pass the dataframe to the function. 2. List the column(s) to return.\nFinally, there is an example talks you through using the function with some data. For select() it uses an example with data on the weather.\nAdditional information appears in extra boxes with a light-bulb icon. If you find those confusing, don’t worry about them at this stage.\n\n\n\n\ngeom_point() - create a scatterplot - recipe\ngeom_line() - add a regression line - there is no recipe, but have a look at the ggplot2() cheatsheet mentioned earlier\nlabs() - change the axes labels - recipe\n\n\n\nPre-lab activity 3: Getting ready for the lab class\n\nGet your files ready\nDownload the 122_week13_forStudents.zip file and upload it into the new folder in RStudio Server you created (see last week’s Pre-lab activity 4 for instructions on how to do that.\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below.",
    "crumbs": [
      "Home",
      "PSYC122",
      "3. Week 13 - The Linear Model"
    ]
  },
  {
    "objectID": "PSYC122/Week13.html#sec-wk13-lab-activities",
    "href": "PSYC122/Week13.html#sec-wk13-lab-activities",
    "title": "3. Week 13 - The Linear Model",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nconducting simple regression in R\ninterpreting simple regression in R\nreporting the results in APA format\nwhen and why to apply simple regression to answer questions in psychological science\n\n\nLab activity 1: The regression line\n\nQuestion 1\nWhat is the regression equation as discussed during the lecture and what does each letter represent?\n\n\nQuestion 2\nWhat are residuals?\n\n\nQuestion 3\nDiscuss the answers to the pre-lab activity questions. What did you find?\n\nChange the slider for the intercept. How does it change the regression line? The value for y at x = 0 changes.\nChange the slider for the slope. How does it change the regression line? The steepness of the line changes.\nWhat happens to the residuals (the red dashed lines) when you change the slope and the intercept of the regression line? The distance between the fitted values (the line) and the observed values (the dots) increases. Therefore, the red dashed lines become longer suggesting that the residuals increase. The model therefore fits the data less well.\n\n\n\n\nLab activity 2: Statistics anxiety and engagement in module activities\nIn this lab, we’ll be working with real data and using regression to explore the question of whether there is a relationship between statistics anxiety and engagement in course activities.\n\nBackground\nThe hypothesis is that students who are more anxious about statistics are less likely to engage in course-related activities. This avoidance behaviour could ultimately be responsible for lower performance for these students (although we won’t be examining the assessment scores in this activity).\nWe are going to analyse data from the STARS Statistics Anxiety Survey, which was administered to students in the third-year statistics course in Psychology at the University of Glasgow. All the responses have been anonymised by associating the responses for each student with an arbitrary ID number (integer).\nThe STARS survey (Cruise, Cash, & Bolton, 1985) is a 51-item questionnaire, with each response on a 1 to 5 scale, with higher numbers indicating greater anxiety.\nCruise, R. J., Cash, R. W., & Bolton, D. L. (1985). Development and validation of an instrument to measure statistical anxiety. Proceedings of the American Statistical Association, Section on Statistical Education, Las Vegas, NV.\nExample items from the STARS survey\n\nAs a measure of engagement in the course, we will use data from Moodle usage analytics. Over the course of the term, there were eight optional weekly on-line sessions that students could attend for extra support. The variable n_weeks in the psess.csv file tells you how many (out of eight) a given student attended.\nOur hypothesis was that greater anxiety would be reflected in lower engagement. Answer the following question.\n\nQuestion 1a: If our hypothesis is correct, what type of correlation (if any) should we observe between students’ mean anxiety levels and the variable n_weeks?\n\n\n\n\n\n\n\nBefore we begin\n\n\n\nLet’s put the basics in place:\n\nMake sure you have started a new R Markdown script. If you need a reminder of how to do that, please revisit week 6 of PSYC121 (here).\nYou’ll need the data files stars2.csv and psess.csv you downloaded when completing Pre-lab activity 3. If you experienced issues with uploading files to the server, follow the instructions below.\nWhen starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one.\nFinally, make sure your working directory is set to the folder in which you have stored the data files (stars2.csv and psess.csv).\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week13/stars2.csv?raw=true\", destfile = \"stars2.csv\")\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week13/psess.csv?raw=true\", destfile = \"psess.csv\")\n\n\n\n\n\n\n\nCleaning the R environment\n\n\n\n\n\nYou can clean the R environment by clicking on the broom icon at the top right of the environment window, or you can use the code below.\n\nrm(list=ls())\n\n\n\n\n\n\n\n\n\n\nChecking your working directory\n\n\n\n\n\nUse the code below to check what you working directory is currently set to. This is the folder that R will use to look for files. Is the file path that is written to the Console after you run the code snippet the one that contains the data file? You can check by nativating to the path you can see in the Console in the ‘Files’ pane on the right. Does it contain the data files?\n\ngetwd()\n\nIf your working directory is not set to the folder that contains the data file, navigate to folder that contains the data file in the ‘Files’ pane, click ‘More’ and then on ‘Set as working directory’.\n\n\n\n\nStep 1. Add the code to load the relevant libraries in a new code chunk. We need the following ones: broom, car and tidyverse. If you are unsure, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library()function. Remember to put it inside a ‘code chunk’ in your R Markdown script.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(tidyverse)\n\n\n\n\nStep 2. Read in both files, have a look at the layout of the data and familiarise yourself with it.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function to read in the data and the head() function to have a quick look at each data frame.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nstars &lt;- read_csv(\"stars2.csv\")\nengage &lt;- read_csv(\"psess.csv\")\n\nhead(stars) # Look at the data frames\nhead(engage)\n\n\n\n\nQuestion 2a: In the stars data frame, what do the numbers in the first row across the three columns refer to?\n\n\nStep 3. Getting the data ready. Now that we’ve read in both data files, the next step is to calculate the mean anxiety scores for each participant. At the moment we have scores on all questions separately for each participant in the stars table. Instead we need one mean anxiety score for each participant. Write the code to calculate mean anxiety scores.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember that participant is identified by the ID variable. Use group_by() and summarise(). Store the resulting table in a variable named stars_mean. Also, remember to use na.rm = TRUE when calculating the mean scores to deal with participants who have missing data (NAs).\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nstars_means &lt;- stars %&gt;%\n  group_by(ID) %&gt;%\n  summarise(mean_anxiety = mean(Score, na.rm = TRUE))\n\n\n\n\nQuestion 3a: What is the mean anxiety score for participant 3?\n\nOk, before we get ahead of ourselves, in order to perform the regression analysis we need to combine the data from stars (the mean anxiety scores) with the data from engage (n_weeks).\n\nTASK: Join the two tables, call the resulting table joined.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the inner_join() function (making use of the variable that is common across both tables) to join.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\njoined &lt;- inner_join(stars_means, engage, \"ID\")\n\n\n\n\nStep 4. We now need descriptive statistics for both variables. Calculate the mean and standard deviations for the anxiety scores and the engagement data.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the summarise() function, in combination with the mean() and sd() functions to do this. Remember to use na.rm = TRUE when calculating the mean scores to deal with participants who have missing data (NAs).\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\ndescriptives &lt;- joined %&gt;%\n  summarise(mean_anx = mean(mean_anxiety, na.rm = TRUE),\n            sd_anx = sd(mean_anxiety, na.rm = TRUE),\n            mean_weeks = mean(n_weeks, na.rm = TRUE),\n            sd_weeks = sd(n_weeks, na.rm = TRUE))\n\n\n\n\nQuestion 4a: What are the means and standard deviation for anxiety and engagement with the statistics module?\n\n\nStep 5. Visualise the data. As always, it is a good idea to visualise your data. Now that we have all the variables in one place, make a scatterplot of anxiety as a function of engagement.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor this you’ll need the ggplot() function together withgeom_point()andgeom_smooth(). Make sure to give your axes some sensible labels with thelabs()` function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nggplot(joined, aes(x = mean_anxiety, y = n_weeks)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Anxiety\", y = \"Engagement\") +\n  theme_bw()\n\n\n\n\nQuestion 5a: What does the scatterplot suggest about the relationship between anxiety and engagement?\n\n\nStep 6. With all the variables in place, we’re ready now to start building the regression model. Use the lm() function to run the regression model in which you model engagement (the outcome variable) as a function of anxiety (the predictor variable) and use the summary() function to look at the output.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the template below. Replace the ‘outcome’, ‘predictor’ and ‘my_data’ parts with the relevant info.\nmod &lt;-lm(outcome ~ predictor, data = my_data)\nmod_summary &lt;- summary(mod)\nmod_summary\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nmod &lt;- lm(n_weeks ~ mean_anxiety, data = joined)\nmod_summary &lt;- summary(mod)\nmod_summary\n\n\n\n\nQuestion 6a: What is the estimate of the y-intercept for the model, rounded to three decimal places?\n\n\nQuestion 6b: To three decimal places, if the General Linear Model for this model is Y=beta0 + beta1X + e, then the value of beta1 is …\n\n\nQuestion 6c: To three decimal places, for each unit increase in anxiety, engagement decreases by …\n\n\nQuestion 6d: To two decimal places, what is the overall F-value of the model?\n\n\nQuestion 6e: Is the overall model significant?\n\n\nQuestion 6f: What proportion of the variance does the model explain?\n\n\nStep 7. Now that we’ve fitted a model, let’s check whether the model meets the assumptions of linearity, normality and homoscedasticity. Write the code to create the plots that allow you to check the assumptions.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncrPlots() to check linearity, qqPlot() to check normality of the residuals, and residualPlot() to check homoscedasticity of the residuals.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below\ncrPlots(mod)            # Plot linear line and line that best fits the data to check the relationship between outcome and predictor is linear\n\nqqPlot(mod$residuals)   # Create qq-plot to check residuals are normally distributed\n\nresidualPlot(mod)      # Create residual plot to check residual show homoscedasticity\n\n\n\n\nQuestion 7a: Does the relationship appear to be linear?\n\n\nQuestion 7b: Do the residuals show normality?\n\n\nQuestion 7c: Do the residuals show homoscedasticity?\n\n\nStep 8. Finally, it’s time to write up the results following APA guidelines. What would the results section look like if you wrote them up, following APA guidelines?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe Purdue writing lab website is helpful for guidance on punctuating statistics.",
    "crumbs": [
      "Home",
      "PSYC122",
      "3. Week 13 - The Linear Model"
    ]
  },
  {
    "objectID": "PSYC122/Week13.html#sec-wk13-answers",
    "href": "PSYC122/Week13.html#sec-wk13-answers",
    "title": "3. Week 13 - The Linear Model",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\n\nLab activity 1\n\nWhat is the regression equation as discussed during the lecture and what does each letter represent?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nY = b0 + b1 * X + e Y = outcome variable b0 = intercept b1 = slope X = predictor variable e = error\n\n\n\n\nWhat are residuals?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nResiduals reflect the discrepancy between the observed values and the fitted values and give an indication of how well the model ‘fits’ the data.\n\n\n\n\nDiscuss the answers to the pre-lab activity questions. What did you find?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nChange the slider for the intercept. How does it change the regression line? The value for y at x = 0 changes.\nChange the slider for the slope. How does it change the regression line? The steepness of the line changes.\nWhat happens to the residuals (the red dashed lines) when you change the slope and the intercept of the regression line? The distance between the fitted values (the line) and the observed values (the dots) increases. Therefore, the red dashed lines become longer suggesting that the residuals increase. The model therefore fits the data less well.\n\n\n\n\n\n\nLab activity 2\nYou can download the R Markdown-script that contains the code to complete lab activity 2 here: 122_wk13_labAct2.Rmd.\n1a. If our hypothesis is correct, what type of correlation (if any) should we observe between students’ mean anxiety levels and the variable n_weeks?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA negative correlation\n\n\n\n2a. In the stars table, what do the numbers in the first row across the three columns refer to?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nID = 3, Question = Q01 and Score = 1 shows us that participant 3 reported a score of 1 on question 1.\n\n\n\n3a. What is the mean anxiety score for participant 3?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n1.058824\n\n\n\n4a. What are the means and standard deviation for anxiety and engagement with the statistics module?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAnxiety M = 2.08, SD = 0.56; Engagement M = 4.54, SD = 2.42.\n\n\n\n5a. What does the scatterplot suggest about the relationship between anxiety and engagement?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThat there might indeed be a relatively strong negative correlation between the two; students with more anxiety, engage less.\n\n\n\n6a. What is the estimate of the y-intercept for the model, rounded to three decimal places?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n9.057. Explanation: In the summary table, this is the estimate of the intercept.\n\n\n\n6b. To three decimal places, if the General Linear Model for this model is Y=beta0 + beta1X + e, then the value of beta1 is …\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n-2.173. Explanation: In the summary table, this is the estimate of mean_anxiety, i.e., the slope.\n\n\n\n6c. To three decimal places, for each unit increase in anxiety, engagement decreases by …\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n2.173. Explanation: In the summary table, this is also the estimate of mean_anxiety, the slope is how much it decreases so you just remove the - sign.\n\n\n\n6d. To two decimal places, what is the overall F-ratio of the model?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n11.99. Explanation: In the summary table, the F-ratio is noted as the F-statistic.\n\n\n\n6e. Is the overall model significant?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes. Explanation: The overall model p-value is .001428 which is less than .05, therefore significant.\n\n\n\n6f. What proportion of the variance does the model explain?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n25.52%. Explanation: The variance explained is determined by R-squared, you simply multiple it by 100 to get the percent.\n\n\n\n7a. Does the relationship appear to be linear?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes, the pink line roughly falls across the dashed blue line and looks mostly linear.\n\n\n\n7b. Do the residuals show normality?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes, in the qq-plot the open circles mostly assemble around the solid blue line, and fall mostly within the range of the dashed blue lines.\n\n\n\n7c. Do the residuals show homoscedasticity?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes, the residual plot shows that the spread of the residuals is roughly similar for different fitted values.\n\n\n\n\nWhat would the results section look like if you wrote them up, following APA guidelines?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA simple linear regression was performed with engagement (M = 4.54, SD = 0.56) as the outcome variable and statistics anxiety (M = 2.08, SD = 0.56) as the predictor variable. The results of the regression indicated that the model significantly predicted course engagement (F(1, 35) = 11.99, p &lt; .001, R^2 = 0.25), accounting for 25% of the variance. Anxiety was a significant negative predictor (beta = -2.17, p &lt; 0.001): as anxiety increased, course engagement decreased.",
    "crumbs": [
      "Home",
      "PSYC122",
      "3. Week 13 - The Linear Model"
    ]
  },
  {
    "objectID": "PSYC122/Week13.html#online-qa",
    "href": "PSYC122/Week13.html#online-qa",
    "title": "3. Week 13 - The Linear Model",
    "section": "Online Q&A",
    "text": "Online Q&A\nBelow is the recording of this week’s online Q&A.",
    "crumbs": [
      "Home",
      "PSYC122",
      "3. Week 13 - The Linear Model"
    ]
  },
  {
    "objectID": "PSYC122/index.html",
    "href": "PSYC122/index.html",
    "title": "Statistics for Psychologists II",
    "section": "",
    "text": "Welcome\nWelcome to PSYC122!\nThis module builds on the knowledge and skills acquired in Statistics for Psychologists 1 (PSYC121). You will continue to practise data handling, data processing and data visualisation, using R and R Studio. In addition, you will learn about statistical methods to test whether two (or more) variables are associated and how to implement those methods in R and R Studio.\nWatch the video below (~ 5 minutes) to get a short overview of the topics we will cover in weeks 11 to 15.\n\nThis page gives you access to all the materials that you will need. You will have timetabled lab classes during which you are expected to work through a series of exercises to practise that week’s material. Before you come to your lab session, you should watch the lectures for that week, read the relevant book chapter and complete the pre-lab activities. Following all that and to check that you’ve understood the week’s materials, you can complete a quick quiz.\nThere will be class tests in weeks 15 and 20. These take place, in person, during your regular lab session.\n\n\nAsking for help\nWe have carefully prepared and refined the lab materials in this course over several years, and we feel that the pace of the materials is just right for our students. Some students will complete them more quickly, and others more slowly - both of these scenarios are absolutely fine. You should work at the pace that suits you best, making sure you understand the materials before you move forward.\nIt is fairly inevitable that you will get stuck on the lab materials in this module at some point. This might be in Week 11, Week 12, or later. When you do, it’s important you reach out for help:\n\nAsk your friends on your table. We’ve designed this teaching space to help collaborative work. You are encouraged to work with other students. Make sure you ask others to explain how they’ve solved an exercise. Make sure you help out others where you can. Always make sure you understand the code and the exercise; don’t simply be satisfied that you’ve got the right answer.\nAsk a GTA or Lecturer. Our Graduate Teaching Assistants are there to help you. There are no “stupid questions” in statistics, so just ask the GTAs any question about what you’re doing. Likewise, ask the Lecturer.\nAsk on the Discussion Forum. On the PSYC122 moodle page you will find a Discussion Forum. This is a great way to ask a question outside of the lab sessions. It might seem scary to ask a question in the forum, but please don’t be afraid to do this. If you have a question, you can bet 30+ other students also have the same question! So by asking the question on the forum, you help out many more people on the module. A friendly GTA or Lecturer will be along to answer the question as soon as possible (we aim for within 48 hours during the working week).\nAsk on the module Q & A session. Each week we hold a “Q&A” online session where we will try and resolve any general queries and problems. It’s an ideal time to discuss things that students are struggling with or confused about, and can share ideas and answers. You can ask on the discussion forum above and then we might be able to pick up the issues and discuss them, but also you can ask in the session itself.\n\n\n\nCourse Contacts\n\n\n\n\nEmail Address\n\n\n\n\nMargriet Groen\nm.groen at lancaster dot ac dot uk\n\n\nRob Davies\nr.davies1 at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "PSYC122"
    ]
  },
  {
    "objectID": "PSYC122/Week18.html",
    "href": "PSYC122/Week18.html",
    "title": "7. Week 18 – Developing the linear model",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.",
    "crumbs": [
      "Home",
      "PSYC122",
      "7. Week 18 -- Developing the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week18.html#sec-wk18-introduction",
    "href": "PSYC122/Week18.html#sec-wk18-introduction",
    "title": "7. Week 18 – Developing the linear model",
    "section": "Week 18: Introduction",
    "text": "Week 18: Introduction\nWelcome to your overview of our work together in PSYC122 Week 18.\n\n\n\n\n\n\nTip\n\n\n\nPutting it all together\n\nWe will complete four classes in weeks 16-19.\nThese classes are designed to help you to revise and to put into practice some of the key ideas and skills you have been developing in the first year research methods modules PSYC121, PSYC123 and PSYC124.\nWe will do this in the context of a live research project with potential real world impacts: the Clearly Understood project.\n\n\n\n\nOur learning goals\nIn Week 18, we aim to further develop skills in analyzing and in visualizing psychological data.\nWe will do this in the context of the Clearly Understood project: our focus will be on what makes it easy or difficult for people to understand written health information.\nIn the Week 18 class, we will aim to answer two research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe will use linear models to estimate the association between predictors and outcomes. What is new, here, is that we will explore the power and flexibility of the linear model analysis method in two important aspects.\n\n\n\n\n\n\nTip\n\n\n\n\nWe will fit linear models including multiple predictors, this is why this form of analysis is also often called multiple regression.\nWe will use linear models to estimate the effects of numeric and categorical or nominal predictor variables.\n\n\n\nWhen we do these analyses, we will need to adapt how we report the results:\n\nwe need to report information about the model we specify, identifying all predictors;\nwe will need to decide if the effects of one or more predictors are significant;\nwe will report the model fit statistics (F, R-squared) as well as coefficient estimates;\nand we need to learn to write texts describing the impact of predictors.\n\nUsually, in describing the impacts of predictors, we are required to communicate:\n\nthe direction of the effect – do values of the outcome variable increase or decrease given increasing values of the predictor?\nthe size of the effect – how much do values of the outcome variable increase or decrease given increasing values of the predictor?\n\nThis task of description is enabled by producing plots of the predictions we can make:\n\nplots to show we expect the outcome to change, given different values of a predictor.\n\n\n\n\n\n\n\nTip\n\n\n\nWe will aim to build skills in producing professional-looking plots for our audiences.\n\nWe can produce plots showing the effects of predictors\nAs predictions of change in outcome, given different values of the predictor variables.",
    "crumbs": [
      "Home",
      "PSYC122",
      "7. Week 18 -- Developing the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week18.html#sec-wk18-lectures",
    "href": "PSYC122/Week18.html#sec-wk18-lectures",
    "title": "7. Week 18 – Developing the linear model",
    "section": "Lectures",
    "text": "Lectures\n\n\n\n\n\n\nTip\n\n\n\nBefore you go on to the activities in Section 5, watch the lectures:\n\n\nThe lecture for this week is presented in four short parts. You can view video recordings of the lectures using Panopto, by clicking on the video images shown following.\n\nAnybody who has the link should be able to view the video.\n\n\nOverview (19 minutes): What we are doing in Week 18 – Exploring the power of linear models, extending their application to use multiple variables to predict people.\n\n\n\nUsing linear models to predict people (13 minutes): Coding, thinking about, and reporting linear models with multiple predictors.\n\n\n\nCritical evaluation (15 minutes): Critically evaluating the results of analyses involving linear models.\n\n\n\nEverything is some kind of linear model (13 minutes): Understanding just how general and powerful this method for understanding people can be.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe slides presented in the videos can be downloaded either as a web page or as a Word document.\n\n\n\nThe slides exactly as presented (6 MB).\nThe slides converted to a Word .docx (1 MB).\n\nYou can download the web page .html file and click on it to open it in any browser (e.g., Chrome, Edge or Safari). The slide images are high quality so the file is quite big and may take a few seconds to download.\nYou can download the .docx file and click on it to open it as a Word document that you can then edit. Converting the slides to a .docx distorts some images but the benefit of the conversion is that it makes it easier for you to add your notes.\n\nThe lectures have three main areas of focus\n1. Working with the linear model with multiple predictors\nWe focus in-depth on how you code linear models, how you identify critical information in the results summaries, and how you report the results: the language and the style you can use in your reports.\n\n\n\n\n\n\nTip\n\n\n\n\nA small change to lm() coding releases tremendous power and flexibility in how you use the analysis method.\n\n\n\n2. Analyses are done in context so when we conduct analyses we must use contextual information\nThe power and flexibility of the linear model presents challenges. We must decide which predictor variables we specify in our model. This specification requires us to think about our theoretical assumptions and what they require us to include to make sense of the behaviours or the individual differences we observe when we do things like investigating what makes health information easy or difficult to understand.\n3. Developing critical thinking\nAs we develop conceptual understanding and practical skills, we must learn to reflect critically on our analyses, and learn to critically evaluate the analyses we read about when we read research reports in the scientific literature.\n\n\n\n\n\n\nTip\n\n\n\nCritical analysis can develop by considering\n\nvalidity\nmeasurement\ngeneralizability\n\n\n\nWe are always working in the broader context of uncertainty:\n\nuncertainty about the predictions we may make concerning outcomes of interest;\nuncertainty given the possibility that predicted effects may vary between individuals or groups;\nuncertainty given the influence of sources of randomness in how specific responses are produced.\n\n\n\n\n\n\n\nTip\n\n\n\nTo work with the recordings:\n\nWatch the video parts right through.\nUse the printable versions of the slides (provided on Moodle) to make notes.\nTry out the coding exercises in the how-to guide and the acitivity tasks or questions (Section 5) to learn how to construct visualizations and do analyses.",
    "crumbs": [
      "Home",
      "PSYC122",
      "7. Week 18 -- Developing the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week18.html#reading-links-to-other-classes",
    "href": "PSYC122/Week18.html#reading-links-to-other-classes",
    "title": "7. Week 18 – Developing the linear model",
    "section": "Reading: Links to other classes",
    "text": "Reading: Links to other classes\nWe do not provide further reading for this class but you will find it helpful to revise some of the key ideas you have been learning about PSYC122 and in other modules.\n\nThe lectures in PSYC123 on: the scientific method; reliability and validity; experimental design, especially between-subjects studies; hypothesis testing; and precise hypotheses.\nThe lecture in PSYC122 on linear models.",
    "crumbs": [
      "Home",
      "PSYC122",
      "7. Week 18 -- Developing the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week18.html#sec-wk18-prelab-activities",
    "href": "PSYC122/Week18.html#sec-wk18-prelab-activities",
    "title": "7. Week 18 – Developing the linear model",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\n\nPre-lab activity 1\nIn weeks 16-19, we will be working together on a research project to investigate how people vary in their response to health advice.\nCompleting the project involves collecting responses from PSYC122 students: you.\nTo enter your responses, we invite you to complete a short survey.\nComplete the survey by clicking on the link here\n\n\n\n\n\n\nTip\n\n\n\nIn our week 19 class activity, we will analyze the data we collect here.\n\n\nThe survey should take about 20 minutes to complete.\nTaking part in the survey is completely voluntary. You can stop at any time without completing the survey if you do not want to finish it. If you do not want to do the survey, you can do an alternative activity (see below).\nAll responses will be recorded completely anonymously.\n\n\nPre-lab activity alternative option\nIf you do not want to complete the survey, we invite you to read the pre-registered research plan for the PSYC122 health advice research project.\nRead the project pre-registration",
    "crumbs": [
      "Home",
      "PSYC122",
      "7. Week 18 -- Developing the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week18.html#sec-wk18-lab-activities",
    "href": "PSYC122/Week18.html#sec-wk18-lab-activities",
    "title": "7. Week 18 – Developing the linear model",
    "section": "Lab activities",
    "text": "Lab activities\n\nIntroduction\nWe will do our practical lab work to develop your skills in the context of the Clearly Understood project.\n\nOur focus will be on what makes it easy or difficult for people to understand written health information.\n\n\n\n\n\n\n\nImportant\n\n\n\nIn these classes, we will complete a research project to answer the research questions:\n\nWhat person attributes predict success in understanding health information?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\n\n\n\nGet ready\n\nDownload the data\nClick on the link: 122-week18_for_students.zip to download the data files folder. Then upload the contents to the new folder you created in RStudio Server.\nThe downloadable .zip folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand the R Markdown .Rmd:\n\n2023-24-PSYC122-w18-how-to.Rmd\n\nIf you can’t upload these files to the server – this affects some students – you can use some code to get R to do it for you: uncover the code box below to reveal the code to do this.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nYou can use the code below to directly download the file you need in this lab activity to the server.\nRemember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\nGet the study-one-general-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/study-one-general-participants.csv?raw=true\", destfile = \"study-one-general-participants.csv\")\n\n\nGet the study-two-general-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/study-two-general-participants.csv?raw=true\", destfile = \"study-two-general-participants.csv\")\n\n\nGet the 2023-24-PSYC122-w18-how-to.Rmd how-to guide\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/2023-24-PSYC122-w18-how-to.Rmd?raw=true\", destfile = \"2023-24-PSYC122-w18-how-to.Rmd\")\n\n\n\n\n\n\nCheck: What is in the data files?\nEach of the data files we will work with has a similar structure, as you can see in this extract.\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\n\n\n\n\n\nYou can use the scroll bar at the bottom of the data window to view different columns.\nYou can see the columns:\n\nparticipant_ID participant code;\nmean.acc average accuracy of response to questions testing understanding of health guidance (varies between 0-1);\nmean.self average self-rated accuracy of understanding of health guidance (varies between 1-9);\nstudy variable coding for what study the data were collected in\nAGE age in years;\nHLVA health literacy test score (varies between 1-16);\nSHIPLEY vocabulary knowledge test score (varies between 0-40);\nFACTOR3 reading strategy survey score (varies between 0-80);\nGENDER gender code;\nEDUCATION education level code;\nETHNICITY ethnicity (Office National Statistics categories) code.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is always a good idea to view the dataset – click on the name of the dataset in the R-Studio Environment window, and check out the columns, scroll through the rows – to get a sense of what you are working with.\n\n\n\n\n\nLab activity 1: Work with the How-to guide\nThe how-to guide comprises an .Rmd file:\n\n2023-24-PSYC122-w18-how-to.Rmd\n\nIt is full of advice and example code.\nThe code in the how-to guide was written to work with the data file:\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\nTip\n\n\n\nWe show you how to do everything you need to do in the lab activity (Section 5.4, next) in the how-to guide.\n\nStart by looking at the how-to guide to understand what steps you need to follow in the lab activity.\n\n\n\nWe will take things step-by-step.\nWe split .Rmd scripts by steps, tasks and questions:\n\ndifferent steps for different phases of the analysis workflow;\ndifferent tasks for different things you need to do;\ndifferent questions to examine different ideas or coding challenges\n\n\n\n\n\n\n\nTip\n\n\n\n\nMake sure you start at the top of the .Rmd file and work your way, in order, through each task.\nComplete each task before you move on to the next task.\n\n\n\nIn the activity Section 5.4, we are going to work through a sequence of steps and tasks that mirrors the sequence you find in the how-to guide.\n\nThere is a little bit of variation, comparing the later steps in the how-to guide and the steps in Section 5.4, but that is designed to help you with your learning, in different places, when we think you will most need the support.\n\n\n\n\n\n\n\nTip\n\n\n\n\nNotice that we are gradually building up our skills: consolidating what we know; revising important learning; and extending ourselves to acquire new skills.\nOver time, we will refer less and less to what we have learned before.\n\n\n\nStep 1: Set-up\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\n\nStep 2: Load the data\n\nRead in the data file – using read_csv()\nInspect the data – using head() and summary()\n\nStep 3: Use a linear model to to answer the research questions – one predictor\n\nUse lm() to examine the relation between an outcome variable and one predictor variable\n\nStep 4: Use a linear model to to answer the research questions – multiple predictors\n\nUse lm() to examine the relation between between an outcome variable and multiple predictors\n\nStep 5: Plot predictions from linear models with multiple predictors\n\nUse ggpredict() to plot linear model predictions for one of the predictors\nProduce plots that show the predictions for all the predictor variables in a model\n\nIn Section 5.4, you will see that we show you how you can understand what linear model estimates show by examining the predictions from one outcome-predictor relation.\nStep 6: Draw boxplots to examine associations between variables\nThe how-to guide shows you how to produce boxplots. We do not include the task in the Section 5.4 tasks sequence but you will find it useful to produce boxplots when you are examining the impact of categorical variables (next).\n\nCreate boxplots to examine the association between a continuous numeric outcome variable like mean.acc and a categorical variable like ETHNICITY\n\nStep 7: Estimate the effects of factors as well as numeric variables\nWe refer to categorical or nominal variables like ETHNICITY as factors in data analysis.\n\nFit a linear model including both numeric variables and categorical variables as predictors\nFit a linear model including both numeric variables and categorical variables as predictors, and then plot the predicted effect of the factor (the categorical variable)\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are unsure about what you need to do, look at the advice in 2023-24-PSYC122-w18-how-to.Rmd on how to do the tasks, with examples on how to write the code.\n\n\nYou will see that you can match a task in the activity Section 5.4 to the same task in the how-to guide. The how-to shows you what function you need and how you should write the function code.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in modern psychological science.\n\n\n\n\n\n\nWarning\n\n\n\nDon’t forget: You will need to change the names of the dataset or the variables to complete the tasks in Section 5.4.\n\n\n\n\nLab activity 2\n\n\nOK: now let’s do it!\nIn the following, we will guide you through the tasks and questions step by step. \n\n\n\n\n\n\nTip\n\n\n\n\nWe will not at first give you the answers to questions about the data or about the results of analyses.\nAn answers version of the workbook will be provided after the last lab session (check the answers then in Section 6) so that you can check whether your independent work has been correct.\n\n\n\n\nQuestions\n\n\n\n\n\n\nWarning\n\n\n\nStudents have told us that it would be helpful to your learning if we reduce the information in the hints we provide you. We have done this in Week 18.\nThe motivation for doing this is:\n\nIt will require you to do more active thinking to complete tasks or answer questions;\nThus, you can check to see how your learning is developing – can you do the tasks, given what you know now?\nPlus, psychological research shows that active thinking is better for understanding and for learning.\n\nWhere we do give you hints, we will sometimes replace the correct bit of code with a place-holder: ...\n\nYour task will therefore be to replace the place-holder ... with the correct bit of code or the correct dataset or variable name.\n\n\n\n\n\nStep 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\n\n\n\n\n\nTask 2 – Run code to load relevant libraries\nNotice that in Week 18, we need to work with the libraries ggeffects and tidyverse. Use the library() function to make these libraries available to you.\n\n\n\n\n\n\n\n\nStep 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file for Lab Activity 2 is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n... &lt;- read_csv(\"...\")\n\n\n\n\nWhen you code this, you can choose your own file name, but be sure to give the data object you create a distinct name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\nEven though you have done this before, you will want to do it again, here, and pay particular attention to:\n\nsummary information about the numeric variables;\nsummary information about variables of class: character.\n\n\n\n\n\n\nStep 3: Use a linear model to to answer the research questions – one predictor\n\n\nRevise: practice to strengthen skills\n\n\n\n\n\n\nTip\n\n\n\n\nRevise: We start by revising how to use lm() with one predictor\n\n\n\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe can address this question by examining whether someone’s rated evaluation of their own understanding matches their performance on a test of that understanding, and by investigating what variables predict variation in mean self-rated accuracy.\n\nFor these data, participants were asked to respond to questions about health information to get mean.acc scores\nand they were then asked to rate their own understanding of the same information (ratings on a scale from 1-9) to get mean.self scores.\nRatings of accuracy are ordinal data but, here, we choose to examine the average of participants’ ratings of their own understanding of health information to keep our analysis fairly simple.\n\nIf you can evaluate your own understanding then ratings of understanding should be associated with performance on tests of understanding\n\nTask 5 – Estimate the relation between outcome mean self-rated accuracy (mean.self) and tested accuracy of understanding (mean.acc)\nWe can use lm() to estimate whether :\n\nthe outcome variable, participants’ ratings of the accuracy of their understanding (mean.self), can be predicted by\nthe predictor variable, information about the same participants’ level of accuracy in direct tests of their understanding (mean.acc).\n\nCan you work out how to specify the model?\n\n\n\n\n\n\n\n\n\n\nYou can get more advice on how lm() code works if you click on the Hint box.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIn R analysis code, we normally write linear model analysis code like this:\nmodel &lt;- lm(outcome ~ predictor, data)\nsummary(model)\n\n\n\n\n\n\n\n\n\nIf you first run the model, and then look at the model summary you can answer the following questions.\n\n\n\nQuestions: Task 5\n\nQ.1. What is the estimate for the coefficient of the effect of the predictor mean.acc on the outcome mean.self in this model?\n\n\n\nQ.2. Is the effect significant?\n\n\n\nQ.3. What are the values for t and p for the significance test for the coefficient?\n\n\n\nQ.4. What do you conclude is the answer to the research question, given the linear model results?\n\n\n\nQ.5. What is the F-statistic for the regression? Report F, DF and the p-value.\n\n\n\nQ.6. Is the regression significant?\n\n\n\nQ.7. What is the Adjusted R-squared?\n\n\n\nQ.8. Explain in words what this R-squared value indicates?\n\n\n\n\nStep 4: Use a linear model to to answer the research questions – multiple predictors\n\n\nIntroduce: make some new moves\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe have already looked at this question by asking whether ratings of understanding are predicted by performance on tests of understanding.\nBut there is a problem with that analysis – it leaves open the question:\n\nWhat actually predicts ratings of understanding?\n\nWe can look at this follow-up question, next.\n\nTask 6 – Examine the relation between outcome mean self-rated accuracy (mean.self) and multiple predictors\nHere, the predictors will include all of:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nage in years (AGE);\nreading strategy (FACTOR3);\nas well as average accuracy of the tested understanding of health information (mean.acc).\n\nWe use lm(), as before, but now when we specify the model we write the code to include all of the multiple predictors in the same model at the same time.\n\nWhen you do this, specify all of the predictors we list.\nSpecify each variable listed here by using the variable name.\n\nCan you write the code you need to do the linear model analysis?\nYou can click on the button to see the hint. You can see example code, for a different model, for Step 4 in the 2023-24-PSYC122-w18-how-to.Rmd.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can include multiple predictor variables in a model by:\n\nlisting the predictors in series;\nspecifying each predictor variable name;\nentering the names ... separated by a +;\none variable at a time ... + ...;\nlike this:\n\n\nmodel &lt;- lm(outcome ~ ... + ... + ..., \n            data = study.two.gen)\nsummary(model)\n\nYou will need to replace place-holder ...s with the names of variables as they appear in the dataset.       \n\n\n\nIf you look at the model summary you can answer the following questions.\n\nQ.9. What predictors are significant in this model?\n\n\n\nQ.10. What is the estimate for the coefficient of the effect of the predictor mean.acc in this model?\n\n\n\nQ.11. Is the effect significant?\n\n\n\nQ.12. What are the values for t and p for the significance test for the coefficient?\n\n\n\nQ.13. What do you conclude is the answer to the follow-up question, what actually predicts ratings of understanding?\n\n\n\n\n\nStep 5: Understanding linear model predictions by comparing one outcome-predictor relation\n\n\nConsolidate your learning\nNext, we focus in on whether (1.) mean.self predicts mean.acc or, in reverse, whether (2.) mean.acc predicts mean.self?\nWe are talking about two models here:\n\nThe model mean.acc ~ mean.self\nThe model mean.self ~ mean.acc\n\n\n\n\n\n\n\nImportant\n\n\n\n\nA comparison between these models teaches us something important about what it is that linear models predict.\n\n\n\nYou will learn something about how linear models work if you look closely at the Estimate value in the summary for each model.\n\nWhere we reference model estimates, here, we are looking at the values in theEstimate column of the lm() model summary.\nThese estimates give us the expected or predicted change in the outcome, given change in the predictor variable named on that row.\n\nCompare the Estimate value in the summary for each model. Then have a think about why these values are different even though the variables and the data are the same.\nRemember that:\n\nmean.acc is scaled from 0 to 1 because it represents the average accuracy of the responses made by study participants to questions about health texts.\nmean.self is scaled from 1 to 9 because it represents the average self-rated accuracy of understanding.\n\n\nQ.14. Why do you think it appears that the slope coefficient estimate is different if you compare:\n\n\nThe model mean.acc ~ mean.self versus\nThe model mean.self ~ mean.acc?\n\nYou can fit these two simple models using the verbal description in the Q.14. information, plus what you have learned so far.\n\nRemember to give each model a different name.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nRemember: you write model code with the outcome on the left of the tilde symbol ~ and the predictor (or predictors) on the right of the ~.\nIn the model information, we specify two different models.\n\n\nThe variables and the data are the same.\nBut which variable is the outcome, and which variable is the predictor, is different in the two models.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo that then compare the Estimate of the predictor effect in the two models.\n\nReflect on what the comparison shows about the scale of predicted effects.\nHave a think before clicking on the Hint button to see our information on the key learning we are talking about here.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhat does a comparison of the model predictor Estimate values show us?\n\nYou may benefit by reflecting on the lm-intro) lecture and practical materials, especially where they concern predictions.\n\nThe lesson to learn here is that:\n\nIf we have the model, mean.acc ~ mean.self then this means that the outcome is mean.acc.\n\n\nSo if we are predicting change in outcome mean.acc, which is scaled 0-1, then we are looking at coefficients that will lie somewhere on the same scale (also 0-1).\nHere: the model estimate will show that each unit change in values of the variable mean.self predicts an increase of 0.053566 in mean.acc.\n\n\nWhereas if we have the model, mean.self ~ mean.acc then this means that the outcome is mean.self.\n\n\nSo if we are predicting change in outcome mean.self, which is scaled 1-9, then we are looking at coefficients that will lie somewhere on the same scale (also 1-9).\nHere: the model estimate will show that unit change in mean.acc predicts increase of 5.5670 in mean.self.\n\nRemember that:\n\nmean.acc is scaled from 0 to 1 because it represents the average accuracy of the responses made by study participants to questions about health texts. This average has to have a minimum of 0 (no responses correct) and a maximum of 1 (all responses correct). The average is calculated by adding up all the correct answers and dividing by the number of questions answered by each participant.\nmean.self is scaled from 1 to 9 bcause it represents the average self-rated accuracy of understanding. Participants are asked to rate on a scale form 1 (not all) to 9 (very well) how well they think they understand a health information text. The average is calculated by adding up all the ratings and dividing by the number of texts responded to by each participant.\n\nThe important lesson, here, is that estimates of predictor effects are scaled in terms of predicted change in the outcome, so whatever scale the outcome measurement is in determines how big or small the predictor coefficient estimates can be.\n\n\n\n\n\n\nWe can visualize the predictions from each model to visualize the comparison. This will help your learning:\n\nLook at how much the outcome is predicted to change;\nLook at the values on the y-axis labels.\n\n\nQ.15. Can you plot the predictions from each model?\n\n\nCan you work out how to write the model prediction plotting code without looking at the code example?\nClick on the Hint button to see advice on what you need to do. You can see example code, for a different model, for Step 5 in the 2023-24-PSYC122-w18-how-to.Rmd.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFirst fit the models like this:\n\nmodel.1 &lt;- lm(outcome ~ predictor, data)\n\n\nRemember to give each model object distinct names.\n\n\n\n\n\n\n\n\n\n\nSecond get the predictions like this:\n\nmodel.predictions &lt;- ggpredict(model.1, \"...\")\n\n\nReplace ... with the name of the predictor in model.1.\n\n\n\n\n\n\nThird make the prediction plots like this:\n\nplot(model.predictions)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ.16. Look at the two plots: what do you see?\n\nLook at changes in height of the prediction line, given changes in predictor values.\n\n\n\n\n\n\n\nStep 6: Estimate the effects of factors as well as numeric variables\n\n\nConsolidation: build your skills\nWe have not yet included any categorical or nominal variables as predictors but we can, and should: lm() can cope with any kind of variable as a predictor.\nThere are different ways to do this, here we ask you to use the R default method.\n\nTask 7 – Fit a linear model to examine what variables predict outcome mean self-rated accuracy of mean.self\nInclude as predictors both numeric variables and categorical variables.\nHere, our model includes predictors that are numeric like:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nAGE;\nreading strategy (FACTOR3);\naccuracy mean.acc.\n\nAs well as a categorical or nominal variable like:\n\nEDUCATION.\n\nNote: EDUCATION is a categorical or nominal variable because participants are classified by what education category (higher education, further education, secondary school) they report themselves as having received.\nCan you write the code to complete the linear model analysis?\n\n\n\n\n\n\nHint\n\n\n\n\n\nFollow the same procedure for model specification that you have been learning to follow: the inclusion of a nominal variable does not affect how you specify the model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you look at the model summary you can answer the following questions.\n\nQ.17. Can you report the overall model and model fit statistics?\n\n\n\n\n\n\n\n\nQ.18. Can you plot the predicted effect of EDUCATION given your model?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFollow the same procedure that you have been learning to follow.\n\nFit the model:\n\n\nmodel &lt;- lm(outcome ~ predictors, data)\n\n\nReplace outcome with the outcome variable required for this analysis.\nReplace predictor with the predictor variable required for this analysis.\nReplace data with the name of the correct data set.\nGive the model a distinctive name.\n\n\nGet the predictions:\n\n\nmodel.predictions &lt;- ggpredict(model, \"EDUCATION\")\n\n\nUse the model name you assigned to the analysis you just did.\nAsk for predictions of the effect on outcomes of the nominal variable.\n\n\nPlot the predictions:\n\n\nplot(model.predictions)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ.19. The plot should give you dot-and-whisker representations of the estimated mean.self outcome for different levels of EDUCATION. What is the difference in the estimated mean.self between the groups?\n\nThe effect or prediction plot will show you dot-and-whisker representations of predicted outcome mean.self. In these plots, the dots represent the estimated mean.self while the lines (whiskers) represent confidence intervals.\n\n\nQ.20. Compare the difference in the estimated mean.self between these groups, given the plot, with the coefficient estimate from the model summary: what do you see?\n\n\n\n\n\n\n\n\n\nWe are learning some new things here so it is useful to explain them in a bit more detail:\n\nCategorical variables or factors and reference levels.\n\n\nIf you have a categorical variable like EDUCATION then when you use it in an analysis, R will look at the different categories (called levels) e.g., here, higher education, further education, secondary school and it will pick one level to be the reference or baseline level.\nThe reference is the the level against which other levels are compared.\nHere, the reference level is Further (education) simply because, unless you tell R otherwise, it picks the level with a category name that begins earlier in the alphabet as the reference level.\n\n\nDot and whisker plots show estimates with confidence intervals.\n\n\nDot and whisker plots are a nice way to present a concise visual summary about the estimates we get from prediction models.\nHere, the plots show the coefficient estimates from our model (the dots) plus confidence intervals (the lines or “whiskers”).\n\n\nConfidence intervals are often misunderstood but they are helpful.\n\n\nEssentially, a confidence interval tells us about we might expect to see using our analysis procedure (Hoekstra et al., 2014).\n\n\nIf we were to repeat the experiment over and over, then 95 % of the time the confidence intervals contain the true mean.\n\n\n\n\n\n\n\nReading to grow your understanding\n\n\n\n\nYou can read more about this here:\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E. J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21, 1157-1164.\n\n\n\n\n\nYou have now completed the Week 18 questions.\nYou have now extended the power of the linear models that you can deploy to predict people and their behaviour.\n\n\n\n\n\n\nTip\n\n\n\nModels like the models you have been working with are used by:\n\nscientists to predict outcomes relevant to important research questions;\nbusinesses using Artificial Intelligence to predict client or customer outcomes.",
    "crumbs": [
      "Home",
      "PSYC122",
      "7. Week 18 -- Developing the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week18.html#sec-wk18-lab-activities-answers",
    "href": "PSYC122/Week18.html#sec-wk18-lab-activities-answers",
    "title": "7. Week 18 – Developing the linear model",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week.\n\n\n\n\n\n\nTip\n\n\n\nThe .Rmd script containing all code and all answers for each task and each question will be made available after the final lab session has taken place.\n\nYou can download the script by clicking on the link: 2023-24-PSYC122-w18-workbook-answers.Rmd.\nOr by copying the code into the R Console window and running it to get the 2023-24-PSYC122-w18-workbook-answers.Rmd loaded directly into R:\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.Rmd?raw=true\", destfile = \"2023-24-PSYC122-w18-workbook-answers.Rmd\")\n\n\n\nWe set out answers information the Week 18 Developing the linear model questions, below.\n\nWe focus on the Lab activity 2 questions where we ask you to interpret something or say something.\nWe do not show questions where we have given example or target code in the foregoing lab activity Section 5.4.\n\nYou can see all the code and all the answers in 2023-24-PSYC122-w18-workbook-answers.Rmd.\n\nAnswers\n\n\n\n\n\n\nTip\n\n\n\nClick on a box to reveal the answer.\n\n\n\nQuestions\n\nQ.1. What is the estimate for the coefficient of the effect of the predictor mean.acc on the outcome mean.self in this model?\n\nThe model is:\n\nmodel &lt;- lm(mean.self ~ mean.acc, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.1. 5.5670\n\n\n\n\n\nQ.2. Is the effect significant?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.2. It is significant, p &lt; .05\n\n\n\n\n\nQ.3. What are the values for t and p for the significance test for the coefficient?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.3. t = 8.499, p = 9.36e-15\n\n\n\n\n\nQ.4. What do you conclude is the answer to the research question, given the linear model results?\n\nThe research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.4. The model slope estimate suggests that higher levels of tested understanding can predict higher levels of rated understanding so, yes: it does appear that people can evaluate their own understanding.\n\n\n\n\n\nQ.5. What is the F-statistic for the regression? Report F, DF and the p-value.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.5. F-statistic: 72.24 on 1 and 170 DF, p-value: 9.356e-15\n\n\n\n\n\nQ.6. Is the regression significant?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.6. Yes: the regression is significant.\n\n\n\n\n\nQ.7. What is the Adjusted R-squared?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.7. Adjusted R-squared: 0.2941\n\n\n\n\n\nQ.8. Explain in words what this R-squared value indicates?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.8. The R-squared suggests that about 30% of outcome variance can be explained by the model\n\n\n\n\n\nQ.9. What predictors are significant in this model?\n\nThe model is:\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc,\n            data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc, \n    data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.72027 -0.49118 -0.00177  0.55561  2.00134 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.561110   0.700632   0.801   0.4244    \nHLVA         0.041272   0.034833   1.185   0.2378    \nSHIPLEY     -0.046125   0.018701  -2.466   0.0147 *  \nFACTOR3      0.063689   0.010747   5.926 1.74e-08 ***\nAGE          0.025570   0.005472   4.673 6.12e-06 ***\nmean.acc     4.763278   0.708166   6.726 2.69e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8805 on 166 degrees of freedom\nMultiple R-squared:  0.5014,    Adjusted R-squared:  0.4864 \nF-statistic: 33.39 on 5 and 166 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.9. Vocabulary (SHIPLEY), reading strategy (FACTOR3), AGE, and performance on tests of accuracy of understanding (mean.acc) all appear to significantly predict variation in mean ratings of understanding (mean.self).\n\n\n\n\n\nQ.10. What is the estimate for the coefficient of the effect of the predictor mean.acc in this model?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.10. 4.763278\n\n\n\n\n\nQ.11. Is the effect significant?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.11. It is significant, p &lt; .05\n\n\n\n\n\nQ.12. What are the values for t and p for the significance test for the coefficient?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.12. t = 6.726, p = 2.69e-10\n\n\n\n\n\nQ.13. What do you conclude is the answer to the follow-up question, what actually predicts ratings of understanding?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.13. Ratings of understanding appear to be predicted by performance on tests of accuracy of understanding, together with variation in age, vocabulary knowledge, health literacy and reading strategy\n\n\n\n\n\nQ.14. Why do you think it appears that the slope coefficient estimate is different if you compare:\n\n\nThe model mean.acc ~ mean.self versus\nThe model mean.self ~ mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.14. Linear models are prediction models. We use them to predict variation in outcomes given some set of predictor variables. Predictions will necessarily be scaled in the same way as the outcome variable.\n\nSo, to expand on that explanation a bit more, to help understanding – the answer is:\n\nIf we have the model, mean.acc ~ mean.self then this means that the outcome is mean.acc.\n\n\nSo if we are predicting change in outcome mean.acc, which is scaled 0-1, then we are looking at coefficients that will lie somewhere on the same scale (also 0-1).\nHere: the model estimate suggests that each unit change in values of the variable mean.self predicts an increase of 0.053566 in mean.acc.\n\n\nWhereas if we have the model, mean.self ~ mean.acc then this means that the outcome is mean.self.\n\n\nSo if we are predicting change in outcome mean.self, which is scaled 1-9 , then we are looking at coefficients that will lie somewhere on the same scale (also 1-9).\nHere: the model estimate suggests that unit change in mean.acc predicts increase of 5.5670 in mean.self.\n\n\n\n\n\nQ.15. Can you plot the predictions from each model?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.15. Here is the code to plot the predictions from both models.\n\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nFirst fit the models.\n\nRemember to give each model object distinct names.\n\n\nmodel.1 &lt;- lm(mean.acc ~ mean.self,\n              data = study.two.gen)\nsummary(model.1)\n\nmodel.2 &lt;- lm(mean.self ~ mean.acc,\n            data = study.two.gen)\nsummary(model.2)\n\nSecond get the predictions:\n\ndat.1 &lt;- ggpredict(model.1, \"mean.self\")\ndat.2 &lt;- ggpredict(model.2, \"mean.acc\")\n\nThird make the prediction plots:\n\nPredictions from the model mean.acc ~ mean.self\n\n\nplot(dat.1)\n\n\nPredictions from the model mean.self ~ mean.acc\n\n\nplot(dat.2)\n\n\n\n\n\nQ.16. Look at the two plots: what do you see?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.16. A side-by-side comparison shows that:\n\n\nFor model mean.acc ~ mean.self increases in predictor mean.self from about 4 to 9 are associated with a change in outcome mean.acc from about .6 to about .85;\nFor model mean.self ~ mean.acc increases in predictor mean.acc from about 0.4 to 1.0 are associated with a change in outcome mean.self from about 5 to about 9.\n\n\n\n\nAfter you have fitted a linear model to examine what variables predict outcome mean self-rated accuracy of mean.self:\n\nIncluding as predictors both numeric variables and categorical variables.\n\nThen if you look at the model summary you can answer the following questions.\n\nQ.17. Can you report the overall model and model fit statistics?\n\nThe model is:\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc +\n                        EDUCATION,\n            data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + \n    EDUCATION, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70987 -0.50037  0.01988  0.55965  2.01412 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.487753   0.702049   0.695   0.4882    \nHLVA                0.047100   0.034915   1.349   0.1792    \nSHIPLEY            -0.044132   0.018719  -2.358   0.0196 *  \nFACTOR3             0.061918   0.010771   5.749 4.29e-08 ***\nAGE                 0.023997   0.005595   4.289 3.06e-05 ***\nmean.acc            4.912833   0.712381   6.896 1.10e-10 ***\nEDUCATIONHigher    -0.082217   0.146390  -0.562   0.5751    \nEDUCATIONSecondary  0.346161   0.266030   1.301   0.1950    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8783 on 164 degrees of freedom\nMultiple R-squared:  0.5099,    Adjusted R-squared:  0.489 \nF-statistic: 24.38 on 7 and 164 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.17.\n\n\nWe fitted a linear model with mean self-rated accuracy as the outcome and with the predictors: health literacy (HLVA), vocabulary (SHIPLEY), reading strategy (FACTOR3), AGE, as well as mean accuracy (mean.acc) and education level (EDUCATION). The model is significant overall, with F(7, 164) = 24.38, p &lt; .001, and explains 49% of variance (adjusted R2 = 0.489).\n\n\n\n\n\nQ.18. Can you plot the predicted effect of EDUCATION given your model?\n\n\n\n\n\n\n\nHint and code\n\n\n\n\n\n\nWe first fit the model, including EDUCATION.\n\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + EDUCATION,\n            data = study.two.gen)\n\n\nWe then use the ggpredict() function to get the prediction for the effect of EDUCATION differences on outcome mean.self.\n\n\ndat &lt;- ggpredict(model, \"EDUCATION\")\nplot(dat)\n\n\n\n\n\nQ.19. Q.19. The plot should give you dot-and-whisker representations of the estimated mean.self outcome for different levels of EDUCATION. What is the difference in the estimated mean.self between the groups?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.19. The difference in the estimated mean.self between these groups is small: the groups vary between ratings of about 7, 7.10 and 7.5.\n\n\n\n\n\nQ.20. Compare the difference in the estimated mean.self between these groups, given the plot, with the coefficient estimate from the model summary: what do you see?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.20. The effect of EDUCATION is presented in the summary as two estimates:\nEDUCATIONHigher    -0.082217\nEDUCATIONSecondary  0.346161\n\nThe reference level for EDUCATION is Further.\nThe estimates therefore show that people with Higher education have mean.self scores about -.08 lower than mean.self for people with Further education.\nPeople with Secondary education have mean.self scores about .35 higher than mean.self for people with Further education.",
    "crumbs": [
      "Home",
      "PSYC122",
      "7. Week 18 -- Developing the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week18.html#sec-wk18-lab-Q-and-A",
    "href": "PSYC122/Week18.html#sec-wk18-lab-Q-and-A",
    "title": "7. Week 18 – Developing the linear model",
    "section": "Online Q&A",
    "text": "Online Q&A\nYou will find, below, a link to the video recording of the Week 18 online Q&A after it has been completed.",
    "crumbs": [
      "Home",
      "PSYC122",
      "7. Week 18 -- Developing the linear model"
    ]
  },
  {
    "objectID": "PSYC121/Week4.html",
    "href": "PSYC121/Week4.html",
    "title": "4. Customisation of graphs, and z-scores",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Lecture Part 3\n```\nWatch Lecture Part 4\n\nDownload the lecture slides here",
    "crumbs": [
      "Home",
      "PSYC121",
      "4. Customisation of graphs, and z-scores"
    ]
  },
  {
    "objectID": "PSYC121/Week4.html#customisation-of-data-plots",
    "href": "PSYC121/Week4.html#customisation-of-data-plots",
    "title": "4. Customisation of graphs, and z-scores",
    "section": "3.1 - Customisation of data plots",
    "text": "3.1 - Customisation of data plots\nStep 1. Set up a project / folder that you created last week.\nStep 2. Bring the week_4_2024.zip file into R Studio server. Like last week, upload the zip file. Launch the week_4 R script as before, and read in the data file.\n{If you’ve done Step 1 &2 already as a pre-lab preparation, super, pat yourself on the back, skip these steps an move on)}\nStep 3. Once again, we’re gong to be using commands from the tidyverse library (the pipe operator is one example) so we need to ensure that it’s active. Run the command\nlibrary(tidyverse)\nStep 4. Read in the datafiles that will be on the server. There’s already a script line for this, you just need to change the file name (and we’ve done this in previous weeks)\nStep 5. We’ve provided a suggestion of how you can complete the visualisation challenge task from week 3.\nStep 6. Customize you graph work. We’ve provided some suggestions about adding titles and labels for your graph. Edit and play with the script lines to make them useful to you and to understand how they work. Note that the ggplot instructions have a similar structure / grammar to the group_by() instructions that we used: piping a data frame to a (here, plotting) function and piping that to an output or summarisation format.\n\nTry change the text, the colours, and so on of the graphs.\nAdd comments for yourself about what the different commands do. The idea is to learn by trying different things out (changing values, taking out elements of the command, putting other is) and record for yourself.\nIf you are struggling or not sure, try look at help files.",
    "crumbs": [
      "Home",
      "PSYC121",
      "4. Customisation of graphs, and z-scores"
    ]
  },
  {
    "objectID": "PSYC121/Week4.html#z-scores",
    "href": "PSYC121/Week4.html#z-scores",
    "title": "4. Customisation of graphs, and z-scores",
    "section": "3.2 - z-scores",
    "text": "3.2 - z-scores\n\nHint / Reminder: Sketch a normal (z score) distribution and mark the mean/mode, and mark off the relevant parts of the question so you know what you are trying to achieve and how to interpret any calculations you make.\n\n\nHint/ Guide 2. For questions 6 & 7, typically in psychology we use the 5% level as a cutoff to decide, in broadly described terms, whether something is extreme or unlikely vs. at least somewhat plausible or likely.\n\n\n3.2.1 z-scores 1\nz-score distributions\nQ1. What is the relationship between the sign of a z-score and its position in a distribution?\nQ2. If a distribution has a mean of 100 and a standard deviation of 10, what is the raw score equivalent to a z-score of 1.96?\nQ3. If a distribution has a mean of 157 and a standard deviation of 19, what is the raw score equivalent to a z-score of 1?\n\n\n3.2.2 z-scores 2 Using z-score tables\nQ4. What proportion of scores lie between the mean and a z-score of 0.5?\nQ5. What is the combined proportion of scores lying between z=-1.2 and z=.85?\n\n\n3.2.3 z-scores 3 Applying z-scores to inferential problems\nQ6. A Neuropsychologist has presented a test of face recognition to 200 neurotypical participants and finds that the scores are normally distributed with a mean of 85 and the standard deviation of 12. Two brain-damaged patients are also given the test. The one with right hemisphere brain damage scored 58 and the one with left hemisphere damage scored 67.\n\nWhat is the z score of the right hemisphere patient when compared to the neurotypical group?\nWhat proportion of neurotypical participants score lower that this patient?\nIs this patient likely to belong to the population of neurotypical participants? (justify your answer)\nWhat is the z score of the left hemisphere patient when compared to the neurotypical group?\nWhat proportion of neurotypical participants score lower than this patient?\nIs this patient likely to belong to the population of neurotypical participants? (justify your answer)\n\n\n\n3.2.4 Final z-score challenge\nCome back to this afterwards for some extra practice if you want:\nQ7. Tom Bunion has completed a huge research study and measured the foot size of men and women and found each to be normally distributed. The men have a mean size of 55 with a standard deviation of 5 and the women a mean of 33 and a standard deviation of 5. Joanna Toes has foolishly measured two individuals but forgotten to note their gender. These have foot sizes of 37 and 47. To which gender is each more likely to belong? What evidence is there for this?",
    "crumbs": [
      "Home",
      "PSYC121",
      "4. Customisation of graphs, and z-scores"
    ]
  },
  {
    "objectID": "PSYC121/Week7.html",
    "href": "PSYC121/Week7.html",
    "title": "7. Filtering data and testing means (one-sample t-test)",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.",
    "crumbs": [
      "Home",
      "PSYC121",
      "7. Filtering data and testing means (one-sample t-test)"
    ]
  },
  {
    "objectID": "PSYC121/Week7.html#reading",
    "href": "PSYC121/Week7.html#reading",
    "title": "7. Filtering data and testing means (one-sample t-test)",
    "section": "Reading",
    "text": "Reading\nChapter 12 of Howell\nToday we will look in a bit more detail at people’s estimates of the average UK salary. We will first plot this data using geom_histogram() and also geom_boxplot(). When we do this, we’ll see that there are some unusual values, and we’ll need to do a bit of data wrangling to remove them, using the filter() command. We’ll then turn to the conceptual ideas of the lecture - how can we tell if the mean of our sample is unusual, or whether we would actually expect this mean value under the null hypothesis? Finally, we’ll continue to develop our skills in data visualisation by exploring geom_density() plots.",
    "crumbs": [
      "Home",
      "PSYC121",
      "7. Filtering data and testing means (one-sample t-test)"
    ]
  },
  {
    "objectID": "PSYC121/Week7.html#task-3---sample-size-size-of-effect-and-the-one-sample-t-test",
    "href": "PSYC121/Week7.html#task-3---sample-size-size-of-effect-and-the-one-sample-t-test",
    "title": "7. Filtering data and testing means (one-sample t-test)",
    "section": "Task 3 - Sample size, size of effect, and the one sample t-test",
    "text": "Task 3 - Sample size, size of effect, and the one sample t-test\nIn the lecture this week, Tom used an application to show the process of sampling data. You can access this application at the link below. There are three “parameters” you can change in this:\n\nThe true mean of the effect: Think of this like the bias that was set up in your deck of cards last week. There is some true state out there in the world, and we are going to draw samples from a distribution of data that has a mean that equals this value. If you make this 100, then the true mean is equal to that under the null hypothesis (there is no effect).\nThe standard deviation of the data: This sets how variable the data are in this population. If the data are more variable, then our samples will produce estimations that are less accurate of the true mean value.\nThe sample size: How many observations are drawn in the sample. These are represented by the yellow circles in the plot.\n\nEach time you draw a sample the data points are plotted in yellow and the mean of the sample is marked with the red line. The application also runs a one-sample t-test against the expected mean under the null hypothesis, of 100. The null hypothesis is also represented by the static distribution presented in grey, centred on 100.\nThings to try:\n\nStart with a sample size of 10, and a mean of the effect of 110 (SD = 15). How often do you get a significant result (p &lt; .05) when you draw a new sample?\nNow try changing the mean of the effect to 120. Does this increase or decrease the likelihood of getting significant results? What about changing to 130?\nNow keep the mean effect constant (say 110), but increase the sample size. Try 5, then 10, 15, and so on. Does this increase or decrease the likelihood of getting significant results?\nSet the mean of the effect to 100 and the sample size to 10. Keep drawing new samples, noting each time the p value. You will evenutally get a p value of &lt; .05. What type of error is this?\n\nClick here for the one-sample t-test application\n\nTask 4 - Practising filtering\n\nFiltering is very useful for selecting certain sub-sets of our data. Here we have given you an example of how we select a sub-set of data based on two conditions from two different columns:\n\n\nname_of_the_data_object %&gt;% \n  filter(home_location_in_UK == \"NW\" & sibling_order == \"oldest\")\n\nWe have given you a few different columns to look at and to use in practicing your filter commands:\n\nsibling_order: what position in age was the respondent within their siblings\nhome_location: UK / Asia / Europe, etc\nhome_location_in_UK: NW, NE, etc (NA is non-UK residents)\nattention_check: respondents were asked “click strongly agree to show you are paying attention” - some people failed this!!!\n\nGain some skills in filtering by trying to complete the following filters. Use the filtered data object that has 130 rows. We’ve put in () the number of rows you should see in the resulting object, after the filter.\n\nJust those people who come from the North East (15 rows)\nThose people who come from South East and are an only child within their siblings (7 rows)\nThose people who failed the attention check (17 rows)\nThose people passed the attention check, are from the UK, and are the oldest child (30 rows)\nThose people who are NOT from the North West (hint: you’ll need to use !=) (64 rows)\nThose people who are from the South East or (|) the South West (33 rows)",
    "crumbs": [
      "Home",
      "PSYC121",
      "7. Filtering data and testing means (one-sample t-test)"
    ]
  },
  {
    "objectID": "PSYC121/Week7.html#week-7-quiz",
    "href": "PSYC121/Week7.html#week-7-quiz",
    "title": "7. Filtering data and testing means (one-sample t-test)",
    "section": "Week 7 Quiz",
    "text": "Week 7 Quiz\nYou can access a set of quiz questions related to this week here.",
    "crumbs": [
      "Home",
      "PSYC121",
      "7. Filtering data and testing means (one-sample t-test)"
    ]
  },
  {
    "objectID": "PSYC121/Week2.html",
    "href": "PSYC121/Week2.html",
    "title": "2. Descriptive statistics in RStudio",
    "section": "",
    "text": "Due to illness, we’re releasing some previously recorded lecture videos that explain the week 2 content. Unfortuantely I’m full of cold right now - and making a video recording is just creating a muffled and hard to hear version of the ideas :-(\nAlso, just bear in mind - these lectures in PSYC121 are designed to provide an explanation of the conceptual and computational work involved in some core analytic material. The workshops are designed (a) to put these ideas into practice (b) to work with R Studio in practicing with data, as a tool that can help to explore data. So the lectures and lab complement each other, and we will continue to takle this approach across the module.\nWatch Part 1\n\nWatch Part 2\n\nWatch Part 3\n\nDownload the lecture slides here",
    "crumbs": [
      "Home",
      "PSYC121",
      "2. Descriptive statistics in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/Week2.html#r-studio-tasks-recap",
    "href": "PSYC121/Week2.html#r-studio-tasks-recap",
    "title": "2. Descriptive statistics in RStudio",
    "section": "3.1 R Studio tasks recap",
    "text": "3.1 R Studio tasks recap\nFor a reminder of how to start RStudio, see week 1’s instructions\n(remember: off campus, you will need to be on the VPN)\n\nA word of advice (from David Howell’s statistics book: One more word of advice I can’t resist adding what is perhaps the best advice I have. If there is something that you don’t understand, just remember that “Google is your friend.” She certainly is mine. (Well, maybe Google is getting a bit pushy, but there are many other search sites.) If you don’t understand what Fisher’s Exact Test is, or you don’t like my explanation, go to Google and type in Fisher’s Exact Test. I just did that and had 260,000 hits. You can’t tell me that there isn’t going to be something useful in there.)",
    "crumbs": [
      "Home",
      "PSYC121",
      "2. Descriptive statistics in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/Week2.html#bringing-data-scripts-and-files-into-r-studio",
    "href": "PSYC121/Week2.html#bringing-data-scripts-and-files-into-r-studio",
    "title": "2. Descriptive statistics in RStudio",
    "section": "3.2 Bringing data, scripts and files into R Studio",
    "text": "3.2 Bringing data, scripts and files into R Studio\nIn week 1, we had a tiny dataset (relatively speaking) that we entered into R through a script line. That worked for what is was. But it’s going to become painful and tedious when (a) we want to work with larger datasets (b) we have data more complex than a 1-dimensional list of numbers (think about some 2-dimensional data sheets you might have encountered in excel for example)\nR can handle data files, and this week we’re going to explore them. Within R, we can specify ‘data frames’ which can have, essentially, multiple columns of data, and we can link data files to data frames for processing\nTo make things straightforward, each week we’ll provide students with a “zip” file that contains the script to start from (which you can expand and annotate etc, and save on your file space). We’ll also provide a data file or data files for you to use in the zip file. R can then import these files into the RStudio environment. So when you upload the zip file, you can import the data AND you can open up the script",
    "crumbs": [
      "Home",
      "PSYC121",
      "2. Descriptive statistics in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/Week2.html#main-lab-exercise---descriptive-information-in-r-studio-penelope-the-cow",
    "href": "PSYC121/Week2.html#main-lab-exercise---descriptive-information-in-r-studio-penelope-the-cow",
    "title": "2. Descriptive statistics in RStudio",
    "section": "3.3 Main lab exercise - descriptive information in R Studio (Penelope the cow)",
    "text": "3.3 Main lab exercise - descriptive information in R Studio (Penelope the cow)\nSome years ago, a large group of participants gave an estimate of the weight of Penelope the cow. Just over 17,000 guesses. And the distribution of guesses was something like this: \nWhat we can see from this graph is that:\n\nGuesses formed a roughly normal distribution. There is a bit of a skew with a right-hand tail, but this is inevitable as a weight of less than 0 is physically impossible, but there is no limit of the semantics of a large guess.\nThe mean guess weight (1,287 lbs) is very close to the actual (true) weight of the cow (1,355 lbs). So even though lots of people were inaccurate, a central tendency measure has a pretty good alignment with the true weight. This is known as the Wisdom of Crowds phenomenon, first identified by Galton in 1907 (though he suggested using the median weight). The concept of the wisdom of crowds continues to be used and investigated in psychology today (see for example here and here\n\nLet’s look at (a sample of) the PSYC121 student data collected on guessing the weight of Penelope, and ask whether it resembles the properties of this large dataset.\n\nStep 1. Loading the data\nUsing the instructions and advice given on Moodle, get the week_2_2024.zip file and bring the data and R script into R Studio. The week 2 zip file is here\n\n\nStep 2. Using the R script\nLet’s start working with our data, by opening up (clicking on) the script “Week_2.R” file.\nThe first command is to load a library of functions:\n\nlibrary(tidyverse)\n\nTo run this, simply click anywhere on line 1 of the R script to put the cursor there, and press ctrl+enter (cmd+enter on a mac) or click the button called run. You will see a number of messages appear in the console. Don’t worry about these, or worry too much about what exactly this command is doing. Essentially this is giving us some useful tools for our analysis. We will introduce the features of the tidyverse gradually during this course.\nThe data are on the RStudio server if you have followed all the instructions to this point. Note that when you imported the data into the R environment, a command line was generated at the console\n\ncows &lt;- read_csv(\"~/penelope22.csv\")\n\nWhat this command accomplished was to read the spreadsheet called ‘penelope22’ into an object in R called cows. You could use any object label - it doesn’t have to be ‘cows’- but it’s important to then keep that alternate name consistent in what you do next.\nThe command was also generated\n\n View(cows)\n\nwhich presents the data in a window of RStudio. Note that “NA” means not available or missing data. Does this file structure make some sense to you?\n\n\nStep 3. Finding the mean and median estimates\nUse the data to answer the following questions…\n\nWhat is the mean weight estimates?\nWhat is the standard deviation of the estimates?\nWhat is the median weight of the estimates?\nWhich of these central tendency measures is the more accurate measure of the true cow weight? (make a judgement)\nWhat is the mean weight estimate (and standard deviation) for female respondents and non-female (male / non-binary /prefer not to say) respondents?\n\nYou may be thinking, how do I possibly do any of this?! Well this week most of the commands you need are contained in the R script you have downloaded. Also, remember from last week, we explored the R command:\n\nmean(week_1_lecture_data)\n\nThat gave us the mean of the small dataset week_1_lecture_data. This time, we want to explore the penelope dataset. But also, the lecture_data was just a single list of numbers. The penelope22 object is more like a datasheet. So we need to tell R Studio which column we are interested in. RStudio uses the format data$column. So run the followinbg line in the script\n\nmean(cows$estimate) \n\n\nsd(cows$estimate)\n\nSo from this, can you work out what you would do to get the median value (remember from last week how we got the median value?)? Part of the command is given to you, can you change the text so that it works?\n\n\nStep 4. Calculations from a range of columns\nWe have seen that:\n\nmean(cows$estimate) \n\nwill provide a mean of the column “estimate”. In the third column, named “female_estimate”, we have the estimates of just the female respondents. In the fourth column, named “other_estimate”, we have the estimates of the “other” respondents (males and non-binary and prefer not to say).\nSo can you now figure out how you might get information about the estimate from the female data (only) or the non-female data? Try it, based on what you have just done. Does it work?\nYou will find that the result of the this command produces an “NA” result. This means that the answer is “Not Available”, or in other words, is a “missing value”. This is because some of the values in this column are NA, and the mean of a column with NAs will always lead to the result NA.\nInstead, try change the script so it looks like this:\n\nmean(cows$female_estimate, na.rm = TRUE )\n\nAny different? The na.rm = TRUE instruction tells RStudio that missing data can be ignored in this mean calculation. (in technical language, na.rm is a parameter of the function mean that removes the NAs if set to TRUE)\n\n\nStep 5. Simple graphs\nRStudio can be used to create graphical data plots that can help interpret datasets\nThe first thing we can do is create a histogram distribution of guesses from the sample student data to compare with the previous large sample study (i.e. the 17,000 guesses):\n\nhist(cows$estimate)\n\nOne way to alter or adjust the histogram is to change the width of the bars, the intervals, between each plot section. Try run this line from the script\n\nhist(cows$estimate, breaks = ??)\n\nDoes it work? No? What you need to do is replace the two question marks in the script (or better still, create a new instruction line in which you amend this to have a numerical value representing the number of different plot bars. Try at least 3 different values. Look at and think about how this affects the visual distribution.\nWe can also create a “box and whisker plot”. Here’s a general simple description of a box-and-whisker plot as a graphical representation of data:",
    "crumbs": [
      "Home",
      "PSYC121",
      "2. Descriptive statistics in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/Week2.html#extension-and-practice.-apply-your-new-skils-to-a-different-dataset",
    "href": "PSYC121/Week2.html#extension-and-practice.-apply-your-new-skils-to-a-different-dataset",
    "title": "2. Descriptive statistics in RStudio",
    "section": "3.4. Extension and practice. Apply your new skils to a different dataset",
    "text": "3.4. Extension and practice. Apply your new skils to a different dataset\nIn the zip file, we also provide data on the estimates of the percentage of immigrants in the UK. This will allow you to explore this variable, create visualisations of the data and its spread. We’ll be looking at a version of this variable in week 3: but for now, can you apply the analysis of the penelope data to the immigration data (report descriptive statistics)? Write some new script lines to investigate this additional dataset, and annotate those new script lines.",
    "crumbs": [
      "Home",
      "PSYC121",
      "2. Descriptive statistics in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/index.html",
    "href": "PSYC121/index.html",
    "title": "Statistics for Psychologists I",
    "section": "",
    "text": "Welcome\nWelcome to the PSYC121 lab material for 2024!\nIn this module we will provide you with an introduction to data handling, data processing and data visualisation. What that means is that, by the end of the this module (at Christmas time), you will be able to take a set of data, look at some basic statistics (e.g., the mean value), filter and process the data in order to answer basic questions about it, and present the data in an appealing way with different graphs. On top of this, you will be able to apply some of your knowledge of the basic “inferential” statistical tests that we will introduce in the lecture series (e.g., “t-test”).\nIn Week 1 we will introduce you to the software that we use to do all this useful work in statistics: “R” and “RStudio”. This is a coding language, and you will be taught the basics of how to write code in order to do all of the above key steps in data analysis. This tuition will continue in Term 2, and in your statistics modules in Year 2. Coding is challenging, but we know from experience that those students who attend classes, who work through the exercises carefully, and who seek help when they need it, do very well on these modules.\nMost of all, it’s important that you recognise that data analysis (statistics) is a critical aspect of the study of psychology. When we want to understand behaviour, we take measurements of that behaviour, which the majority of the time will result in quantitative (numerical) data. In order to understand the behaviour in a meaningful way, we need to conduct all of the above steps in our data analysis workflow. In summary, we cannot investigate psychological processes without the skills and toolbox of statistics and data analysis techniques.\n\n\nWorking at your own pace and seeking help\nWe have carefully prepared and refined the lab materials in this course over several years, and we feel that the pace of the materials is just about right for our students. Some students will complete them more quickly, and others more slowly - both of these scenarios are absolutely fine. You should work at the pace that suits you best, making sure you understand the materials before you move forward.\nIt is fairly inevitable that you will get stuck on the lab materials in this module at some point. This might be in Week 1, Week 2, or later. When you do, it’s important you reach out for help:\n\nAsk your friends on your table. We’ve designed this teaching space to help collaborative work. You are encouraged to work with other students. Make sure you ask others to explain how they’ve solved an exercise. Make sure you help out others where you can. Always make sure you understand the code and the exercise; don’t simply be satisfied that you’ve got the right answer.\nAsk a GTA or Lecturer. Our Graduate Teaching Assistants are there to help you. There are no “stupid questions” in statistics, so just ask the GTAs any question about what you’re doing. Likewise, ask the Lecturer.\nAsk on the Discussion Forum. On the PSYC121 moodle page you will find a Discussion Forum. This is a great way to ask a question outside of the lab sessions. It might seem scary to ask a question in the forum, but please don’t be afraid to do this. If you have a question, you can bet 30+ other students also have the same question! So by asking the question on the forum, you help out many more people on the module. A friendly GTA or Lecturer will be along to answer the question as soon as possible (we aim for within 48 hours during the working week).\nAsk on the module Q & A session. Each week we hold a “Q&A” online session where we will try and resolve any general queries and problems. It’s an ideal time to discuss things that students are struggling with or confused about, and can share ideas and answers. You can ask on the discussion forum above and then we might be able to pick up the issues and discuss them, but also you can ask in the session itself.\n\nAsking good questions - it’s really important that you give us as much information as you can when you ask your questions (in class and especially on the forum). It’s so much harder to help respond to “I can’t do Exercise 5 in Week 7” (because we don’t know why it is that you can’t do it) than for example “In Exercise 5 of Week 7, I’ve managed to read in the data, put the graph looks quite odd. Here is the code I’m using…”\n\n\nCourse Contacts\nIf you have something that needs to be private, then please feel free to email the academic staff at the email addresses below:\n\n\n\n\nEmail Address\n\n\n\n\nTom Beesley (Coordinator)\nt.beesley at lancaster dot ac dot uk\n\n\nJohn Towse\nj.towse at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "PSYC121"
    ]
  },
  {
    "objectID": "PSYC121/Week8.html",
    "href": "PSYC121/Week8.html",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.",
    "crumbs": [
      "Home",
      "PSYC121",
      "8. Related-samples t-tests, plotting means and SE bars"
    ]
  },
  {
    "objectID": "PSYC121/Week8.html#reading",
    "href": "PSYC121/Week8.html#reading",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "Reading",
    "text": "Reading\nChapter 13 of Howell\nToday we will take a look at summarising means and standard errors (SEs) from our data. We will look at how we plot these together on the one graph (using ggplot() commands that allow us to share mappings between different geoms. We will explore our data on the famous “Stroop Task” and we will use a related-samples t-test to examine the differences between the means of our different conditions in this task.",
    "crumbs": [
      "Home",
      "PSYC121",
      "8. Related-samples t-tests, plotting means and SE bars"
    ]
  },
  {
    "objectID": "PSYC121/Week8.html#pre-lab-work-online-tutorial",
    "href": "PSYC121/Week8.html#pre-lab-work-online-tutorial",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "Pre-lab work: online tutorial",
    "text": "Pre-lab work: online tutorial\nOnline tutorial: You must make every attempt to complete this before the lab! To access the pre-lab tutorial click here (on campus, or VPN required)\nGetting ready for the lab class\n\nCreate a folder for Week 8 and download the Week_8 csv file file and upload it into this new folder in RStudio Server.",
    "crumbs": [
      "Home",
      "PSYC121",
      "8. Related-samples t-tests, plotting means and SE bars"
    ]
  },
  {
    "objectID": "PSYC121/Week8.html#rstudio-tasks",
    "href": "PSYC121/Week8.html#rstudio-tasks",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "RStudio Tasks",
    "text": "RStudio Tasks\n\nTask 1 - Examining the distributions and filtering\nThe “Stroop Effect” is a classic demonstration of automaticity of behaviour. Participants have to say the colour a word is printed in, which is an easy task for a “compatible” stimulus like GREEN, and a much more difficult task for an “incompatible” stimulus like BLUE. We can’t help but read the text - it has seemingly become an automatic process.\n In this task we will calculate the means and standard errors of the means and then we will then plot them using ggplot(). First though, we’ll need to inspect the data and maybe do a bit of data wrangling by using our filter() command.\n\nCreate a new R Markdown document. If you’re unsure about this step, see the instructions from Week 6 (or 7).\nAs usual, add a code chunk with library(tidyverse) and a read_csv command (see above for the link to the csv). Assign the result to a new data object, and call your data something meaningful (perhaps data_w8 or data_stroop but maybe not bestest_most_fantastic_data_on_the_stroop_test_eva_init)\nView the data with View(data_object_name). You will see that the data are a little different from the data we have worked with previously. We have an pID variable, which gives a unique number for each person, but each person has 3 rows of data. This is because the different conditions of the Stroop task reflect a within-subjects variable (related samples). For data like this it is often useful to have them arranged in what is referred to as “long format”, with multiple rows for each response the participant provides. For the current data that means we have a variable called condition, which is our IV, and one called time which is our DV. We also have a column labelled avg_time, which is the average of the 3 time values for each participant (the data is duplicated, which is both normal and necessary with long format data).\nLet’s look at the distribution of time (our DV) as a function of condition. Add another chunk of code and include the following code:\n\n\n# distribution of times by condition\nyour_data_object %&gt;% \n  ggplot() +\n  geom_density(aes(x = missing_column_name_A, fill = missing_column_name_B), alpha = .8) + # you need to EDIT this for Q4\n  theme_dark()\n\n\nYou’ll need to “map” x to time and fill to condition for our geom_density() plot. You can play around with the alpha parameter (which sets the transparency of the elements of the graph), setting it to a value between 0 and 1. Note that this is done OUTSIDE of the aes() command.\nFrom the density plot, it does seem like we have some outlier values. It’s probably best if we remove data for the whole participant if their average time is unusual. To do that, we’ll look at the data using the avg_time column. Add the following code for a geom_histogram() to plot the distribution of values in the new avg_time column.\n\n\n# distribution of average times\nyour_data_object %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = missing_column_name_A), fill = \"pink\") + # you need to EDIT this line\n  theme_classic()\n\n\nLet’s use the filter command we learned last week to remove these high values. Like last week, we will do this (for now) in a fairly unprincipled manner, by “eyeballing” the data (next week we’ll consider something a bit more “scientific”). Complete the filter command so that it keeps only the responses for people that had an avg_time less than 12 seconds. Remember that you need to think about how you are storing the result of this filter process. Do you want to create a new object, or overwrite the existing object?\n\n\n# filter out the high values\nnew_data_object &lt;- # create a new object (or overwrite)\n  your_data_object %&gt;% # original data object \n  filter(insert_an_expression_here)\n\n\n\n\n\n\n\nCheck your result!\n\n\n\nIf you’ve done this correctly, you should now have a data object that has 360 rows (data for 120 participants, with 3 responses each).\n\n\n\nAdd and edit the following code to plot a histogram of the filtered data.\n\n\n# draw a histogram of the filtered data \nnew_data_object %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = missing_columns_name), \n                 fill = \"pink\", # try some different colours?\n                 colour = \"purple\", # and here?\n                 bins = 3) #  # adjust the bins? \n# you could also add (+) a theme to this plot! \n# for a list of themes, type: ?theme_classic\n\n\nFinally, copy the code for the original geom_density() plot that you drew in step 4. Paste it, and edit the code so that it now plots the filtered set of data (from step 7) for each of the three conditions in the stroop task.\n\n\n\nTask 2 - Running related samples t-tests\nWe have seen in our density plots that the reaction times (DV) look different in the three different Stroop conditions (our IV). But now we need to look at whether there are statistically significant differences between the means of the three conditions.\nTo do this, we will first summarise the mean time taken by each condition in the Stroop task. In Week 3 we learnt how to use group_by() and summarise() to get summary stats (e.g., mean, sd) at each level of the IV. That’s what we want to do now:\n\nCopy the code below into your R Markdown and edit the group_by() line to specify the IV and the summarise() line to calculate the mean() of our DV. If you do this correctly, you’ll get three values - a mean value for each level (condition) of our IV. Do these means reflect what you would expect in the Stroop task? Do they match the central tendency of the distributions you plotted?\n\n\nname_of_data_object %&gt;%\n  group_by(name_of_IV_column) %&gt;% # you need to EDIT this for Q1\n  summarise(stroop_mean = mean(name_of_DV_column)) # you need to EDIT this for Q1\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nYou should have 3 values: 4.22, 5.69, 7.28\nIf all of your values are the same, you’ve analysed the wrong column.\n\n\n\n\nNext we need to test if these differences between our means are real. To do that, we can run a related samples t-test. We use this test because each level of the IV in this experiment came from the same person. First though, we must use a filter() to restrict the data to just two levels of the IV. The IV is the condition column/variable in the data. The related samples t-test looks at the difference between two means (and only two), so the column we use for the t-test needs to have just two levels of the IV (two of the conditions).\nCopy the code below into your R Markdown. The filter command is already set up to restrict the data to two of the conditions. Note that the filter uses an “|” symbol, which means “or”, because we want the data that is the same as (==) one condition OR is the same as (==) the other condition. You’ll need to edit the name of the data object to get this to run.\n\n\n# use filter to select two levels of the IV - Q3-5\nstroop_comparison &lt;-\n  name_of_data_object %&gt;% # Edit this for the name of YOUR data object\n  filter(condition == \"compatible\" | condition == \"incompatible\")\n\n# run the t-test comparing the means of these two levels\nt.test(data = stroop_comparison, time ~ condition, paired = TRUE)\n\n\nRun the t-test on this selection of data to compare the means from these two levels of the IV. Is the result significant? Note the t-value and the p-value.\nWrite out a statement in your R Markdown document to express this result. Here’s a template you can use, where you need to edit the bits in the []:\n\n\n“There [was a / was no] significant difference between the [describe the variables that were compared], t([degrees of freedom here]) = [t value here], p &lt; [p value here].”\n\n\nWith 3 levels to the IV condition there are 3 possible comparisons we can make (L1 vs. L2; L1 vs. L3; L2 vs. L3). Complete all three tests, by copying and pasting the code chunk twice more, editing each to make a different filter selection, and then running the t-test. Write out a reporting statement (Q5) for each of your comparisons.\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nUsing the filtered data (360 rows) you should get the following t statistics: -18.257, -11.754, -10.258\nRemember that it’s the magnitude that’s important, not whether it’s positive or negative. The sign simply depends which way round they are compared in the t calculations (mean_1 - mean_2 or mean_2 - mean_1)\n\n\n\n\n\nTask 3 - Plotting the means and SEs\n\nIn Task 2 you calculated the means for each condition in the Stroop task. We’ve seen in lectures that “standard error” provides an estimate of how variable that mean will be across the samples we collect. A very typical way to plot a mean value is to plot it with the standard error of the mean (SEM):\n\n\n\nThe code from Task 2, Question 1 will give the mean. We will now add a second line of this code to give the standard error values:\n\n\nstroop_summary &lt;- \n  name_of_data_object %&gt;%\n  group_by(name_of_IV_column) %&gt;% # you need to EDIT this for Q2\n  summarise(stroop_mean = mean(name_of_DV_column),\n            stroop_SE = sd(name_of_DV_column)/sqrt(n())) # you need to EDIT this for Q1\n\n\nAdd this code to your document and the correct column (DV) to both the sd() and the mean() commands. Note that you don’t need to put anything in n(), as this simply calculates how many rows there are.\nView the new summary object you have created. Check that the means and SEs are different for the 3 conditions. If they are the same, you probably summarised the wrong column!\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nThe SE values should be: 0.117, 0.170, 0.208\n\n\n\n\nWe will now plot these 3 mean values in a figure. Let’s use geom_point() so that our means and SEs look a bit like the figure above. Complete the ggplot command to plot our summarised value called stroop_mean (y), as a function of the IV, condition (x):\n\n\n# let's first plot the means\nname_of_data_object %&gt;%\n  ggplot(aes(x = name_of_IV_column, y = name_of_DV_column)) + # map variables to x and y for Q5\n  geom_point(size = 5)\n\n\nNow we need to add some “error bars” which provide a visual guide as to how much uncertainty we have in our mean value. Edit the code below for the ggplot() command to plot both geom_point() (same as Q5) and geom_errorbar. You will need to calculate a ymin and a ymax value.\n\n\n\n\n\n\n\nPlotting the error bars\n\n\n\nUse the illustration of the error bars above to work out how to combine the mean value and the SE value (hint: you’ll need to either ADD or SUBTRACT for the two statements) to create the right ymin and ymax. You need to put this in the “missing_equation” bit of the code below:\n\n\n\n# let's first plot the means\nname_of_data_object %&gt;%\n  ggplot(aes(x = name_of_IV_column, y = name_of_DV_column)) + # map variables to x and y for Q5\n  geom_point(size = 5) +\n  geom_errorbar(aes(ymin = missing_equation, # edit this for Q5\n                    ymax = missing_equation), # edit this for Q5\n                width = .2) \n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nThe correct result will have 3 points, and an error bar around each mean point. These 3 error bars should all be different sizes (as per the 3 SEs you calculated in steps 2-4)\n\n\n\nEXTRA: These next steps can be completed to practice customising your plot\n\nAdd a labs() layer to the plot to change the axis titles, and the title of the plot.\nChange the theme of the plot (e.g., theme_classic())\nMap the colour aesthetic to the variable condition. You can do this for geom_point or geom_errorbar or both at once by putting it in the aes() within the ggplot() command.\nTry changing your geom_point() to geom_col.\n\n\n\nTask 4 - Knit the document\nLet’s try knitting the document. If you’ve done everything right, then the knitting process will work and you’ll get a nice output (in html, or PDF, whichever you choose). If something goes wrong, here’s a few things you can check\n\nDid you keep all your code in the code chunks?\nCheck all your code blocks run.\nAre there any red cross symbols next to your lines of code? These indicate a code error and need to be fixed before it will knit.\n\nWhen you knit the document, you will probably see the code you have written in the output. You can decide whether you want to present the code or not using the options for each code chunk:\n\nClick the cog, then select the type of output you want each code to produce.\nKnitting the document is a great way to see how your work functions as an actual report. Go back and add more description between your code chunks to describe all the steps you have performed in your analysis.",
    "crumbs": [
      "Home",
      "PSYC121",
      "8. Related-samples t-tests, plotting means and SE bars"
    ]
  },
  {
    "objectID": "PSYC121/Week8.html#week-8-quiz",
    "href": "PSYC121/Week8.html#week-8-quiz",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "Week 8 Quiz",
    "text": "Week 8 Quiz\nYou can access a set of quiz questions related to this week here.",
    "crumbs": [
      "Home",
      "PSYC121",
      "8. Related-samples t-tests, plotting means and SE bars"
    ]
  },
  {
    "objectID": "PSYC121/Week9.html",
    "href": "PSYC121/Week9.html",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.",
    "crumbs": [
      "Home",
      "PSYC121",
      "9. Unrelated-samples t-test and Power"
    ]
  },
  {
    "objectID": "PSYC121/Week9.html#reading",
    "href": "PSYC121/Week9.html#reading",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "Reading",
    "text": "Reading\nChapter 14 of Howell",
    "crumbs": [
      "Home",
      "PSYC121",
      "9. Unrelated-samples t-test and Power"
    ]
  },
  {
    "objectID": "PSYC121/Week9.html#pre-lab-work-online-tutorial",
    "href": "PSYC121/Week9.html#pre-lab-work-online-tutorial",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "Pre-lab work: online tutorial",
    "text": "Pre-lab work: online tutorial\nOnline tutorial: You must make every attempt to complete this before the lab! To access the pre-lab tutorial click here (on campus, or VPN required)\nGetting ready for the lab class\nCreate a folder for Week 9 and download the Week_9 csv file file and upload it into this new folder in RStudio Server.",
    "crumbs": [
      "Home",
      "PSYC121",
      "9. Unrelated-samples t-test and Power"
    ]
  },
  {
    "objectID": "PSYC121/Week9.html#rstudio-tasks",
    "href": "PSYC121/Week9.html#rstudio-tasks",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "RStudio tasks",
    "text": "RStudio tasks\n\nTask 1 - Exploring the data\nIn this class we will be exploring some data on people’s estimations on aspects of the UK population. We asked people 4 different questions:\n\nOut of every 100 people, about how many do you think are:\n\n\n\nChristian?\nMuslim?\nOver the age of 65?\n\n\nWe also asked a related question about immigration:\n\nWhat percentage of the UK population do you think are immigrants to this country? (i.e. not born in UK)\n\n\nCreate a new R Markdown document for Week 9.\nIn the first chunk add library(tidyverse) and create a new data object by using read_csv() to read “data_wk9.csv”.\nYou can view the data by clicking on it in the environment. Note that in previous weeks we’ve used the view() command in our scripts (which does the same thing), but that can conflict with knitting the .Rmd file.\nTake a look at the summary statistics for all of the columns in our data using summary(your_data_object_name)\n\nTo what extent are people’s estimations of these population parameters related? Let’s look at this by plotting these data as geom_point().\n\nCopy the following code. Edit it to map one of the numeric columns in the data to x and another numeric column to y. You can pick any of the columns you like, but it’s important that you understand what research question you are asking with your choice. For example, you might be asking “Do people who estimate that there are more Christians in the population also think there are more Muslims in the population?”\n\n\ndata_object_name %&gt;% \n  ggplot(aes()) + # map two of the columns to x and y\n  geom_point() # you can change the size or colour of the points if you wish\n\n\nConsider the graph, noting any general pattern/trend in the data. Is there a postive relationship: do people who give high estimations for one variable tend to give high estimations for the other variable? Or is there a negative relationship: do people who give high estimations for one variable tend to give lower estimations for the other variable? Or is there no discernible relationship at all?\nWrite a statement after this code chunk to briefly make a comment about any pattern you see in the data (or absence of a pattern).\nCopy this code into new chunks and explore relationships between the other numeric variables, each time noting the research question you are asking, and discussing with people on your table what kind of relationship you can see in the data. Write some comments in your R Markdown document to describe the patterns you are seeing.\n\n\n\nTask 2 - Using z-scores to remove outliers\n\nYou may have noticed that there are some fairly extreme values in some of these numeric estimations of the population. As we’ve discussed in previous weeks, these outlier values can be problematic when we run our statistical tests, so (like last week) we probably want to control their influence by removing them. As you saw in your online tutorial, we can convert the data to z scores, and then remove z values above and below certain values.\nLet’s create a “z-transform column” called z_imm for the estimates of the percentage of immigrants. Complete the code below by changing the data object names and adding the relevant variable (column) name. Note that you may want to assign the result (&lt;-) to a new data object at this point.\n\n\n# use mutate and scale to create z-scores of immigration estimates\nnew_data_object_name &lt;- \n  data_object_name %&gt;% \n  mutate(z_imm = scale(column_name))\n\n\nView the new data object to check this column has been created correctly. Like in the online tutorial, it would be a good idea to calculate some descriptive statistics for this new column to check it conforms to what we know about z-scores (e.g., mean() = 0, give or take some rounding, and sd() = 1).\n\n\n# check the mean and sd of the new column\nmean(data_object_name$column_name)\nsd(data_object_name$column_name)\n\n\nWe know from our earlier lectures on the z distribution that values of greater than 2 (or less than -2) reflect around 5% of the distribution, and values greater than 3 (or less than -3) represent less than 1% of the distribution:\n\n\n\nLet’s consider an outlier any value that has a z of 2.5 (a conventional cutoff). Plot a histogram of the z_imm column in order to inspect whether there are data that are above 2.5 or below -2.5.\n\n\n# histogram of the z_imm column\n\n# eh, what, no code? Come on...you've got this!!! \n# start with the data, pipe, then ggplot\n# if you get really stuck, look back at last week\n\n\nAdd a filter command to remove the values in the z_imm column are greater than 2.5 or less than -2.5. That means you’ll need two separate statements with an & in the middle\n\n\n# add a filter command\ndata_object_filtered &lt;- \n  data_object_name %&gt;% \n  filter(first_expression_here & second_expression_here) \n\n\nYou should have removed 3 rows of data. Make a note of this in your R markdown document.",
    "crumbs": [
      "Home",
      "PSYC121",
      "9. Unrelated-samples t-test and Power"
    ]
  },
  {
    "objectID": "PSYC121/Week9.html#task-3---unrelated-samples-t-test",
    "href": "PSYC121/Week9.html#task-3---unrelated-samples-t-test",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "Task 3 - Unrelated samples t-test",
    "text": "Task 3 - Unrelated samples t-test\nWe have also included a categorical variable in our data this week, which is one you have seen before in our analysis classes: the home location in the UK of the respondent, home_location_in_UK. For this data object we have included only those responses from those people from the “North” (NW and NE) and those from the “South” (SW and SE). Other respondents from elsewhere have been removed from the data. We can therefore look at whether people’s home location determines their population estimations.\n\nFirst we will look at the mean population estimations, split by home location. To do this, copy and edit the code below and complete the group_by() and summarise() commands to give the mean() estimates of the proportion of immigrants in the population by home location. You don’t need to edit the N = n() line - this provides the number of participants at each level of the home_location_in_UK variable.\n\n\n# summary statistics\ndata_object_name %&gt;% \n  group_by(column_name) %&gt;% \n  summarise(mean_imm_est = complete_this_statement,\n            sample_size = n())\n\n\nWhat do the means suggest? Do people in the North and South give different estimations? Write a statement in your .Rmd file to describe the difference.\nLet’s test if these differences are real. First, it is worth noting that many more respondents originate from the North than from the South (see the N column in the summary). We have unequal sample sizes, and potentially unequal variances. Copy the code below into your .Rmd. The first bit of code runs the var.test() to check if the variances of the two samples are similar (homogeneity of variance). If this test produces a p value less that .05, then the variances in the two samples are unequal. That will have consequences for how we run the t-test() in the next step.\n\n\n# check if variances are unequal (p &lt; .05) - Q3\nvar.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name)\n\n\nNow let’s run the t-test. This week we are comparing data from different samples of participants (those who are from the North and South). We need to tell the t-test that the data are NOT paired (paired = FALSE). The result of the var.test() in the last step will tell you whether the var.equal value should be TRUE or FALSE. Set var.equal = FALSE or var.equal = TRUE depending on whether the variances are equal. When you’re happy with the parameters, run the t-test.\n\n\n# run unrelated samples t-test\nt.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name, \n       paired = FALSE, \n       var.equal = missing_value) # you'll need to set this to TRUE or FALSE depending on what you found in var.test\n\n\nIf you’ve done this correctly, you should have a t-statistic = -1.2801. Examine the p-value and discuss on your table what this means. Write a line in your .Rmd to formally state the result of the t-test (look at last week for the format). Describe what this result means in your own words.\nIn that t-test we looked at the pop_est_immigrants variable, but we can do this test for all of our population estimates. Copy the code to run another var.test() and t.test(), for the pop_est_christian variable. Document the result of the t-test in your .Rmd and describe the finding. What do these tell us about the relationship between home_location and estimates of the population (if anything)? Feel free to come back to this and run the other two tests on the other population estimations.",
    "crumbs": [
      "Home",
      "PSYC121",
      "9. Unrelated-samples t-test and Power"
    ]
  },
  {
    "objectID": "PSYC121/Week9.html#task-4---power-and-effect-size-d-calculations",
    "href": "PSYC121/Week9.html#task-4---power-and-effect-size-d-calculations",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "Task 4 - Power and effect size (d) calculations",
    "text": "Task 4 - Power and effect size (d) calculations\n\nWe saw in last week’s lab tasks that there was a significant effect in our Stroop task data: participants were faster to say the colour names of the compatible list compared to the incompatible list (there were significant differences with the control list too). We will now use these data to calculate an effect size (Cohen’s d) for the t-statistic that we observed in that test.\nImport the new stroop data csv file. We have reduced the data down to just the compatible and incompatible conditions.\nAdd the following code into a chunk and run it (edit the data object name) to calculate the cohens_d() effect size, which is reported as effsize. You can ignore any negative sign, taking note of the absolute value.\n\n\nlibrary(effectsize)\nlibrary(pwr)\n\n# add code here to read in the stroop csv file\n\ncohens_d(time ~ condition, \n         data = your_stroop_data_object,\n         paired = TRUE)\n\n\nWe already know that this large effect size was significant with our large sample of participants. What might we have expected with a much smaller sample size? Copy the code below and use the pwr.t.test() function to add in the effect size that you calculated (Cohen’s d) in step 3. We can set the N to 20. What power would we have achieved with this sample size, to detect this large effect? Discuss with your table, or staff, what this power means.\n\n\npwr.t.test(d = value_from_step_3, n = 20) #Q4\n\n\nLet’s say we wanted our next experiment to have an 80% chance of finding an effect at least as large as the one we found. Copy the code you used in step 4, and edit it to run pwr.t.test() to work out the minimum sample size we would need to achieve power of .8, with the effect size you calculated in step 3.\nLet’s say we are looking to run a new experiment in which we give people a stressful task to complete simultaneously. We will ask them to put their hands in a bucket of ice cold water while doing the Stroop task (this is a real “stressor task” people use!). We are unsure of what consequence this will have for our effect size, but we want to estimate the effect size that could be detected in our experiment. We decide to run 40 participants, and want to achieve a power of .90 (90% chance to find an effect at least this large). Copy the pwr-t-test() code and edit it to find the minimum effect size we could hope to detect under these conditions?",
    "crumbs": [
      "Home",
      "PSYC121",
      "9. Unrelated-samples t-test and Power"
    ]
  },
  {
    "objectID": "PSYC121/Week9.html#a-note-on-saving-your-work",
    "href": "PSYC121/Week9.html#a-note-on-saving-your-work",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "A note on saving your work",
    "text": "A note on saving your work\nScripts: By now you are hopefully getting used to editing and working within the R Markdown script. As you know, to save a script, you simply click the save icon, or press ctrl+S (cmd+s on a mac).\nPlots: To save a graph you have produced, click the “Export” button in the plot window, then “Save as Image”. You can resize the graph and give it an appropriate filename. If you’ve set the working directory correctly, then the new file should appear in the current folder.\nData: The data objects you create (in the Environment) only exist within RStudio, and are temporary (with a script and the csv file, you can always redo the analysis). But what if you want to use the data elsewhere? For example you may want to share the data with your project (PEP?) supervisor. To do this, we need to write the data to a csv file (like those we use to import the data). You can do this with the following command: write_csv(the_data_object, \"the_filename.csv\").\nExporting from RStudio: The above save operations save files to a folder within RStudio Server. At some stage you will need to get these files out of RStudio Server, for example if you need a graph for your report, or you need to share the data or the scripts. Or maybe you want to make the csv file available to other researchers. To get files out of RStudio, simply select the files you want in the Files pane, click “More” and then “Export”. Selecting multiple files will produce a “.zip” file, which will need to be “unzipped” on your computer to access the individual files (instructions for Windows and instructions for Mac)",
    "crumbs": [
      "Home",
      "PSYC121",
      "9. Unrelated-samples t-test and Power"
    ]
  },
  {
    "objectID": "PSYC121/Week9.html#week-9-quiz",
    "href": "PSYC121/Week9.html#week-9-quiz",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "Week 9 Quiz",
    "text": "Week 9 Quiz\nYou can access a set of quiz questions related to this week here.",
    "crumbs": [
      "Home",
      "PSYC121",
      "9. Unrelated-samples t-test and Power"
    ]
  },
  {
    "objectID": "PSYC121/Week1.html",
    "href": "PSYC121/Week1.html",
    "title": "Statistics for Psychologists",
    "section": "",
    "text": "Watch the introduction: Lecture Part 1\n\nWatch Lecture Part 2\n\nWatch Lecture Part 3\n\nWatch Lecture Part 4\n\nDownload the lecture slides here",
    "crumbs": [
      "Home",
      "PSYC121",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC121/Week1.html#task-3.1---check-in-with-the-university-attendance-register",
    "href": "PSYC121/Week1.html#task-3.1---check-in-with-the-university-attendance-register",
    "title": "Statistics for Psychologists",
    "section": "Task 3.1 - check-in with the University attendance register",
    "text": "Task 3.1 - check-in with the University attendance register\nWhen you arrive, make sure you have checked-in to your Analysis session in the Levy lab. All students are required by the University to confirm attendance at taught session\nStaff will remind you of this in your class.",
    "crumbs": [
      "Home",
      "PSYC121",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC121/Week1.html#task-3.2---getting-dicy",
    "href": "PSYC121/Week1.html#task-3.2---getting-dicy",
    "title": "Statistics for Psychologists",
    "section": "Task 3.2 - Getting dicy",
    "text": "Task 3.2 - Getting dicy\n\n\n\n\n\nHere’s a simple task for you to complete as a group around each of the workstations;\nYou will be given a pair of dice\n\nWorking in pairs, one person rolls both dice.\nAdd up the total on each of them and have someone record that total (if you don’t have some spare paper or a pen, use your computer)\nRepeat those steps 20 times.\nThen swap over your roles (the person rolling the dice, the person recording the outcome)\nOnce everyone at the workstation has had a turn at this, each person should attempt to work out (a) the mean and (b) the median of their dice roll total.\nCheck each others working, and discuss any differences or problems you have.\n\nAre all your answers the same? Why / why not? If not, are they very different or very similar?",
    "crumbs": [
      "Home",
      "PSYC121",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC121/Week1.html#task-3.3---using-rstudio",
    "href": "PSYC121/Week1.html#task-3.3---using-rstudio",
    "title": "Statistics for Psychologists",
    "section": "Task 3.3 - Using RStudio",
    "text": "Task 3.3 - Using RStudio\n\nIntroducing R Studio\nR and RStudio is the software that we will be using to explore and learn about analysis in your Psychology degree. It’s a computational engine: a very snazzy calculator that you should see as your friend and ally in the journey to understand and appreciate psychology. It sits alongside what we teach about the concepts and interpretation of statistical analysis.\nR is the core software, RStudio is the interface for interacting with it. Put another way, R is the engine, RStudio is the cockpit.\nLike even a simplest calculator, it just does what you ask (at least when you ask nicely!) but it requires the user to know what they want from it and to understand what it is telling you. A calculator can’t help a kid get the right answer to a multiplication problem if they don’t know the difference between multiplication and division and addition etc. And whilst a calculator is brilliant at doing the number crunching (and as a bonus, R Studio can help with turning the numbers into beautiful graphs and images too), even a calculator requires a thoughtful person to take the answers and make sensible interpretations from them.\nTherefore, we need to learn both about the concepts of statistical analysis on the one hand, and the processing of statistical information -through R- on the other. The lectures will provide the starting point and the direction for statistical concepts, whilst these analysis labs provide the more practical experiences in how to use R, and how to make R your ally. Over the next year, in these labs we will increasingly be using RStudio to focus on the latter, processing side, which will allow you to focus your energies on the conceptual side and its relevance for appreciating psychology.\n\n\nGetting started with RStudio\nFor Lancaster University Psychology Students in 2024, we will be learning about R Studio through a simple but powerful web server architecture. That is, through the power of the internet, you can access and use R Studio by logging into a free account that we have provided and we will maintain for your use.\n\nHere’s a little secret: There are several different ways to access RStudio. For example, you can download a copy of the software onto your computer, or use a Virtual Machine set up to run a copy. There’s nothing to stop you having your local copy, but please note - we can’t support your own version through lab classes. We’re using the web server to make sure everyone has the same, controlled experience.\n\nTo log in to the R server, first make sure that you have the VPN switched on, or you will need to be connected to the university network (Eduroam). To set up the VPN, follow ISS instructions here or connecting to Eduroam here.\nWhen you are connected, navigate to https://psy-rstudio.lancaster.ac.uk, where you will be shown a login screen that looks like the below. Click the option that says “Sign in with SAML”.\n \nThis will take you through to the University login screen, where you should enter your username (e.g. ivorym) and then your university password. This will then redirect you to the R server where you can start using RStudio!\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you have already logged in through the university login already, perhaps to get to the portal, then you may not see the username/password screen. When you click login, you will be redirected straight to RStudio. This is because the server shares the login information securely across the university.\n\n\n\n\nWhat does RStudio look like?\nWhen RStudio starts, it will look something like this: \nRStudio has three panels or windows: there are tabs for Console (taking up the left hand side), Environment (and History top right) , Current file (bottom right). You will also see a 4th window for a script or set of commands you develop, also (on the left hand side).\n\n\nLet’s get started!\nThe first thing we want to do in RStudio is to create a folder for this week so that we can put the relevant material there and keep it tidy.\nFrom the lower-right panel of RStudio, click the files tab.\nSelect the “new folder” option and create a new folder (eg “week 1”)\nClick on that folder to open it\nNext, we’ve prepared some instructions for RStudio to use - this is called a “script”. So we need to get this script into the server for you to explore and play with\n\nDownload the “zip” file by clicking this link\nFind the location of the file on your computer and check it is saved as a “.zip” file\nReturn to RStudio\nClick “Upload”\nClick choose file and find the file on your computer.\nSelect the file and click “Open”. Click “OK”\n\nYou should now see the files extracted in the directory.\nYou should now have the script available in RStudio.\nUse “Save…As” to create a new version of the script. By doing this, you’ll be able to have a “before” and “after” version of the script and can go back over the changes\nIn the script, select or highlight the first line of text, which is this one:\n\nRun your first ever R instruction!\n\n5 + 5\n\nand “run” this line. That tells RStudio to carry out the instruction.\nYou should see that in the console tab, RStudio calculates the answer to this incredibly hard maths challenge! (amazing huh? OK, maybe not *that* amazing…).\n\n\nModify your first ever R instruction!\nUse your imagination – add a new line to the script and ask a different simple arithmetic question of your own choosing! What happens?\n\n\nCalculate descriptive stats in R for the first time!\nIn this week’s analysis lecture, we looked at measures of central tendency and how to calculate them. So let’s get R to do these calculations also!\nFirst, we tell R about the data used in the lecture. We’ve already created the instruction that will do exactly this and it is in the script, so run this line from the script\n\nweek_1_lecture_data &lt;- c(7,8,8,7,3,1,6,9,3,8)\n\nThis creates an “object” called week_1_lecture_data. We can then perform calculations on this object. For example, we can find the mean by running the following command (use the script to do this)\n\nmean(week_1_lecture_data)\n\nCheck the answer is the same we found in the lecture (it should be 6!).\nNext, let’s ask for the median by running this line from the script:\n\nmedian(week_1_lecture_data)\n\nThis also should be the answer from the lecture (7)\nR doesn’t have a single corresponding command for the mode, but we can use the block of code in the script for this that starts and ends with the “getmode” text (there are 6 lines of text)\nThis is just a bit of clever jiggery-pokery that gets the mode. What does R say the mode is?\n\n\nYour challenge\nHow can you get RStudio to verify / check the dice calculations that you attempted earlier? Think about how you might solve this problem, on the basis of what we have covered so far.\nWe will discuss this in class and attempt to get RStudio to check your answers. In doing so, annotate the script (add notes for you - not RStudio) using the “#” command",
    "crumbs": [
      "Home",
      "PSYC121",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC121/Week1.html#before-you-finish",
    "href": "PSYC121/Week1.html#before-you-finish",
    "title": "Statistics for Psychologists",
    "section": "Before you finish",
    "text": "Before you finish\n\nMake sure you save a copy of the script that you have been working on by the end of the session. This provides you with the record - the digital trace - on what you have done. And it means you can come back and repeat any of the work you have performed.\nEnd your session on the RStudio server, this logs you out of the server and stops any ongoing activities and tasks you have set up, maybe in the background.\n\nThere is a red “power” button near the top right of the R studio window (do ask for help if you can’t find it). It’s a good habit to get into to turn the session off\n\n\nExtra content for outside the lab class\n\nIn the Howell text book on statistics, there’s some R code on descriptive statistics. It is included in the script for you to look at and play with.\nin your own time and think about the following:\n\nIn R, “&lt;-” is the assignment operator as in the command we used:\n\nPSYC121_week_1_data &lt;- c(7,8,8,7,3,1,6,9,3,8)\n\nWe create the variable label on the left (Analysis_week1_data) and we give it those numbers on the right. The nameAnalysis_week1_data is largely arbitrary: try use a variable of your own naming (your own name?) instead - and then use that alternative name for the other commands.\n\nThroughout this year, we’ll use the convention of the “underscore” to separate words in labels (it_makes_them_easier_to_read than ifyoudidn’thaveanyspaces)",
    "crumbs": [
      "Home",
      "PSYC121",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC121/Week1.html#task-3.4-review-the-learnr-sample-practice-questions",
    "href": "PSYC121/Week1.html#task-3.4-review-the-learnr-sample-practice-questions",
    "title": "Statistics for Psychologists",
    "section": "Task 3.4 – Review the learnr sample / practice questions",
    "text": "Task 3.4 – Review the learnr sample / practice questions\nAfter every block of teaching in part-1 analysis (specifically, we mean in week 5, week 10, week 15 and week 20) there will be a class test. This will assess your knowledge and your understanding of the material that has been covered.\nThe class test will comprise a set of Multiple Choice Questions (and the set of questions will be different for each student, as the test will involve random selection from a larger pool) under timed conditions.\nIn order to help you get (a) a broad or basic feel for the sort of questions you might get in the class test (b) self-review your progress through the term, we will provide MCQs each week for you to attempt.\nSo these are for your benefit… you can take the questions when you choose to, and the learnr quiz will provide feedback on the answers your provide. Just bear in mind:\n\nWe place a set of questions at the end of the learnr pages so that you can attempt these at the end of each week, after you’ve completed lab activities, follow-up work, weekly Q&As etc. But it’s up to you when you answer the questions\nThese are meant as indicative questions. There’s no point in learning/ memorising these questions (they won’t be on the quiz!) and our advice is to reflect on how the teaching and content links to the sorts of questions that get posed.",
    "crumbs": [
      "Home",
      "PSYC121",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC121/Week1.html#task-3.5-data-collection-exercise",
    "href": "PSYC121/Week1.html#task-3.5-data-collection-exercise",
    "title": "Statistics for Psychologists",
    "section": "Task 3.5 – Data collection exercise",
    "text": "Task 3.5 – Data collection exercise\nIn order to learn about psychology and data analysis techniques, we need data! Rather than rely too much on artificial data (certainly it is sometimes useful to say “Here are a bunch of numbers and this is what we can do with them” – think about the R Studio example for this week’s lab) for the most part, we prefer to draw on datasets that are a bit more engaging and meaningful that you have a stake in yourself! By using a common data set, that we can return to over the year, we can also build up familiarity and confidence in the data and remove a potential obstacle to thinking about the more important analysis part.\nSo a key task will be for everyone to have a go at taking our online survey, and contribute to a dataset that can be used throughout the year.\nThe survey runs by following this link",
    "crumbs": [
      "Home",
      "PSYC121",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC121/Week1.html#post---lab-recap-the-slides-we-used",
    "href": "PSYC121/Week1.html#post---lab-recap-the-slides-we-used",
    "title": "Statistics for Psychologists",
    "section": "Post - lab recap: The slides we used",
    "text": "Post - lab recap: The slides we used\nWant to see again the introduction slides that we used in the Levy lab? They are available here",
    "crumbs": [
      "Home",
      "PSYC121",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC121/Week3.html",
    "href": "PSYC121/Week3.html",
    "title": "3. DVs and IVs in RStudio",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Lecture Part 3\n\nWatch Lecture Part 4\n\nDownload the lecture slides here",
    "crumbs": [
      "Home",
      "PSYC121",
      "3. DVs and IVs in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/Week3.html#task-1---more-with-the-penelope22-data",
    "href": "PSYC121/Week3.html#task-1---more-with-the-penelope22-data",
    "title": "3. DVs and IVs in RStudio",
    "section": "3.1 Task 1 - More with the penelope22 data",
    "text": "3.1 Task 1 - More with the penelope22 data\nStep 1. Create a project and a folder, and set the working directory. This is covered in the learnr tutorial so head over there if you need reminding.\nStep 2. Bring the week3_2024.zip file into R Studio server. Like last week, upload the zip file, and launch the R script. You can get the file here\nStep 3. This week, we again want to explore commands from the tidyverse library (toolkit) which can help us do more powerful things more elegantly. So let’s get R to work again with the tidyverse library by running the code line\nlibrary(tidyverse)\nStep 4. Explore help() commands. R can give you more information about how it works.\nStep 5. Read or load the penelope data into R. That is what line 18 of the code is designed to do\n\ndata_object_name &lt;- read_csv(\"fill in\") # use your own dataobject_name and specify the file you want to work with\n\nbut note that you will need to edit this line -and ensure you are in the correct working directory- for this to be successful. Then have a look at it using the View() command in the script\nThis time, let’s ask for the estimate data arranged by identity:\n\naggregate(x = *MISSING*$estimate, by = list(*MISSING*$identity), FUN = mean)\n\nFirst, let’s try this (you will need to use your dataframe/variable name in place of MISSING). What do you get? Does this match what we did last week when we calculated the mean for the female and for the other (i.e., non-female) group?\nSecond, let’s look at what is happening here:\naggregate This is a command to call for descriptive statistics\nx= This defines what column we are analyzing\nby=list Now we tell R how to group the estimate data, and which column does that\nFUN=mean Specifies which descriptive function is being asked for Can you explore whether you can call on alternate measures?)\n\n3.1.2 group_by()\nThere’s another way that also allows us to group scores by a (nominal) variable. This is explored in the learnr tutorial, which should help you create the command the get weight estimates broken down by gender identity. You need to define the data frame for the estimates data, and the gender IV and the estimates DV\n\n*MISSING* %&gt;% group_by(*MISSING*) %&gt;% summarise(mean_estimate = mean(*MISSING*))\n\nFirst, try this command and see what you get. If you run this command as entered, it won’t work. So now use your experience at skills from the above and the learnr tutorial to work out what is required.\nNote\n%&gt;% This is called a “pipe operator”, basically take the output from the left and feed it into the requests on the right. Summarise Provide summary statistics information for the specified variable as specified (whether mean, median etc)\n\n\n3.1.3 The assignment operator\nAs well as learning about the pipe operator, we want to remind you /draw attention explicitly to another important element of the R command line syntax: the assignment operator. Uing a command such as\ncows &lt;- read_csv(\"penelope22.csv\")\nlooks for the csv datafile called ‘penelope22’, and assign it to an object or variable called ‘cows’\nWe could create any object name we wanted (within limits of names already known to RStudio). It isn’t just for reading in data files, we can perform a whole range of functions and assign them to an object.\n\nTask 2 - New salary data\nUsing aggregate and summarise may not seem like much progress, because they are just replicating what we had already done with mean() is week 2. However (a) this emphasizes that there are often several ways to get at the same thing in R (b) now we know about grouping, about working with 2-dimensional data, we can start to do more efficient and informative things.\nNow, let’s turn to the guesses made about median salary in the UK. We can get the data, from you as a group of PSYC121 students, from the file wages2024.csv (you will need to adapt the code we used above for the weight estimation file so that it will load in the wages data, and in what follows the assumption is your new variable name is called wages)\nLet’s take a peek at the dataset with\nglimpse(wages)\nGlimpse pretty much does what you might think from the meaning of the word – it just gives us a data sample (handy because this is a much bigger dataset) and shows that we have 3 columns; uk_region (where someone lives, note ‘other’ probably equals Northern Ireland, Europe, China, etc), family_position (age relationship with siblings), and salary (estimate).\nBy the way, the govt statistics say the actual median income in 2023 was approx. £34,963 see this link\n\nWriting into your script, use the working “aggregate” commands from task 1 with the penelope weight data to find out the salary guesses as a function of where someone lives? That is, can you adapt that code for this problem? First, make sure you read in the data file into an R object.\nCan you use the aggregate command to find out salary guess as a function of family relationships? (if you are the youngest child maybe you have older siblings earning money that changes your evaluation?)\nCan you get a breakdown of guess as a function of BOTH UK region AND family relationship together?\nCan you use the group by() command to display salary guesses as a function of where someone lives? Check this gives you the same answer.",
    "crumbs": [
      "Home",
      "PSYC121",
      "3. DVs and IVs in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/Week3.html#task-3.2---new-phone-use-data",
    "href": "PSYC121/Week3.html#task-3.2---new-phone-use-data",
    "title": "3. DVs and IVs in RStudio",
    "section": "Task 3.2 - New phone use data",
    "text": "Task 3.2 - New phone use data\n\nDataset 3: Use the dataset of phone screen time usage, screentime2024.csv to further explore and consolidate the group_by() command (ie we’ll drop the aggregate command for this task to focus on group_by()). Use copy and paste to adapt the existing script lines from the above two tasks so that this time you read in and calculate screen time usage as a function of the type of phone. In other words, add line (and comments) to the scripts for this new task.\nUse RStudio to figure out the overall mean screen time usage estimate and the standard deviation. Calculate by hand what usage estimate would have a z score of z=-1.5?",
    "crumbs": [
      "Home",
      "PSYC121",
      "3. DVs and IVs in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/Week3.html#task-3.3---final-challenge-visualisation",
    "href": "PSYC121/Week3.html#task-3.3---final-challenge-visualisation",
    "title": "3. DVs and IVs in RStudio",
    "section": "Task 3.3 - Final challenge: visualisation",
    "text": "Task 3.3 - Final challenge: visualisation\nCan you find a way to visualise the screentime usage data that you have been working with above? The script provides two ways to consider doing this - boxplots (which we have looked at in script commands already) and ggplot, which we have spent less time with but is an extremely powerful engine for creating plots. We’ve provided the start of the code in each case, leaving you to work out the specifics. Remember to annotate your creations!",
    "crumbs": [
      "Home",
      "PSYC121",
      "3. DVs and IVs in RStudio"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html",
    "href": "PSYC121/Week6.html",
    "title": "6. Sampling, probability and binomial tests",
    "section": "",
    "text": "Watch Part 1\n\n\nWatch Part 2\n\n\nWatch Part 3\n\n\nWatch Part 4\n\n\nYou can download the lecture slides here",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#week-6-lecture",
    "href": "PSYC121/Week6.html#week-6-lecture",
    "title": "6. Sampling, probability and binomial tests",
    "section": "",
    "text": "Watch Part 1\n\n\nWatch Part 2\n\n\nWatch Part 3\n\n\nWatch Part 4\n\n\nYou can download the lecture slides here",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#reading",
    "href": "PSYC121/Week6.html#reading",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Reading",
    "text": "Reading\nChapter 8 of Howell",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#pre-lab-work",
    "href": "PSYC121/Week6.html#pre-lab-work",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Pre-lab work",
    "text": "Pre-lab work\n\nEnsure you have watched the above lecture content for Week 6.\nPLEASE NOTE! The learnr server is currently down - we are trying to fix this asap. Complete the short learnr tutorial which will introduce you to running the binomial tests in R. You can find it here.",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#working-with-r-markdown-documents-.rmd",
    "href": "PSYC121/Week6.html#working-with-r-markdown-documents-.rmd",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Working with “R Markdown” documents (.Rmd)",
    "text": "Working with “R Markdown” documents (.Rmd)\nToday we will take a look at a different type of document file called “R Markdown” (the filetype is .Rmd). It’s like a .R script, only a bit more fancy! Today we’ll introduce a couple of basic features of these files and use this document for our tasks below.\n\nMake sure you have a Week 6 folder\nOnce in that folder in the files pane, click “more” and “set as working directory”\nThen click the new file button and select “R Markdown”\n\n\n\nYou’ll be asked to name this file. Leave the other options as they are and click OK.\nWhen the new R Markdown file appears, try “knitting” it (the icon at the top with the ball of wool). You should get a nice output of the default R Markdown document.",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#adding-code-chunks",
    "href": "PSYC121/Week6.html#adding-code-chunks",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Adding Code chunks",
    "text": "Adding Code chunks\nR Markdown documents allow you to freely type in text in the main body of the file. You are no longer restricted to putting comments after the “#” sign. Instead, when you want to put in R code you will need to create a “code chunk” within the document. These are places where you put your R code you want to run.\nThe easiest way to add a code chunk is to use the dedicated button in the editor pane (the shortcut is ctrl+alt+i):\n\nSelect “R” as that is the type of code you want to write. With your template document, try running the very first code chunk (click the green arrow on the right). This will run the code and display the output (in the document and in the console).\n\n\n\n\n\n\n.Rmd and .R differences\n\n\n\nIn a way, R Markdown files function in the opposite way to .R files:\n\n.Rmd: you write normal text in the main part (like you’d do in a word processor), but you create a special “code chunk” for your code.\n.R: you write code in the main body, and use the “#” to write normal text as a comment",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#source-mode-vs.-visual-mode",
    "href": "PSYC121/Week6.html#source-mode-vs.-visual-mode",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Source mode vs. Visual mode",
    "text": "Source mode vs. Visual mode\nOne of the nice things about working with R Markdown documents is that you can switch from the “coding” view (called “Source”) to something that is much more like a word processor (called “Visual”). You’ll see these two options in the top left corner of the document. Try flicking between them. Visual mode allows you to edit the document like a word-processor, making it easy to make formatting changes, add titles, insert images and tables, etc.",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#creating-an-r-markdown-for-your-lab-work",
    "href": "PSYC121/Week6.html#creating-an-r-markdown-for-your-lab-work",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Creating an R Markdown for your lab work",
    "text": "Creating an R Markdown for your lab work\n\nDelete all of the script except the first title (## R Markdown)\nChange this title to something more relevant: (e.g., ## Task 1 - Card Sampling task)\nKnit your document to check it is still working!",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#card-sampling-task",
    "href": "PSYC121/Week6.html#card-sampling-task",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Card sampling task",
    "text": "Card sampling task\n\nIn the first task this week we will look at the sampling of events and we will apply the basic statistical test of the binomial test: binom.test()\nEach table has a set of cards. These will be 13 red cards and 13 black cards - please check your set to ensure you have the right number of each colour (it doesn’t matter what suit the cards are).\nWe are going to play a game in which one person chooses a set of these cards and biases the deck towards either red or black. The other members of the table have to try and work out which way the set is biased. To do this, they will draw samples from the deck.\n\n\n\n\n\n\nThe Experiment\n\n\n\nThink of this as an experiment: there is something real out there in the world in our “population” (the cards). As an experimenter we are trying to estimate what is true about the world, and in order to do this we need to take samples. When you can only see the backs of the cards, that data is unobserved. But as we draw samples, we start to understand how the “world” is - whether it is biased towards red or black.\nSo each time you draw a card, you are observing one data point from the population, and based on the data you collect (your samples) you are going to draw an inference about what is true about the population.\n\n\n\nSet up and instructions:\n\nOne person on each table should act as the “world” (the person who biases the cards). Congratulations, you are God! This person will determine what is true about the state of things in the world. This means they control what is contained in the deck of cards.\nFor each experiment, this person secretly looks at the cards, and removes some cards to use in the experiment. For example, from the set of 26 cards, they might choose to remove 4 black cards. The deck is now biased towards red (13 red; 9 black).\nIt’s important that no one sees what the cards are (the ones you’ve kept, or the ones removed). Shuffle the cards so they are ready to be sampled.\nThe remaining people (1 or more) will act as the experimenters. Your job is to draw samples and work out whether you think the deck is biased or not towards either red or black.\nNow copy the following text and code to your R Markdown document to record your work:\n\n### Experiment 1\n\nNumber of samples:\nTotal red cards found:\nTotal black cards found:\nConclusion: \nThe true bias was: \n\n\n```{r}\n\nbinom.test(x, n) # x is the number or red or black; n is the sample size\n\n```\n\n\nRunning each experiment\nDo these steps for each experiment:\n\nThe “World” removes some cards from the full deck (the number and colour of the cards removed is up to them). They shuffle the chosen cards ready to start the “experiment”.\nThe “Experimenters” pre-register their sample size. That is, they state how many cards they are going to draw.\nDraw samples one at a time (each experimenter can take one card, to speed things up).\n\n\n\n\n\n\n\nImportant!\n\n\n\nMake sure you replace all the cards each time you draw samples. The world/dealer should also give the pack a quick shuffle.\n\n\n\nDo step 3 until you have collect the sample size you chose\nOnce you have all the samples, the experimenters should draw a conclusion based initially on their own “gut feeling” about the data. Do you think the deck was biased towards red, black, or was it unbiased?\nChange the binom.test() code to provide a statistical result. Note the “p value”. Was this result unusual? How likely were the data given the null hypothesis?\nThe “world” can then reveal the hidden cards. Was the deck actually biased or not? How does this sit with a) your initial conclusions, and b) the result of the binomial test?\nComplete your record log in the .Rmd file. Feel free to Write a short statement about what you found in this experiment.\n\nRepeat all of the above steps (1-8) for a new experiment, making sure that you try different parameters for the experiment. So vary a) how many cards are removed from the deck, b) the combination of cards removed from the deck, and c) the pre-registered sample size. Feel free to swap the roles around.\nOnce you’ve conducted a few experiments, discuss on your table the results you found. It might be useful to think about the following things:\n\nwere there times when your intuitions were different to the statistical result? For example, you were sure there was a bias, but in fact the statistics told you this was not that unusual (p was &gt; .05)?\nwere there times when the deck was actually biased, but you failed to prove this with your experiment (you failed to see p &lt; .05)? Do you remember what this type of error is called?\nwere there times when the deck was not biased, but the test result suggested it was (p &lt; .05)? Do you remember what type of error this is called?",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#risky-and-safe-decisions",
    "href": "PSYC121/Week6.html#risky-and-safe-decisions",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Risky and safe decisions",
    "text": "Risky and safe decisions\nFor the second exercise today we will look at data from the survey on “risky and safe decisions”. You may remember that you were asked the following question:\n\n\n\n\n\n\nGain\n\n\n\nImagine you are on a game-show and you win £300. The presenter gives you have a choice: receive an additional £100 for sure, or take a gamble offering a 50% chance to gain £200 and a 50% chance to gain nothing. Which would you choose?\n\nreceive £100 for sure\ntake the gamble of a 50% chance to gain £200 and a 50% chance to gain nothing\n\n\n\nWe then asked you a similar question:\n\n\n\n\n\n\nLoss\n\n\n\nImagine you are on a different game-show and you win £500. Here you are given a choice between either losing £100 from your winnings for sure, or taking a gamble offering a 50% chance to lose nothing and a 50% chance to lose £200. Which would you choose?\n\nlose £100 for sure\ntake the gamble of a 50% chance to lose nothing and a 50% chance to lose £200\n\n\n\nWe’ve called these “gain” and “loss”, because in the first scenario you’re being asked about a chance to gain money, while in the second, it’s about a chance to lose money. Note that the “expected utility” of the choices is equivalent:\n\n\n\n\n\n\n“The expected utility of an act is a weighted average of the utilities of each of its possible outcomes, where the utility of an outcome measures the extent to which that outcome is preferred, or preferable, to the alternatives. The utility of each outcome is weighted according to the probability that the act will lead to that outcome.” see here\n\n\n\nThat’s to say, on average, you’ll end up with +£100 for the two cases in the gain scenario, or -£100 for the two cases in the loss scenario.\nBut what do people actually pick? Well people tend to be risk-averse, choosing the safe option overall. But interestingly, the safe option is picked far less when the scenario is presented as a loss. People seem to want to take the risk of potentially not losing anything (but maybe losing more).\nLet’s look to see if you showed the same pattern!\n\nCreate a new section of your markdown, giving it a suitable header\nCreate a new code chunk by clicking the “Code” menu, then “Insert Chunk”\nYou can download the data from this link, then upload it into the server.\nAdd a read_csv() command to read the data into the environment.\n\n\n\n\n\n\n\nReading CSVs\n\n\n\n\nRemember to set the working directory so R knows where the file is\nRemember to assign (&lt;-) to a new data object and give this a sensible name\n\n\n\n\nView the data, and see that the columns represent the gain and loss scenarios. The values represent the choices people made.\nUse the count() function to count the number of “safe” and “risky” choices that were made for our sample\n\n\ncount(my_data_object_name, gain)\n\n\nWe can now tell whether, in our sample, people tended to play it safe or take the risky choice. Did the sample have a meaningful bias towards one type of decision? If they didn’t we’d expect it to be a 50/50 split between safe and risky (people might make their choice at random). Use the binom.test() to look at whether the result would be expected by chance, noting the p value that is found.\nWrite a sentence or two after your code to explain what this result means.\nRepeat for the data from the loss column. Was the p value &lt; .05 here? Again, write a sentence or two to explain what this means.",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week6.html#week-6-quiz",
    "href": "PSYC121/Week6.html#week-6-quiz",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Week 6 Quiz",
    "text": "Week 6 Quiz\nYou can access a set of quiz questions related to this week here.",
    "crumbs": [
      "Home",
      "PSYC121",
      "6. Sampling, probability and binomial tests"
    ]
  },
  {
    "objectID": "PSYC121/Week5.html",
    "href": "PSYC121/Week5.html",
    "title": "5. Class test",
    "section": "",
    "text": "Formulae for weeks 1-4\nHere you can download a list of the formulae used in the first half of this module.\nThere are no other materials for this week!\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "PSYC121",
      "5. Class test"
    ]
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html",
    "title": "PSYC121: Week 9 Lab",
    "section": "",
    "text": "For this week’s online tutorial we have data on how much students use social media platforms and people’s mean reading times from the stroop task. We will use these data to look at how we create new variables (columns) using mutate(). We will also expand what we have learnt about filtering data based on conditions, using the filter() function. Let’s take a look at the data we have using the summary(), to get useful statistics. You can also use head() to look at the first few rows of data\n\n\nsummary(data)\nhead(data)"
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html#exploring-the-data",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html#exploring-the-data",
    "title": "PSYC121: Week 9 Lab",
    "section": "",
    "text": "For this week’s online tutorial we have data on how much students use social media platforms and people’s mean reading times from the stroop task. We will use these data to look at how we create new variables (columns) using mutate(). We will also expand what we have learnt about filtering data based on conditions, using the filter() function. Let’s take a look at the data we have using the summary(), to get useful statistics. You can also use head() to look at the first few rows of data\n\n\nsummary(data)\nhead(data)"
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html#mutating-new-variables",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html#mutating-new-variables",
    "title": "PSYC121: Week 9 Lab",
    "section": "“Mutating” new variables",
    "text": "“Mutating” new variables\nIn this data set, all of the variables are numerical. Sometimes we may want to recode a variable to turn it from a continuous numerical variable, to a categorical/nominal variable. For example, maybe we want to compare students who are high users of facebook, to those who are low users of facebook. We could do that in the following way using the mutate() function:\n\n\ndata %&gt;% \n  mutate(facebook_use = facebook_days &gt;= 4)\n\n\n\n\n\nWhen you run this code you’ll see that mutate() has created a new column on the end, which tells us whether the person uses facebook for at least 4 days a week. Note that the new column is called “facebook_use” - this works in exactly the same way as the summarise() commands you have been practising, where you tell it the new variable name you want to create. The values “TRUE” and “FALSE” are not especially informative here - we probably want to be a bit clearer in the names we give to these levels of the new variable. To do that we can modify this code a little to use an if_else(), which checks if the “conditional statement” (facebook_days &gt;= 4) is TRUE or FALSE, and specifies the values to use in each case:\n\n\ndata %&gt;% \n  mutate(facebook_use = if_else(facebook_days &gt;= 4,true = \"high\",false = \"low\"))\n\n\n\n\n\n\nJust like with summarise(), we can have multiple new columns created within the one mutate() command. Each of these needs to be separated by a comma, and it’s good practice to put each one on a new line. Try copying and pasting the if_else command, and then modifying it to make two new variables to code for “high” and “low” instagram and twitter use:\n\n\ndata &lt;- \n  data %&gt;% \n  mutate(facebook_use = if_else(facebook_days &gt;= 4,true = \"high\",false = \"low\"),\n         instagram_use = ,\n         twitter_use = )\n\ndata\n# because we are assigning (&lt;-) the changes to update \"data\", \n# we write it again here to display the results\n\n\n\n\n\ndata &lt;- \n  data %&gt;% \n  mutate(facebook_use = if_else(facebook_days &gt;= 4,true = \"high\",false = \"low\"),\n         instagram_use = if_else(instagram_days &gt;= 4,true = \"high\",false = \"low\"),\n         twitter_use = if_else(twitter_days &gt;= 4,true = \"high\",false = \"low\"))\n\ndata\n# because we are assigning (&lt;-) the changes to update \"data\", \n# we write it again here to display the results\n\n\n\n\n\nLet’s now look at our avg_stroop variable, and first plot the data in a box and whisker plot:\n\n\ndata %&gt;% \n  ggplot() +\n  geom_boxplot(aes(y = avg_stroop))\n\n\n\n\n\n\nWe can see here that we have a number of points that lie outside the “whiskers” on the plot. One thing we can do to identify potential outliers is to create a new variable that transforms the data to a z distribution. This is easy to do in R using the scale() function:\n\n\ndata &lt;- \n  data %&gt;% \n  mutate(z_stroop = scale(avg_stroop))\n\ndata\n# because we are assigning (&lt;-) the changes to update \"data\", \n# we write it again here to display the results\n\n\n\n\n\n\nYou may remember that a distribution of z scores has a mean of 0 and a standard deviation of 1. Let’s check that here:\n\n\nmean()\nsd()\n\n\n\n\n\nmean(data_set$variable) # example\nsd(data_set$variable) # example\n\n\n\n\nmean(data$z_stroop)\nsd(data$z_stroop)\n\n\nYou’ll notice that the value for the mean is not quite 0 (but it is very very small!). This is probably due to a rounding of values in the scale() function. To get a value of 0 we could encolse the statement in the round() function, e.g. `round(mean(),digits = 2).\n\n\n\nA good way to get a sense of the range of values in our z-scores is to use arrange() to sort them in order. We can then use head() and tail() to see the values at each end of the distribution (the first ‘n’ rows, and the last ‘n’ rows)\n\n\ndata &lt;- \n  data %&gt;% \n  arrange(desc(z_stroop)) # arrange in descending order\n\nhead(data, n = 10)\ntail(data, n = 10)\n\n\n\nYou can see that we’ve got some quite extreme values here. First, we’ve got some very slow participants, showing average reading times of over 10 seconds. Secondly, we’ve got some extremely fast participants. The fastest participant of all is particularly unusual - perhaps they put in incorrect values into the survey?"
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html#filtering-data",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html#filtering-data",
    "title": "PSYC121: Week 9 Lab",
    "section": "Filtering data",
    "text": "Filtering data\nAs you can see, we quite often want to filter our data to select or remove some of the rows we are working with. To do this, we can use the filter() command.\nTo use filter(), we simply specify the data first, and then we need to use an expression to state how we want the data to be filtered. For example:\n\n\ndata %&gt;% \n  filter(z_stroop &lt;= 2) \n# find all those people who have z_stroop values lower than positive 2\n\n\n\n\nCommon expressions\nThe following table gives some examples of very common expressions used in filtering data:\n\n\n\n\n\nOperator\nMeaning\nExample\n\n\n\n\n==\nis the same as\nfilter(dataQ, age==27)\n\n\n&lt;\nis less than\nfilter(dataQ, age&lt;25)\n\n\n&gt;\nis greater than\nfilter(dataQ, age&gt;30)\n\n\n!=\nis not equal to\nfilter(dataQ, gender != 'female')\n\n\n&\nand\nfilter(dataQ, age&lt;30 & gender == 'female')\n\n\n|\nor\nfilter(dataQ, gender == 'male' | gender == 'non-binary')\n\n\n\n\n\n\n\nIt’s particularly important to note the difference between “==” and “=” in R. “=” is used as an assignment operator - you’ve used it several times already inside functions (e.g., na.rm = TRUE, mu = 29600). You can think of “=” as meaning “set this to”. In contrast the double equals operator, “==”, asks a question: “is this thing the same as this other thing?” In the above example, z_stroop &lt;= 2, it looks for all rows in the data where z_stroop is the same as, or less than, the value of 2. In programming terms, the expression returns a boolean value, which reports whether the statement is TRUE or FALSE (and when used in the filter, it finds all rows where it is TRUE). You can see this in the results of the following “conditional expressions”:\n\n\n2 == 3\n\"blah\" == \"blah\"\n\"blah\" == \"BLAH\"\n\"John\" == \"rock star\"\nmean(c(3,4,5,6)) == 4.5\nTRUE == FALSE # this is getting meta...\n\n\n\n\n\nPractice filtering\nPractice writing your own filter commands in the box below. Try to filter the data to match the following queries:\n\nData for those people who are “high” facebook users (hint: facebook_use == )\nData for those people who use instagram for 7 days, and have a z_stroop score of less than -1 (hint: use &)\nData for those people who are “high” users of at least one social media platform (hint: this needs two “or”: | )\n\n[Each hint here gives the solution to each query]\n\n\ndata %&gt;% \n  filter()\n\n\n\n\n\n# Query 1 solution\ndata %&gt;% \n  filter(facebook_use == \"high\")\n\n\n\n\n# Query 2 solution\ndata %&gt;% \n  filter(instagram_days == 7 & z_stroop &lt; -1)\n\n\n\n\n# Query 3 solution\ndata %&gt;% \n  filter(facebook_use == \"high\" | instagram_use == \"high\" | twitter_use == \"high\")"
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html#section-6",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html#section-6",
    "title": "PSYC121: Week 9 Lab",
    "section": "",
    "text": "End of tutorial\nThis is now the end of the online tutorial on filter() and mutate(). Please return to the tasks in the lab worksheet."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics for Psychologists",
    "section": "",
    "text": "Welcome to Year 1 statistics!\n\nThis year you will begin your statistics and data coding with R journey with us. You will complete two statistics modules:\n\nPSYC121: Statistics for Psychologists 1, with John Towse and Tom Beesley\nPSYC122: Statistics for Psychologists 2, with Margriet Groen and Rob Davies\n\nClick on the button below to access your module: Term 1: PSYC121, Term 2: PSYC122.\n\n\n  \n    \n\n    \n      PSYC121\n    \n    \n      PSYC122"
  },
  {
    "objectID": "PSYC122/Week19.html",
    "href": "PSYC122/Week19.html",
    "title": "8. Week 19 – Linear models – critical perspectives",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.",
    "crumbs": [
      "Home",
      "PSYC122",
      "8. Week 19 -- Linear models -- critical perspectives"
    ]
  },
  {
    "objectID": "PSYC122/Week19.html#sec-wk19-introduction",
    "href": "PSYC122/Week19.html#sec-wk19-introduction",
    "title": "8. Week 19 – Linear models – critical perspectives",
    "section": "Week 19: Introduction",
    "text": "Week 19: Introduction\nWelcome to your overview of our work together in PSYC122 Week 19.\n\n\n\n\n\n\nTip\n\n\n\nPutting it all together\n\nWe have completed four classes in weeks 16-19.\nThese classes are designed to enable you to revise and put into practice some of the key ideas and skills you have been developing in the first year research methods modules PSYC121, PSYC123 and PSYC124.\nWe have been doing this in the context of a live research project with potential real world impacts: the Clearly Understood project.\n\n\n\nIn the week 19 class, we will aim to answer two research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written information?\n\nWe will be revisiting some of the ideas and techniques you have seen introduced in previous classes. And we will be extending your development with some new ideas, to strengthen your skills.\n\n\n\n\n\n\nTip\n\n\n\nI have said that our aim in these classes is to contribute new findings from the data we collect together.\n\nThat time is now.\n\n\n\nThe PSYC122 health comprehension survey is now closed, and we will focus our practical work in week 19 on analyzing the data we have collected.\n\nOur learning goals\nIn Week 19, we aim to further develop skills in analyzing and in visualizing psychological data.\nWe will use linear models to estimate the association between predictors and outcomes in order to answer our research questions.\n\n\n\n\n\n\nTip\n\n\n\nWhat is new here is that we will compare the results from different studies to critically examine questions relating to reproducibility:\n\nDo we see similar results when similar methods are used to collect data to address the same questions?\n\n\n\nWe shall be focusing our analysis work on response data contributed by PSYC122 students.\n\nBut we will critically examine whether the results of our analyses of PSYC122 data are or are not similar to the results of the analyses of data collected in other studies.\n\nWhen we do linear models, as you have seen, we usually need to report:\n\ninformation about the model we specify, identifying all predictors;\nour evaluation of whether the effects of one or more predictors are significant;\nmodel fit statistics (F, R-squared) as well as coefficient estimates;\nand descriptions of the impact of predictors.\n\nUsually, in describing the impacts of predictors, we are required to communicate:\n\nthe direction of the effect – do values of the outcome variable increase or decrease given increasing values of the predictor?\nthe size of the effect – how much do values of the outcome variable increase or decrease given increasing values of the predictor?\n\n\n\n\n\n\n\nTip\n\n\n\nIn assessing reproducibility, therefore, we may focus here on:\n\nWhether an effect is or is not significant in the datasets we are comparing;\nWhether the estimate of the coefficient for the slope of an effect of interest has similar sign (positive or negative) or size (the value of the coefficient) in the datasets we are comparing.",
    "crumbs": [
      "Home",
      "PSYC122",
      "8. Week 19 -- Linear models -- critical perspectives"
    ]
  },
  {
    "objectID": "PSYC122/Week19.html#sec-wk19-lectures",
    "href": "PSYC122/Week19.html#sec-wk19-lectures",
    "title": "8. Week 19 – Linear models – critical perspectives",
    "section": "Lectures",
    "text": "Lectures\n\n\n\n\n\n\nTip\n\n\n\nBefore you go on to the activities in Section 5, watch the lectures:\n\n\nThe lecture for this week is presented in four short parts. You can view video recordings of the lectures using Panopto, by clicking on the video images shown following.\n\nAnybody who has the link should be able to view the video.\n\n\nOverview (17 minutes): Critical perspectives – The real challenge in psychological science (people vary, results vary) – variation, replication and evaluating evidence across multiple studies.\n\n\n\nThe Clearly Understood project – questions and analyses (13 minutes): Critical thinking – candidate answers, our assumptions, the sources of uncertainty, and working with samples.\n\n\n\nEvaluating evidence across studies (18 minutes): People vary, results vary – evaluating, thinking about, critically reflecting on analysis results\n\n\n\nBecoming a power learner (24 minutes): Reproducibility, sharing, and learning to exploit the R knowledge ecosystem – every question you ever have has an answer somewhere online; find out how to locate and use this knowledge for yourself.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe slides presented in the videos can be downloaded either as a web page or as a Word document.\n\n\n\nThe slides exactly as presented (21 MB).\nThe slides converted to a Word .docx (11 MB).\n\nYou can download the web page .html file and click on it to open it in any browser (e.g., Chrome, Edge or Safari). The slide images are high quality and there are a lot of them, so the file is quite big; it may take a few seconds to download.\nYou can download the .docx file and click on it to open it as a Word document that you can then edit. Converting the slides to a .docx distorts some images but the benefit of the conversion is that it makes it easier for you to add your notes.\n\n\n\n\n\n\nTip\n\n\n\nTo work with our lecture recordings:\n\nWatch the video parts right through.\nUse the printable versions of the slides to make notes.\nTry out the coding exercises in the how-to guide and the activity tasks or questions (Section 5) to learn how to construct visualizations and do analyses.\n\n\n\n\nThe lectures have four main areas of focus\n1. The real challenges in psychological science\nWe step back to get a broader perspective on what we are doing when we are doing psychological science. We look at some of the real challenges that professional psychologists work with, as we attempt to build a scientific understanding of what people think and do, and why they do it.\n\n\n\n\n\n\nTip\n\n\n\nWhat makes psychological science challenging:\n\nPeople vary\nResults vary\n\n\n\n2. Critical thinking\nThe power and flexibility of the linear model presents challenges. We must decide which candidate predictor variables we specify in our model. This means we must think critically.\n\n\n\n\n\n\nTip\n\n\n\nWe can develop our critical thinking skills by considering:\n\nOur assumptions about:\n\n\nvalidity;\nmeasurement;\ngeneralizability.\n\n\nSources of uncertainty about:\n\n\npredicted change in outcomes, given our predictors;\nways that expected changes vary between people or groups;\nrandom ways that specific responses can be produced.\n\n\n\n3. Evaluating evidence across multiple studies\nAll important questions in the psychological scientific literature are addressed in multiple studies: how do we evaluate the evidence, comparing the results from different studies?\n\n\n\n\n\n\nTip\n\n\n\nHow do we build knowledge in psychological science?\nWe consider:\n\nreplication\nreproducibility\n\nAnd how to assess results across multiple studies.\n\n\nThese are complex concerns and you will learn more about them, in other modules, this year and next year, when you develop an understanding of systematic reviews, meta-analysis, and the critical evaluation of scientific evidence.\n4. How to become a power user\nYou have been learning about data analysis using R. We have been providing rich learning materials but in Week 19 we start to explore the wider world of knowledge about data analysis and R.\n\n\n\n\n\n\nTip\n\n\n\nR is free and open. This means that:\n\nthere is a vast knowledge ecosystem you can use for your own purposes;\nlearning to be a powerful data analyst involves learning how to locate and to use the resources that are out there.\n\n\n\nWe hope that these lessons are just the start for many of you.\nEvery problem you ever have:\n\nsomeone has had it before;\nsolved it;\nand written a blog or social media post or recorded a YouTube or TikTok about it.",
    "crumbs": [
      "Home",
      "PSYC122",
      "8. Week 19 -- Linear models -- critical perspectives"
    ]
  },
  {
    "objectID": "PSYC122/Week19.html#reading-links-to-other-classes",
    "href": "PSYC122/Week19.html#reading-links-to-other-classes",
    "title": "8. Week 19 – Linear models – critical perspectives",
    "section": "Reading: Links to other classes",
    "text": "Reading: Links to other classes\nWe do not provide further reading for this class but you will find it helpful to revise some of the key ideas you have been learning about PSYC122 and in other modules.\n\nThe lectures in PSYC123 on: the scientific method; reliability and validity; experimental design, especially between-subjects studies; hypothesis testing; and precise hypotheses.\nThe lecture in PSYC122 on linear models.",
    "crumbs": [
      "Home",
      "PSYC122",
      "8. Week 19 -- Linear models -- critical perspectives"
    ]
  },
  {
    "objectID": "PSYC122/Week19.html#sec-wk19-prelab-activities",
    "href": "PSYC122/Week19.html#sec-wk19-prelab-activities",
    "title": "8. Week 19 – Linear models – critical perspectives",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\n\nPre-lab activity 1\nThe survey is now closed.\nIf you want more information about the project, we invite you to read the pre-registered research plan for the PSYC122 health advice research project.\nRead the project pre-registration",
    "crumbs": [
      "Home",
      "PSYC122",
      "8. Week 19 -- Linear models -- critical perspectives"
    ]
  },
  {
    "objectID": "PSYC122/Week19.html#sec-wk19-lab-activities",
    "href": "PSYC122/Week19.html#sec-wk19-lab-activities",
    "title": "8. Week 19 – Linear models – critical perspectives",
    "section": "Lab activities",
    "text": "Lab activities\n\nIntroduction\nWe will do our practical lab work to develop your skills in the context of the Clearly Understood project.\n\nOur focus is on what makes it easy or difficult for people to understand written health information.\n\n\n\n\n\n\n\nImportant\n\n\n\nIn Week 19, we aim to answer the research questions:\n\nWhat person attributes predict success in understanding health information?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\n\nPSYC122 students contributed their responses to a survey we have been using to collect data to find answers to these questions.\nIn our practical work, we will be examining the PSYC122 data but, as we do so, we should understand that no one study in psychological science will give us definitive answers to any interesting question about people and what they do.\nIn the practical work, you will be asked to reflect on how data from different studies – using the same methods, with the same aims – may nevertheless vary:\n\nvary in the data distributions;\nand vary in the results that analyses indicate.\n\nCritically evaluating results across a series of studies, or replication attempts, is part of the process of accumulating evidence to build insight in psychological science, given measurement under uncertainty and limits in samples.\n\n\nGet ready\n\nDownload the data\nClick on the link: 122-week19_for_students.zip to download the data files folder. Then upload the contents to the new folder you created in RStudio Server.\nThe downloadable .zip folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n2023-24_PSYC122-participants.csv\n\nand the R Markdown .Rmd:\n\n2023-24-PSYC122-w19-how-to.Rmd\n\nIf you can’t upload these files to the server – this affects some students – you can use some code to get R to do it for you: uncover the code box below to reveal the code to do this.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nYou can use the code below to directly download the file you need in this lab activity to the server.\nRemember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\nGet the study-one-general-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week19/study-one-general-participants.csv?raw=true\", destfile = \"study-one-general-participants.csv\")\n\n\nGet the study-two-general-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week19/study-two-general-participants.csv?raw=true\", destfile = \"study-two-general-participants.csv\")\n\n\nGet the 2023-24 PSYC122 2023-24_PSYC122-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week19/2023-24_PSYC122-participants.csv?raw=true\", destfile = \"2023-24_PSYC122-participants.csv\")\n\n\nGet the 2023-24-PSYC122-w19-how-to.Rmd how-to guide\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week19/2023-24-PSYC122-w19-how-to.Rmd?raw=true\", destfile = \"2023-24-PSYC122-w19-how-to.Rmd\")\n\n\n\n\n\n\nCheck: What is in the data files?\nEach of the data files we will work with has a similar structure, as you can see in this extract.\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\n\n\n\n\n\nYou can use the scroll bar at the bottom of the data window to view different columns.\nYou can see the columns:\n\nparticipant_ID participant code;\nmean.acc average accuracy of response to questions testing understanding of health guidance (varies between 0-1);\nmean.self average self-rated accuracy of understanding of health guidance (varies between 1-9);\nstudy variable coding for what study the data were collected in\nAGE age in years;\nHLVA health literacy test score (varies between 1-16);\nSHIPLEY vocabulary knowledge test score (varies between 0-40);\nFACTOR3 reading strategy survey score (varies between 0-80);\nGENDER gender code;\nEDUCATION education level code;\nETHNICITY ethnicity (Office National Statistics categories) code.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is always a good idea to view the dataset – click on the name of the dataset in the R-Studio Environment window, and check out the columns, scroll through the rows – to get a sense of what you are working with.\n\n\n\n\n\nLab activity 1: Work with the How-to guide\nThe how-to guide comprises an .Rmd file:\n\n2023-24-PSYC122-w19-how-to.Rmd\n\nIt is full of advice and example code.\nThe code in the how-to guide was written to work with two data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nWe will be working with your (PSYC122) response data in Section 5.4.\n\n\n\n\n\n\nTip\n\n\n\nWe show you how to do everything you need to do in the lab activity (Section 5.4, shown following) in the how-to guide.\n\nStart by looking at the how-to guide to understand what steps you need to follow in the lab activity.\n\n\n\nWe will take things step-by-step.\nWe split .Rmd scripts by steps, tasks and questions:\n\ndifferent steps for different phases of the analysis workflow;\ndifferent tasks for different things you need to do;\ndifferent questions to examine different ideas or coding challenges\n\n\n\n\n\n\n\nTip\n\n\n\n\nMake sure you start at the top of the .Rmd file and work your way, in order, through each task.\nComplete each task before you move on to the next task.\n\n\n\nIn the activity Section 5.4, we are going to work through a sequence of steps and tasks that mirrors the sequence you find in the how-to guide.\n\nThere is a little bit of variation, comparing the later steps in the how-to guide and the steps in Section 5.4, but that variation is designed to help you with your learning.\n\n\n\n\n\n\n\nTip\n\n\n\n\nNotice that we are gradually building up our skills: consolidating what we know; revising important learning; and extending ourselves to acquire new skills.\n\n\n\nStep 1: Set-up\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\n\nStep 2: Load the data\n\nRead in the data files – using read_csv()\nInspect both datasets – using head() and summary()\n\nStep 3: Compare the data from the different studies\n\nCompare the data distributions from the two studies – using geom_histogram() 6-7. and by constructing grids of plots\n\nStep 4: Use scatterplots and correlation to examine associations between variables\n\nDraw scatterplots to compare the potential association between variables\nCreate grids of plots to make side-by-side comparisons of associations in different datasets\nEstimate the associations between pairs of variables and compare the estimates\n\nStep 5: Use a linear model to to answer the research questions – models with multiple predictors\n\nExamine the relation between one outcome and multiple predictors\nDo this in comparable datasets, and compare summaries or plots\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are unsure about what you need to do, look at the advice in 2023-24-PSYC122-w19-how-to.Rmd on how to do the tasks, with examples on how to write the code.\n\n\nYou will see that you can match a task in the activity Section 5.4 to the same task in the how-to guide. The how-to shows you what function you need and how you should write the function code.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in modern psychological science.\n\n\n\n\n\n\nWarning\n\n\n\nDon’t forget: You will need to change the names of the dataset or the variables to complete the tasks in Section 5.4.\n\n\n\n\nLab activity 2\n\n\nOK: now let’s do it!\nIn the following, we will guide you through the tasks and questions step by step.\n\n\n\n\n\n\nTip\n\n\n\n\nWe will not at first give you the answers to questions about the data or about the results of analyses.\nAn answers version of the workbook will be provided after the last lab session (check the answers then in Section 6) so that you can check whether your independent work has been correct.\n\n\n\n\nQuestions\n\n\n\n\n\n\nWarning\n\n\n\nStudents have told us that it would be helpful to your learning if we reduce the information in the hints we provide you. We have done this in Week 19.\nThe motivation for doing this is:\n\nIt will require you to do more active thinking to complete tasks or answer questions;\nThus, you can check to see how your learning is developing – can you do the tasks, given what you know now?\nPlus, psychological research shows that active thinking is better for understanding and for learning.\n\nWhere we do give you hints, we will sometimes replace the correct bit of code with a place-holder: ...\n\nYour task will therefore be to replace the place-holder ... with the correct bit of code or the correct dataset or variable name.\n\n\n\n\n\nStep 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\n\n\n\n\n\n\n\n\nTask 2 – Run code to load relevant libraries\nNotice that in Week 19, we need to work with the libraries ggeffects, patchwork and tidyverse. Use the library() function to make these libraries available to you.\n\n\n\n\n\n\n\n\n\n\n\nStep 2: Load the data\n\nTask 3 – Read in the data files we will be using\nThe data files are called:\n\nstudy-two-general-participants.csv\n2023-24_PSYC122-participants.csv\n\nUse the read_csv() function to read the data files into R:\n\n\n\n\n\n\n\nWhen you read the data files in, give the data objects you create distinct name e.g. study.two.gen versus study.122.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look at both datasets.\n\n\n\n\n\n\n\n\n\n\nStep 3: Compare the data from the different studies\n\n\n\n\n\n\nRevise: practice to strengthen skills\n\n\n\n\n\n\n\nTask 5 – Compare the data distributions from the two studies\n\n\nQuestions: Task 5\n\nQ.1. What is the mean of the mean.acc and SHIPLEY variables in the two studies?\n\n\n\n\n\n\n\nQ.2. Draw histograms of both mean.acc and mean.self for both studies.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\n\n\n\n\n\n\n\nTask 6 – Create grids of plots to make the comparison easier to do\n\nHint: Task 6 – What we are going to do is to create two histograms of mean.acc (one plot for each study dataset) and then present the plots side by side to allow easy comparison of variable distributions\n\nWe need to make two changes to the coding approach you have been using until now.\n\nRemember, you can find what you need to do in 2023-24-PSYC122-w19-how-to.Rmd.\n\nFirst, create plot objects, assign the plot objects distinct names.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecond, name the plots to show them side-by-side.\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is what you need to: check out the process, step-by-step.\n\nNotice that you repeat the process for each of two (or more) plots.\n\n\nggplot(...) tell R you want to make a plot using the ggplot() function;\nplot.one &lt;- tell R you want to give the plot a name; the name appears in the environment;\nggplot(data = study.two.gen ...) tell R you want to make a plot with the study.two data;\nggplot(..., aes(x = mean.acc)) tell R that you want to make a plot with the variable mean.acc;\n\n\nhere, specify the aesthetic mapping, x = mean.acc\n\n\ngeom_histogram() tell R you want to plot values of mean.acc as a histogram;\nbinwidth = .1 adjust the binwidth to show enough detail but not too much in the distribution;\ntheme_bw() tell R what theme you want, adjusting the plot appearance;\nlabs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study Two\") fix the x-axis and y-axis labels;\n\n\nhere, add a title for the plot, so you can tell the two plots apart;\n\n\nxlim(0, 1) adjust the x-axis limits to show the full range of possible score values on this variable.\n\nDo this process twice, once for each dataset, creating two plots so that you can compare the distribution of mean.acc scores between the studies.\nFinally, having created the two plots, produce them for viewing:\n\nplot.two + plot.122 having constructed – and named – both plots, you enter their names, separated by a +, to show them in a grid of two plots.\n\nNotice: until you get to step 10, nothing will appear. This will be surprising but it is perfectly normal when we increase the level of complexity of the plots we build.\n\n\n\n\n\n\n\n\n\n\n\nTask 7 – Try this out for yourself, focusing now on the distribution of SHIPLEY scores in the two studies\nFirst, create plot objects but do not show them.\n\nGive each plot a name. You will use the names next.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecond produce the plots for viewing, side-by-side, by naming them: plot.1.name + plot.2.name.\n\n\n\n\n\n\n\nQ.3. Now use the plots to do some data analysis work: how do the SHIPLEY distributions compare, when you compare the SHIPLEY of study.two.gen versus SHIPLEY of study.122?\n\n\n\n\n\n\nQ.4. Is the visual impression you get from comparing the distributions consistent with the statistics you see in the summary?\n\n\n\n\n\nStep 4: Now use scatterplots and correlation to examine associations between variables\n\n\n\n\n\n\nRevise: practice to strengthen skills\n\n\n\n\n\n\n\nTask 8 – Draw scatterplots to compare the potential association between mean.acc and mean.self in both study.two.gen and study.122 datasets\n\nHint: Task 8 – The plotting steps are explained in some detail in 2023-24-PSYC122-w17-how-to.Rmd and you can see example code in 2023-24-PSYC122-w19-how-to.Rmd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask 9 – Create a grid of plots to make the comparison easier to do\n\nHint: Task 9 – We follow the same steps as we used in tasks 6 and 7 to create the plots\n\nWe again:\n\nFirst construct the plot objects and give them names;\ncreate and show a grid of named plots.\n\nThough this time we are producing a grid of scatterplots.\nFirst, create plot objects, give them names, but do not show them.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecond name the plots to show them side-by-side in the plot window.\n\n\n\n\n\n\nNow use the plots to make comparison judgments.\n\nQ.5. How does the association, shown in the plots, between mean.self and mean.acc compare when you look at the study.two.gen versus the study.122 plot? hint: Q.5. When comparing evidence about associations in different studies, we are mostly going to focus on the slope – the angle – of the prediction lines, and the ways in which points do or do not cluster about the prediction lines.\n\n\nWe are now in a position to answer one of our research questions:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\n\n\n\n\n\n\n\nRevise: practice to strengthen skills\n\n\n\n\n\n\n\n\nTask 10 – Can you estimate the association between mean.acc and mean.self in both datasets?\n\nHint: Task 10 – We use cor.test() as you have been shown how to do e.g. in 2023-24-PSYC122-w16-how-to.Rmd\n\nDo the correlation for both datasets.\nFirst calculate the correlation between mean.acc and mean.self in study.two.\n\n\n\n\n\n\nThen answer the following questions.\n\nQ.6. What is r, the correlation coefficient?\n\n\n\nQ.7. Is the correlation significant?\n\n\n\nQ.8. What are the values for t and p for the significance test for the correlation?\n\n\nSecond, look at the correlation between mean.acc and mean.self in study.122.\n\n\n\n\n\n\nThen answer the following questions.\n\nQ.9. What is r, the correlation coefficient?\n\n\n\nQ.10. Is the correlation significant?\n\n\n\nQ.11. What are the values for t and p for the significance test for the correlation?\n\n\nNow we can answer the research question:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nQ.12. What do the correlation estimates tell you is the answer to the research question?\n\n\n\n\nQ.13. Can you compare the estimates, given the two datasets, to evaluate if the result in study.two.gen is replicated in study.122? hint: Q.13. We can judge if the result in a study is replicated in another study by examining if – here – the correlation coefficient is significant in both studies and if the coefficient has the same size and sign in both studies.\n\n\n\n\n\n\n\n\nTask 11 – In working with R to do data analysis, we often work with libraries of function like {tidyverse} that enable us to do things (see the week 19 lecture for discussion).\nIn this way, we are using the {patchwork} library so that we can create plots and then present them in a grid.\nCan you find the online information about {patchwork} and use it to adjust the layout of the grids of plots you are using?\n\nHint: Task 11 – To find out more information about a function or a library in R, do a search for the keywords\n\nYou can do a search, using any search engine (e.g., Bing, Chrome, Google), by entering:\n\nin r ...\n\nAnd pasting the words you want to know about to replace the ... e.g. “in r patchwork”.\nYou will then see a list of results including the link to the {patchwork} information:\nhttps://patchwork.data-imaginist.com\n\n\n\nStep 5: Use a linear model to to answer the research questions – multiple predictors\n\n\n\n\n\n\nRevise: practice to strengthen skills\n\n\n\n\n\n\n\nTask 12 – Examine the relation between outcome mean accuracy (mean.acc) and multiple predictors\n\nHint: Task 12 – We use lm(), as we have been doing before, see e.g. 2023-24-PSYC122-w18-how-to.R\n\n\nExamine the predictors of mean accuracy (mean.acc), first, for the study.two.gen data.\n\nWe specify a linear model of the study.two.gen data, including as the outcome:\n\nmean accuracy (mean.acc)\n\nand including as the predictors the variables:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\n\n\n\n\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary to then answer the following questions:\n\nQ.14. What is the estimate for the coefficient of the effect of the predictor SHIPLEY in this model?\n\n\n\nQ.15. Is the effect significant?\n\n\n\nQ.16. What are the values for t and p for the significance test for the coefficient?\n\n\n\nQ.17. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.two.gen data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.17. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\n\n\n\n\n\n\n\nTask 13 – Examine the predictors of mean accuracy (mean.acc), now, for the study.122 data\n\nExamine the predictors of mean accuracy (mean.acc), second, for the study.122 data.\n\nWe specify a linear model of the study.122 data, including as the outcome:\n\nmean accuracy (mean.acc)\n\nand including as the predictors the variables:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\n\n\n\n\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:\n\nQ.18. What is the estimate for the coefficient of the effect of the predictor, HLVA, in this model?\n\n\n\nQ.19. Is the effect significant?\n\n\n\nQ.20. What are the values for t and p for the significance test for the coefficient?\n\n\n\nQ.21. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.122 data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.21. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\n\n\n\nAt this point, we can evaluate the evidence from the PSYC122 sample – based on your responses – to assess if the patterns, the estimates, we saw previously are repeated in analyses of PSYC122 responses.\n\nQ.22. Are the findings from study.two.gen replicated in study.122?\n\n\nhint: Q.22. We can judge if the results in an earlier study are replicated in another study by examining if – here – the linear model estimates are significant in both studies and if the coefficient estimates have the same size and sign in both studies.\n\n\n\n\n\n\n\nQ.23. How would you describe the outstanding difference between the results of the two studies?\n\n\nhint: Q.23. We can look at the estimates but we can also use model prediction plotting code to visualize the results. You can build on the code you used before, see:\n\n\n2022-23-PSYC122-w18-how-to.R\n2022-23-PSYC122-w19-how-to.R\n\n\nhint: Q.23. Let’s focus on comparing the study.two.gen and study.122 estimates for the effect of HLVA in both models: we can plot model predictions, for comparison:\n\nFirst: fit the models – using different names for the different models.\n\n\n\n\n\n\n\n\n\nSecond, create prediction plots for the HLVA effect for each model.\n\n\n\n\n\n\n\n\n\nThird, show the plots side-by-side:\n\n\n\n\n\n\nThen use your visualization of the model results to describe the outstanding difference between the results of the two studies – focusing on the effect of HLVA in both models.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe can redraw the prediction plots – next – to add in more information about our samples. This change, see following, will help us to interpret the results of the analyses we have done.\nAnd that will help you to see why data visualization and data analysis work well together.\n\n\n\n\nTask 14 – In producing prediction plots, we are using functions from the {ggefects} library. Can you locate online information about working with the library functions?\n\n\n\n\n\n\nHint\n\n\n\n\n\nTry doing a search with the key words: in r ggeffects.\nIf you do that, you will see links to the website:\nhttps://strengejacke.github.io/ggeffects/\n\n\n\n\n\nTask 15 – In the {ggeffects} online information, you can see links to practical examples. Can you use the information under Practical examples to adjust the appearance of the prediction plots: to make them black and white; to add points?\nFirst create the plots.\n\n\n\n\n\n\n\n\n\nThen show the plots in a grid, to allow comparison of the effect of HLVA between studies in a professional presentation.\n\n\n\n\n\n\n\nIt is often useful to compare model estimates – here, the slopes – with the raw data observations.\n\nNo model will be perfect.\nVisualizing the difference between what we observe and what we predict helps to make sense of how our prediction model could be improved.\n\n\n\nQ.24. Given the information in the adjusted plots, can you explain why we appear to be more uncertain about the HLVA effect given the study.122 data?\n\n\n\n\n\n\nYou have now completed the Week 19 questions.\nYou have now extended your capacity to think critically about our data and our capacity to predict people and their behaviour.\n\n\n\n\n\n\nTip\n\n\n\n\nWe have used PSYC122 students’ responses to examine the robustness of evidence for potential answers to our research questions.\nExamining evidence across multiple different studies is a key element part of the process of building insights in psychological science.",
    "crumbs": [
      "Home",
      "PSYC122",
      "8. Week 19 -- Linear models -- critical perspectives"
    ]
  },
  {
    "objectID": "PSYC122/Week19.html#sec-wk19-lab-activities-answers",
    "href": "PSYC122/Week19.html#sec-wk19-lab-activities-answers",
    "title": "8. Week 19 – Linear models – critical perspectives",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week.\n\n\n\n\n\n\nTip\n\n\n\nThe .Rmd script containing all code and all answers for each task and each question will be made available after the final lab session has taken place.\n\nYou can download the script by clicking on the link: 2023-24-PSYC122-w19-workbook-answers.Rmd.\nOr by copying the code into the R Console window and running it to get the 2023-24-PSYC122-w19-workbook-answers.Rmd loaded directly into R:\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week19/2023-24-PSYC122-w19-workbook-answers.Rmd?raw=true\", destfile = \"2023-24-PSYC122-w19-workbook-answers.Rmd\")\n\n\n\nWe set out answers information the Week 19 Critical perspectives questions, below.\n\nWe focus on the Lab activity 2 questions where we ask you to interpret something or say something.\nWe do not show questions where we have given example or target code in the foregoing lab activity Section 5.4.\n\nYou can see all the code and all the answers in 2023-24-PSYC122-w19-workbook-answers.Rmd.\n\nAnswers\n\n\n\n\n\n\nTip\n\n\n\nClick on a box to reveal the answer.\n\n\n\nQuestions\n\nQ.1. What is the mean of the mean.acc and SHIPLEY variables in the two studies?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.1. The means are:\nstudy two – mean.acc: mean = 0.7596\nstudy two – SHIPLEY: mean = 35.13\nstudy PSYC122 – mean.acc: mean = 0.8231\nstudy PSYC122 – SHIPLEY: mean = 32.31\n\n\n\n\n\nQ.2. Draw histograms of both mean.acc and mean.self for both studies.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.2. You can write the code using the same code structure you have been shown e.g. in 2023-24-PSYC122-w19-how-to.Rmd but changing dataset and variable names to get the right plots:\n\n\nggplot(data = study.two.gen, aes(x = mean.acc)) +\n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) +\n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0, 40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.122, aes(x = mean.acc)) +\n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.122, aes(x = SHIPLEY)) +\n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0, 40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\nCreate histograms to enable you to compare the distribution of SHIPLEY scores in the study.two.gen and the study.122 studies\n\nFirst, create plot objects but do not show them.\nSecond produce the plots for viewing, side-by-side, by naming them: plot.1.name + plot.2.name.\n\n\nQ.3. Now use the plots to do some data analysis work: how do the SHIPLEY distributions compare, when you compare the SHIPLEY of study.two.gen versus SHIPLEY of study.122?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.3. When you compare the plots side-by-side you can see that the SHIPLEY distributions are mostly similar: most people have high SHIPLEY scores.\n\nBut you can also see striking differences:\n\nThe peak of the distribution – where the tallest bar is – is at a higher SHIPLEY score in study.two.gen (around SHIPLEY = 37-38) than in study.122 (where is it around SHIPLEY = 30).\nThere appear to be fewer participants with lower SHIPLEY scores in study.122 than in study.two.\n\n\n\n\n\nQ.4. Is the visual impression you get from comparing the distributions consistent with the statistics you see in the summary?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.4. Yes: If you go back to the summary of SHIPLEY, comparing the two studies datasets, then you can see that the median and mean are higher in study.122 than in study.two.gen.\n\n\n\n\nDraw scatterplots to compare the potential association between mean.acc and mean.self in both the study.two.gen and the study.122 datasets.\nWe again:\n\nFirst construct the plot objects and give them names;\ncreate and show a grid of named plots.\n\nThough this time we are producing a grid of scatterplots.\nNow use the plots to make comparison judgments.\n\nQ.5. How does the association, shown in the plots, between mean.self and mean.acc compare when you look at the study.two.gen versus the study.122 plot? hint: Q.5. When comparing evidence about associations in different studies, we are mostly going to focus on the slope – the angle – of the prediction lines, and the ways in which points do or do not cluster about the prediction lines.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.5. If you examine the study.two.gen versus the study.122 plots then you can see that in both plots higher mean.self scores appear to be associated with higher mean.acc scores. But the trend maybe is a bit stronger – the line is steeper – in study.two.\n\nWe are now in a position to answer one of our research questions:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nIf people can accurately evaluate whether they correctly understand written health information then mean.self (a score representing their evaluation) should be associated with mean.acc (a score representing their accuracy of understanding) for each person.\n\n\n\nCan you estimate the association between mean.acc and mean.self in both datasets?\n\nWe use cor.test() as you have been shown how to do e.g. in 2023-24-PSYC122-w16-how-to.Rmd.\nDo the correlation for both datasets.\n\nFirst calculate the correlation between mean.acc and mean.self in study.two. Then answer the following questions.\n\nQ.6. What is r, the correlation coefficient?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.6. r = 0.5460792\n\n\n\n\n\nQ.7. Is the correlation significant?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.7. r is significant\n\n\n\n\n\nQ.8. What are the values for t and p for the significance test for the correlation?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.8. t = 8.4991, p = 9.356e-15\n\n\n\n\nSecond, use the same method to calculate the correlation between mean.acc and mean.self in study.122. Then answer the following questions.\n\nQ.9. What is r, the correlation coefficient?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.9. r = 0.4027438\n\n\n\n\n\nQ.10. Is the correlation significant?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.10. r is significant\n\n\n\n\n\nQ.11. What are the values for t and p for the significance test for the correlation?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.11. t = 3.4924, p = 0.0008808\n\n\n\n\nNow we can answer the research question:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nQ.12. What do the correlation estimates tell you is the answer to the research question?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.12.\n\n\nThe correlations are positive and significant, indicating that higher mean.self (evaluations) are associated with higher mean.acc (understanding), suggesting that people can judge their accuracy of understanding.\n\n\n\n\n\nQ.13. Can you compare the estimates, given the two datasets, to evaluate if the result in study.two.gen is replicated in study.122? hint: Q.13. We can judge if the result in a study is replicated in another study by examining if – here – the correlation coefficient is significant in both studies and if the coefficient has the same size and sign in both studies.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.13. If you compare the correlation estimates from both study.two.gen and study.122 you can see:\nfirst, the correlation is significant in both study.two.gen and study.122;\nsecond, the correlation is positive in both studies.\n\nBut, if you compare the correlation estimates, you can see that the coefficient estimate is smaller in study.122 (where r = .40) than in study.two.gen (where r = .55).\nThis may suggest that the association observed in study.two.gen is different from the association in study.122, for some reason.\n\n\n\nExamine the relation between outcome mean accuracy (mean.acc) and multiple predictors.\nWe use lm(), as we have been doing before, see e.g. 2023-24-PSYC122-w18-how-to.R\nExamine the predictors of mean accuracy (mean.acc), first, for the study.two.gen data.\nWe specify a linear model of the study.two.gen data, including as the outcome:\n\nmean accuracy (mean.acc)\n\nand including as the predictors the variables:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,    Adjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary to then answer the following questions:\n\nQ.14. What is the estimate for the coefficient of the effect of the predictor SHIPLEY in this model?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.14. 0.008397\n\n\n\n\n\nQ.15. Is the effect significant?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.15. It is significant, p &lt; .05\n\n\n\n\n\nQ.16. What are the values for t and p for the significance test for the coefficient?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.16. t = 4.533, p = 1.1e-05\n\n\n\n\n\nQ.17. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.two.gen data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.17. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.17.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 168) = 31.99, p&lt; .001, and explains 35% of variance (adjusted R2 = 0.35). Mean accuracy was predicted to be higher given higher scores in health literacy (HLVA estimate = .018, t = 4.90, p &lt; .001), vocabulary knowledge (SHIPLEY estimate = .008, t = 4.53, p &lt; .001), and reading strategy (FACTOR3 estimate = .003, t = 2.68, p = .008).\n\n\n\n\nExamine the predictors of mean accuracy (mean.acc), now, for the study.122 data.\nWe specify a linear model now of the study.122 data, including as the outcome:\n\nmean accuracy (mean.acc)\n\nand including as the predictors the variables:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.37214 -0.07143 -0.01102  0.07411  0.25329 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.3066150  0.1447265   2.119   0.0382 *  \nHLVA        0.0335342  0.0071332   4.701 1.52e-05 ***\nSHIPLEY     0.0062524  0.0034741   1.800   0.0768 .  \nFACTOR3     0.0006217  0.0024450   0.254   0.8001    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1162 on 61 degrees of freedom\nMultiple R-squared:  0.4158,    Adjusted R-squared:  0.3871 \nF-statistic: 14.47 on 3 and 61 DF,  p-value: 3.156e-07\n\n\n\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:\n\nQ.18. What is the estimate for the coefficient of the effect of the predictor, HLVA, in this model?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.18. 0.0335342\n\n\n\n\n\nQ.19. Is the effect significant?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.19. It is significant, p &gt; .05 because p = 1.52e-05\n\n\n\n\n\nQ.20. What are the values for t and p for the significance test for the coefficient?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.20. t = 4.701, p &lt; .001\n\n\n\n\n\nQ.21. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.122 data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.21. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.21.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 61) = 14.47, p &lt; .001, and explains 39% of variance (adjusted R2 = .387). Mean accuracy was predicted to be higher given higher scores in health literacy (HLVA estimate = .034, t = 4.70, p &lt; .001). There were non-significant effects of individual differences in vocabulary knowledge (SHIPLEY estimate = .006, t = 1.80, p = .077) and reading strategy (FACTOR3 estimate = .001, t = .25, p = .800).\n\n\n\n\nAt this point, we can evaluate the evidence from the PSYC122 sample – based on your responses – to assess if the patterns, the estimates, we saw previously are repeated in analyses of PSYC122 responses.\n\nQ.22. Are the findings from study.two.gen replicated in study.122? - hint: Q.22. We can judge if the results in an earlier study are replicated in another study by examining if – here – the linear model estimates are significant in both studies and if the coefficient estimates have the same size and sign in both studies.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.22. If you compare the linear model coefficient estimates from both the study.two.gen and study.122 models, you can see:\nfirst, that the HLVA effect estimate is significant in both study.two.gen and study.122;\nsecond, that the estimates of the HLVA effect have the same sign – positive – in both studies while the estimated coefficient is a bit bigger in the study.122 data (implying a stronger effect);\nbut, third that the estimates of the effects of variation in vocabulary knowledge (SHIPLEY) and reading strategy (FACTOR3) are significant in study.two.gen but not in study.122.\n\nThis suggests that the attributes – the set of abilities – that predict comprehension accuracy are similar but not the same in the study.two.gen participants compared to study.122 participants.\n\n\n\n\nQ.23. How would you describe the outstanding difference between the results of the two studies? hint: Q.23. We can look at the estimates but we can also use model prediction plotting code to visualize the results. You can build on the code you used before, see:\n\n\n2022-23-PSYC122-w18-how-to.R\n2022-23-PSYC122-w19-how-to.R\n\n\nhint: Q.23. Let’s focus on comparing the study.two.gen and study.122 estimates for the effect of HLVA in both models: we can plot model predictions, for comparison:\n\nFirst: fit the models – using different names for the different models.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nmodel.two &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model.two)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,    Adjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: &lt; 2.2e-16\n\nmodel.122 &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\nsummary(model.122)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.37214 -0.07143 -0.01102  0.07411  0.25329 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.3066150  0.1447265   2.119   0.0382 *  \nHLVA        0.0335342  0.0071332   4.701 1.52e-05 ***\nSHIPLEY     0.0062524  0.0034741   1.800   0.0768 .  \nFACTOR3     0.0006217  0.0024450   0.254   0.8001    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1162 on 61 degrees of freedom\nMultiple R-squared:  0.4158,    Adjusted R-squared:  0.3871 \nF-statistic: 14.47 on 3 and 61 DF,  p-value: 3.156e-07\n\n\n\n\n\nSecond, create prediction plots for the HLVA effect for each model.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\ndat.two &lt;- ggpredict(model.two, \"HLVA\")\nplot.two &lt;- plot(dat.two) + labs(title = \"Study Two\")\ndat.122 &lt;- ggpredict(model.122, \"HLVA\")\nplot.122 &lt;- plot(dat.122) + labs(title = \"Study PSYC122\")\n\n\n\n\nThird, show the plots side-by-side:\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nplot.two + plot.122\n\n\n\n\n\n\n\n\n\n\n\nThen use your visualization of the model results to describe the outstanding difference between the results of the two studies – focusing on the effect of HLVA in both models.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.23. If we compare the estimates for the coefficient of the HLVA effect in the study.two.gen and study.122 models we can see that:\n\n\nThe health literacy HLVA effect is significant in both study.two.gen and study.122.\nThe effect trends positive in both studies.\nThe coefficient estimate is bigger in study.122 than in study.two.gen.\nThe prediction plots suggest the prediction line slope is steeper in study.122.\nThe grey shaded area around the trend line (indicating our uncertainty about the estimated trend) is wider for study.two.gen than for study.122, suggesting we are more uncertain about the association for the study.two.gen data.\n\n\nThe breadth of the grey shaded area around the trend line is hard to compare between the two plots. You have to look carefully at the y-axis scale information to make a judgment about the relative width of these uncertainty ellipses.\n\nThe visualizations plus the model summaries suggests that the estimates of the effect of health literacy are different in the study.122 compared to the study.two.gen data. Why is that?\n\n\n\nWe can redraw the prediction plots to add in more information about our samples. This change, see following, will help us to interpret the results of the analyses we have done. And that will help you to see why data visualization and data analysis work well together.\nIn the {ggeffects} online information, you can see links to practical examples. Can you use the information under Practical examples to adjust the appearance of the prediction plots: to make them black and white; to add points?\nFirst create the plots.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\ndat.two &lt;- ggpredict(model.two, \"HLVA\")\nplot.two &lt;- plot(dat.two, colors = \"bw\", add.data = TRUE) + labs(title = \"Study Two\")\n\nData points may overlap. Use the `jitter` argument to add some amount of\n  random variation to the location of data points and avoid overplotting.\n\ndat.122 &lt;- ggpredict(model.122, \"HLVA\")\nplot.122 &lt;- plot(dat.122, colors = \"bw\", add.data = TRUE) + labs(title = \"Study PSYC122\")\n\nData points may overlap. Use the `jitter` argument to add some amount of\n  random variation to the location of data points and avoid overplotting.\n\n\n\n\n\nThen show the plots in a grid, to allow comparison of the effect of HLVA between studies in a professional presentation.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nplot.two + plot.122\n\n\n\n\n\n\n\n\n\n\n\n\nIt is often useful to compare model estimates – here, the slopes – with the raw data observations.\n\nNo model will be perfect.\nVisualizing the difference between what we observe and what we predict helps to make sense of how our prediction model could be improved.\n\n\n\nQ.24. Given the information in the adjusted plots, can you explain why we appear to be more uncertain about the HLVA effect given the study.122 data?\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA.24. Adding points allow us to see:\n\n\nThere are far fewer observations in the study.122 dataset than in the study.two.gen data: this means that our estimate of the effect will be more uncertain because we have less information when we look at the study.122 data.\nBut it is also clear that the effect of HLVA appears to be stronger in the study.122 data because observed scores are closer to model predictions: the HLVA effect explains more variation in the study.122 data than in the study.two.gen data.",
    "crumbs": [
      "Home",
      "PSYC122",
      "8. Week 19 -- Linear models -- critical perspectives"
    ]
  },
  {
    "objectID": "PSYC122/Week19.html#sec-wk19-lab-Q-and-A",
    "href": "PSYC122/Week19.html#sec-wk19-lab-Q-and-A",
    "title": "8. Week 19 – Linear models – critical perspectives",
    "section": "Online Q&A",
    "text": "Online Q&A\nYou will find, below, a link to the video recording of the Week 19 online Q&A after it has been completed.",
    "crumbs": [
      "Home",
      "PSYC122",
      "8. Week 19 -- Linear models -- critical perspectives"
    ]
  },
  {
    "objectID": "PSYC122/Week12.html",
    "href": "PSYC122/Week12.html",
    "title": "2. Week 12 - Correlation Part 2",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.\nToday we will continue to look at correlation as a measure of association between two numerical variables. We will review assumptions associated with correlation, discuss some issues important to be aware of when interpreting correlation results and finally, we’ll talk about intercorrelation.",
    "crumbs": [
      "Home",
      "PSYC122",
      "2. Week 12 - Correlation Part 2"
    ]
  },
  {
    "objectID": "PSYC122/Week12.html#sec-wk12-lectures",
    "href": "PSYC122/Week12.html#sec-wk12-lectures",
    "title": "2. Week 12 - Correlation Part 2",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week is presented in three parts:\n\nTheory – Assumptions, issues and inter-correlation(~25 minutes) Watch this part before you complete the reading and the pre-lab activities. The video has captions, in case you find that helpful. You can download the slides and a transcript from the links below the video.\n\n\nSlides Transcript\n\nHow to – Assumptions, issues and inter-correlation(~25 minutes) Watch this part after you’ve completed the reading and before you attend the lab session.\n\n\nSlides Transcript\n\nData wrangling with dplyr(~10 minutes) Watch this part before you complete the pre-lab activities and before you attend the lab session.\n\n\nSlides Transcript",
    "crumbs": [
      "Home",
      "PSYC122",
      "2. Week 12 - Correlation Part 2"
    ]
  },
  {
    "objectID": "PSYC122/Week12.html#sec-wk12-reading",
    "href": "PSYC122/Week12.html#sec-wk12-reading",
    "title": "2. Week 12 - Correlation Part 2",
    "section": "Reading",
    "text": "Reading\nThe reading that accompanies the lectures this week is again from chapter 9 of the core text by Howell (2017).\nRougly, last week we covered the material in sections 9.1 to 9.4, as well as sections 9.8 to 9.11 and section 9.15. This week, we’ll cover the material in sections 9.5 to 9.7, and sections 9.12 to 9.13. Even if a section is not mentioned here, all of chapter 9 is relevant.",
    "crumbs": [
      "Home",
      "PSYC122",
      "2. Week 12 - Correlation Part 2"
    ]
  },
  {
    "objectID": "PSYC122/Week12.html#sec-wk12-prelab-activities",
    "href": "PSYC122/Week12.html#sec-wk12-prelab-activities",
    "title": "2. Week 12 - Correlation Part 2",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures on correlation and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Data-wrangling with dplyr\nData comes in lots of different formats. One of the most common formats is that of a two-dimensional table (the two dimensions being rows and columns). Usually, each row stands for a separate observation (e.g. a participant), and each column stands for a different variable (e.g. a response, category, or group). A key benefit of tabular data is that it allows you to store different types of data-numerical measurements, alphanumeric labels, categorical descriptors-all in one place.\nIt may surprise you to learn that scientists actually spend far more of time cleaning and preparing their data than they spend actually analysing it. This means completing tasks such as cleaning up bad values, changing the structure of tables, merging information stored in separate tables, reducing the data down to a subset of observations, and producing data summaries. Some have estimated that up to 80% of time spent on data analysis involves such data preparation tasks (Dasu & Johnson, 2003)!\nMany people seem to operate under the assumption that the only option for data cleaning is the painstaking and time-consuming cutting and pasting of data within a spreadsheet program like Excel. We have witnessed students and colleagues waste days, weeks, and even months manually transforming their data in Excel, cutting, copying, and pasting data. Fixing up your data by hand is not only a terrible use of your time, but it is error-prone and not reproducible. Additionally, in this age where we can easily collect massive datasets online, you will not be able to organise, clean, and prepare these by hand.\nIn short, you will not thrive as a psychologist if you do not learn some key data wrangling skills. Although every dataset presents unique challenges, there are some systematic principles you should follow that will make your analyses easier, less error-prone, more efficient, and more reproducible.\nThe functions you’ll need in lab activity 2 include select(), filter(), mutate(), group_by() and summarise() from the dplyr package.\nYou’ve used these functions before, but the following ‘recipes’ summarise what each one does and how to use it.\n\nTASK Have a look at each ‘recipe’ and read through it. Try to understand each step.\n\n\n\n\n\n\n\nRecipes - how to use them\n\n\n\nEach ‘recipe’ has the same structure.\n\nFirst, it summarises what it is that you want to achieve when using that specific function. In the case of select() it says “You want to extract specific columns from a data frame and return them as a new, smaller data frame.”\nThen, it outlines a number of steps that you need to carry out when using this function. For select() it outlines 2 steps: 1. Pass the dataframe to the function. 2. List the column(s) to return.\nFinally, there is an example talks you through using the function with some data. For select() it uses an example with data on the weather.\nAdditional information appears in extra boxes with a light-bulb icon. If you find those confusing, don’t worry about them at this stage.\n\n\n\n\nselect() - extract variables (columns) - recipe\nfilter() - extract observations (rows)- recipe\nmutate() - create a new variable (column) - recipe\ngroup_by() - organise the observations into groups - recipe\nsummarise() - compute summary statistics - recipe\n\n\n\nPre-lab activity 2: Getting ready for the lab class\n\nGet your files ready\nDownload the 122_week12_forStudents.zip file and upload it into the new folder in RStudio Server you created (see last week’s Pre-lab activity 4 for instructions on how to do that.\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below.",
    "crumbs": [
      "Home",
      "PSYC122",
      "2. Week 12 - Correlation Part 2"
    ]
  },
  {
    "objectID": "PSYC122/Week12.html#sec-wk12-labactivities",
    "href": "PSYC122/Week12.html#sec-wk12-labactivities",
    "title": "2. Week 12 - Correlation Part 2",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nconstructing and interpreting histograms and qq-plots\nconstructing and interpreting a matrix of scatterplots\nrunning intercorrelation analysis and interpret the results\ncorrect for multiple comparisons when running intercorrelation analysis\nconstructing a correlation matrix in APA format\nwhen and why to apply correlation analysis to answers questions in psychological science\n\n\nLab activity 1: Assumptions of Correlation Analysis\n\nQuestion 1\nCorrelation would be an appropriate form on analysis for researchers interested in the relationship between:\n\nDog (breed) and height (cm) of owner\nSpeed of swimming (mph) and area of tank (cm)\nNumber of cows sitting and rain fall (mm)\nTotal llama saliva (ml) expelled and gender of visitors\nb and d\nb and c\n\n\n\nQuestion 2\nWhen would you use Spearman’s rho analysis instead of Pearson’s r?\n\nWhen there are clear outliers in the data\nWhen the data is not normally distributed\nWhen the relationship between X and Y is curvilinear\na and b\n\n\n\nQuestion 3\nUsing the histograms and qq-plots below, which of these variables satisfies the normality assumption? Explain your answers.\nHistogram non-words \nQQ-plot non-words \nHistogram words \nQQ-plot words \nHistogram vocabulary \nQQ-plot vocabulary \n\n\nQuestion 4\nWhy should correlation analysis not be conducted on variables with a curvilinear relationship?\n\n\n\nLab activity 2: Attitudes towards vaping\nGreat work so far! Now we really want to see what you can do yourself. In this activity we’ll use real data on implicit and explicit attitudes towards vaping.\n\nBackground\nExplicit attitudes were measured via a questionnaire where higher scores indicated a positive attitude towards vaping (VapingQuestionaireScore). Implicit attitudes were measured through an Implicit Association Test (IAT) using images of Vaping and Kitchen utensils and associating them with positive and negative words.\nThe IAT works on the principal that associations that go together (that are congruent, e.g. warm and sun) should be quicker to respond to than associations that do not go together (that are incongruent, e.g. warm and ice). You can read up more on the procedure on the Noba Project which has a good description of the procedure under the section “Subtle/Nonsconscious Research Methods”.\nFor this exercise, you need to know that “Block 3” in the experiment tested reaction times and accuracy towards congruent associations, pairing positive words with Kitchen utensils and negative words with Vaping. “Block 5” in the experiment tested reaction times and accuracy towards incongruent associations, pairing positive words with Vaping and negative words with Kitchen Utensils. As such, if reaction times were longer in Block 5 than in Block 3 then people are considered to hold the view that Vaping is negative (i.e. congruent associations are quicker than incongruent associations). However, if reaction times were quicker in Block 5 than in Block 3 then people are considered to hold the view that Vaping is positive (i.e. incongruent associations were quicker than congruent associations). The difference between reaction times in Block5 and Block3 is called the participants’ IAT score.\n\n\n\n\n\n\nBefore we begin\n\n\n\nLet’s put the basics in place:\n\nMake sure you have started a new R Markdown script. If you need a reminder of how to do that, please revisit week 6 of PSYC121 (here).\nYou’ll need the data file VapingData.csv you downloaded when completing Pre-lab activity 2. If you experienced issues with uploading files to the server, follow the instructions below.\nWhen starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one.\nFinally, make sure your working directory is set to the folder in which you have stored the data file (VapingData.csv).\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week12/122_week12_forStudents/VapingData.csv?raw=true\", destfile = \"VapingData.csv\")\n\n\n\n\n\n\n\nCleaning the R environment\n\n\n\n\n\nYou can clean the R environment by clicking on the broom icon at the top right of the environment window, or you can use the code below.\n\nrm(list=ls())\n\n\n\n\n\n\n\n\n\n\nChecking your working directory\n\n\n\n\n\nUse the code below to check what you working directory is currently set to. This is the folder that R will use to look for files. Is the file path that is written to the Console after you run the code snippet the one that contains the data file? You can check by nativating to the path you can see in the Console in the ‘Files’ pane on the right. Does it contain the data file (‘VapingData.csv’)?\n\ngetwd()\n\nIf your working directory is not set to the folder that contains the data file, navigate to folder that contains the data file in the ‘Files’ pane, click ‘More’ and then on ‘Set as working directory’.\n\n\n\n\n\nStep 1. Add the code to load the relevant libraries in a new code chunk. We need the following ones: broom, car, Hmisc, lsr and tidyverse. If you are unsure, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library()function. Remember to put it inside a ‘code chunk’ in your R Markdown script.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(Hmisc)\nlibrary(lsr)\nlibrary(tidyverse)\n\n\n\n\nStep 2. Read in the data. The data file we’ll be working with is VapingData.csv. Have a look at the layout of the data and familiarise yourself with it. You have 8 columns. Reaction times and Accuracy scores for Blocks 3 and 5 as well as the Explicit Vaping Questionnaire scores, Sex and Age, for each participant.\n\nQuestion 2a: For how many participants do we have data?\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\ndat &lt;- read_csv(\"VapingData.csv\")\n\n\n\n\nStep 3. Data wrangling. The data are not in a shape yet that we can actually use for our analysis. We’ll have to do some ’data wrangling to knock them into shape. We need to take the following into account:\n\n\n\nAccuracy was calculated as proportion and as such can’t go above 1. Participants entered their own data so some might have made a mistake. Remove participants who had an accuracy greater than 1 in either Block 3 or Block 5 as we are unclear on the accuracy of these values.\n\n\n\n\nWe also only want participants who were paying attention so best remove anybody whose average accuracy score across Blocks 3 and 5 was less than 80%. Note - this value is arbitrary and if you wanted, in your own experiment, you could use a more relaxed or strict cut-off based on other studies or guidance. Note that these decisions should be set out at the start of your research as part of your pre-registration or as part of your Registered Report. Finally, in this instance, remember, the values are in proportions not percentages (so 80% will be .8).\n\n\n\n\nNow that we have removed data points that were the result of data entry mistakes or came from participants who didn’t pay attention during the task, we create an IAT score for participants by subtracting Block 3 reaction times (RT) from Block 5 reaction times (IAT_BLOCK5_RT - IAT_BLOCK3_RT).\n\n\n\nLook closely at each line of code below and check you understand what it does. Copy the code to your script and for each line add a comment to describe what it does.\n\n\ndat &lt;- dat %&gt;%\n  filter(IAT_BLOCK3_Acc &lt; 1) %&gt;%\n  filter(IAT_BLOCK5_Acc &lt; 1) %&gt;%\n  mutate(IAT_ACC = (IAT_BLOCK3_Acc + IAT_BLOCK5_Acc)/2) %&gt;%\n  filter(IAT_ACC &gt; .8) %&gt;%\n  mutate(IAT_RT = IAT_BLOCK5_RT - IAT_BLOCK3_RT)\n\n\n\n\n\n\n\nRecipes\n\n\n\nYou might want to revisit the ‘recipes’ for filter() and mutate() we looked at in pre-lab activity 1 (here Section 3) to remind yourself what these functions do and how to use them.\n\n\nQuestion 3a: For how many participants do we have data now that we have cleaned them up?\nQuestion 3b: Use the information in the background description to understand how the scores relate to attitudes. What does a positive IAT_RT score reflect? What does a negative IAT_RT score reflect? What does a higher score on the ‘VapingQuestionnaireScore’ mean?\n\nStep 4. Calculating descriptive statistics. Now that we have the variables that we need and the data cleaned up, we will create a descriptives summary of the number of people, and the means for the IAT and Vaping Questionnaire Score. Look closely at each line of code below and check you understand what it does. Copy the code to your script and for each line add a comment to describe what it does.\n\n\ndescriptives &lt;- dat %&gt;%\n  summarise(n = n(),\n            mean_IAT_ACC = mean(IAT_ACC),\n            mean_IAT_RT = mean(IAT_RT),\n            mean_VPQ = mean(VapingQuestionnaireScore, na.rm = TRUE))\n\nQuestion 4a: Why might these averages be useful? Why are averages not always useful in correlations?\n\nStep 5. Check the assumptions.\n\nVariable types\nQuestions 5a: What are the variable types for the implicit (IAT_RT) and the explicit (VapingQuestionnaireScore) attitude variables?\nMissing data\n\nRemove participants with missing data.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the filter() function and the is.na() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\ndat &lt;- dat %&gt;% \n  filter(!is.na(VapingQuestionnaireScore)) %&gt;% \n  filter(!is.na(IAT_RT))\n\n\n\nQuestion 5b How many people had missing data?\nNormality\n\nCreate histograms and qq-plots for the IAT_RT and VapingQuestionnaireScore variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the ggplot() function with geom_histogram() and use the qqPlot() function (note the capital P).\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nggplot(dat, aes(x = VapingQuestionnaireScore)) + \n  geom_histogram(binwidth = 10) +\n  theme_bw()\n\nqqPlot(x = dat$VapingQuestionnaireScore)\n\nggplot(dat, aes(x = IAT_RT)) + \n  geom_histogram(binwidth = 10) +\n  theme_bw()\n\nqqPlot(x = dat$IAT_RT)\n\n\n\nQuestion 5c What do you conclude from the histograms and the qq-plots? Are the VapingQuestionnaireScore and the IAT_RT normally distributed?\nLinearity and homoscedasticity\n\nPlot the relationship between IAT_RT and VapingQuestionnaireScore using a scatterplot and a line of best fit.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor this you’ll need the ggplot() function together with geom_point() and geom_smooth(). Make sure to give your axes some sensible labels.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(dat, aes(x = IAT_RT, y = VapingQuestionnaireScore)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Implicit attitude\", y = \"Explicit attitude\")\n\n\n\nQuestion 5d What do you conclude from the scatterplot in terms of the homoscedasticity of the data and the linearity, direction and strength of the relationship? What does the scatterplot tell you about possible issues (outliers, range restrictions)?\n\nStep 6. Conduct a correlation analysis.\n\nQuestion 6a Do you need to calculate Pearson’s r or Spearman’s rho? Why?\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the cor.test() function. You may want to use the pull() and the round() functions to get the numbers out.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nresults &lt;- cor.test(dat$VapingQuestionnaireScore, \n                    dat$IAT_RT, \n                    method = \"pearson\") %&gt;% \n  tidy()\n\nresults\n\ncorrelation &lt;- results %&gt;% \n  pull(estimate) %&gt;%\n  round(2)\n\ndf &lt;- results %&gt;% \n  pull(parameter) %&gt;%\n  round(0)\n\npvalue &lt;- results %&gt;% \n  pull(p.value) %&gt;%\n  round(3)\n\n\n\nQuestion 6b Is the correlation significant?\n\nStep 7. Write a few sentences in which you report this result, following APA guidelines. Make sure to include the r, df, p-value and an interpretation.\n\n\nStep 8. Intercorrelations. Finally, let’s check whether either implicit or explicit attitude is associated with age. First, let’s create a new data frame that only includes the relevant variables. Look closely at each line of code below and check you understand what it does. Don’t forget to copy the code below to your script and run it.\n\n\ndat_matrix &lt;- dat %&gt;%\n  select(Age, IAT_RT, VapingQuestionnaireScore) %&gt;%\n  as.data.frame() # Make sure tell R that dat is a data frame\n\n\nNow, create a matrix of scatterplots.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the pairs() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\npairs(dat_matrix)\n\n\n\n\nQuestion 8a What do you conclude from the scatterplots?\n\nFinally, conduct intercorrelation (multiple correlations).\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the correlate() function. Do you need Pearson’s r or Spearman’s rho? Have you adjusted for multiple comparisons?\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nintercor_results &lt;- correlate(x = dat_matrix, # our data\n                          test = TRUE, # compute p-values\n                          corr.method = \"spearman\", # run a spearman test \n                          p.adjust.method = \"bonferroni\") # use the bonferroni correction\nintercor_results\n\n\n\n\nQuestion 8b What do you conclude from the results of the correlation analysis?",
    "crumbs": [
      "Home",
      "PSYC122",
      "2. Week 12 - Correlation Part 2"
    ]
  },
  {
    "objectID": "PSYC122/Week12.html#answers",
    "href": "PSYC122/Week12.html#answers",
    "title": "2. Week 12 - Correlation Part 2",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\n\nLab activity 1\n\nCorrelation would be an appropriate form on analysis for researchers interested in the relationship between\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nDog (breed) and height (cm) of owner\nSpeed of swimming (mph) and area of tank (cm)\nNumber of cows sitting and rain fall (mm)\nTotal llama saliva (ml) expelled and gender of visitors\nb and d\n\nf. b and c All variables in b anc c are continuous. Dog breed and gender are categorical.\n\n\n\n\nWhen would you use Spearman’s rho analysis instead of Pearson’s r?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nb. When the data is not normally distributed\n\n\n\n\nUsing the histograms and qq-plots below, which of these variables satisfies the normality assumption? Explain your answers.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nVocabulary. Only for vocabulary does the histogram resemble a bell curve and do the data-points in the qq-plot fall within the dashed blue lines.\n\n\n\n\nWhy should correlation analysis not be conducted on variables with a curvilinear relationship?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMay be subject to a type 2 error - there actually is a relationship between variables yet we reject the null hypothesis. As the relationship is not linear, correlation analysis will not identify this.\n\n\n\n\n\nLab activity 2\nYou can download the R-Markdown script that contains the code to complete lab activity 2 here: 122_wk12_labAct2.R.\nQuestion 2a. For how many participants do we have data?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are 166 observations, so we have data for 166 participants. You can see this in the Environment window in the top right. This does not tell us whether any of these participants have any missing data.\n\n\n\nQuestion 3a. For how many participants do we have data now that we have cleaned them up?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n104 participants\n\n\n\nQuestion 3b. Use the information in the background description to understand how the scores relate to attitudes. What does a positive IAT_RT score reflect?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nPeople with a positive IAT_RT are considered to hold the implicit view that vaping is negative (i.e. congruent associations are quicker than incongruent associations).\n\n\n\nWhat does a negative IAT_RT score reflect?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\nPeople with a negative IAT_RT are considered to hold the implicit view that vaping is positive (i.e. incongruent associations were quicker than congruent associations). :::\nWhat does a higher score on the ‘VapingQuestionnaireScore’ mean?\n::: {.callout-note icon=false collapse=“true”} ## Answer ::: Higher scores indicated a positive explicit attitude towards vaping. :::\nQuestion 4a. Why might these averages be useful? Why are averages not always useful in correlations?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIt is always worth thinking about which averages are informative and which are not. Knowing the average explicit attitude towards vaping could well be informative. In contrast, if you are using an ordinal scale and people use the whole of the scale then the average may just tell you the middle of the scale you are using - which you already know and really isn’t that informative. So it is always worth thinking about what your descriptives are calculating.\n\n\n\nQuestion 5a. What are the variable types for the implicit (IAT_RT) and the explicit (VapingQuestionnaireScore) attitude variables?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBoth can be considered continuous variables and at least at interval level.\n\n\n\nQuestion 5b. How many people had missing data?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBefore we removed participants with missing data, we had 104 observations, now we have 96. So there must have been 8 participants without a score on one or the other variable.\n\n\n\nQuestion 5c. What do you conclude from the histograms and the qq-plots? Are the VapingQuestionnaireScore and the IAT_RT normally distributed?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes. Both histograms resemble a normal distribution (bell curve) and the open circles in the qq-plots fall within the blue stripy lines.\n\n\n\nQuestion 5d. What do you conclude from the scatterplot in terms of the homoscedasticity of the data and the linearity, direction and strength of the relationship? What does the scatterplot tell you about possible issues (outliers, range restrictions)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe data look like a cloud without a clear direction. This suggests the relationship might might be weak. In terms of linearity, the scatterplot doesn’t suggest any curvilinear relationships. Variance seems quite constant, but there do seem to be few people with negative IAT_RT (Implicit attitude) scores, suggesting few people held the view that vaping is positive.\n\n\n\nQuestion 6a. Do you need to calculate Pearson’s r or Spearman’s rho?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nPearson’s r because the data do meet the assumptions.\n\n\n\nQuestion 6b. Is the correlation significant?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNo, p = .822, which is larger than .05.\n\n\n\nWrite a few sentences in which you report this result, following APA guidelines. Make sure to include the r, df, p-value and an interpretation.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTesting the hypothesis of a relationship between implicit and explicit attitudes towards vaping, a Pearson correlation found no significant relationship between IAT reaction times (implicit attitude) and answers on a Vaping Questionnaire (explicit attitude), r(94) = -.02, p = .822. Overall this suggests that there is no direct relationship between implicit and explicit attitudes with regard to vaping and as such our hypothesis was not supported; we cannot reject the null hypothesis.\n\n\n\nQuestion 8a. What do you conclude from the scatterplots?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe scatterplots with age suggest that age is highly skewed with only a few participants older than 25. For now, let’s say we’ll therefore calculate Spearman’s rho, rather than Pearson’s r. That is ok for now, but if you were analysing these data for a research project, you’d want to have a closer look at the age variable (think histogram, qq-plot, and think about either collecting more data from older participants or transforming the variable (more about that next year).\n\n\n\nQuestion 8b. What do you conclude from the results of the correlation analysis?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNo significant correlation with age was found.",
    "crumbs": [
      "Home",
      "PSYC122",
      "2. Week 12 - Correlation Part 2"
    ]
  },
  {
    "objectID": "PSYC122/Week12.html#online-qa",
    "href": "PSYC122/Week12.html#online-qa",
    "title": "2. Week 12 - Correlation Part 2",
    "section": "Online Q&A",
    "text": "Online Q&A\nBelow is the recording of this week’s online Q&A.\n\nTranscript",
    "crumbs": [
      "Home",
      "PSYC122",
      "2. Week 12 - Correlation Part 2"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html",
    "href": "PSYC122/Week11.html",
    "title": "1. Week 11 - Correlation",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.\nToday we will take a look at correlation as a measure of association between two numerical variables. We will create scatterplots to visualise correlations, we will run a correlation analysis and we will practise interpreting and reporting the results.",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-lectures",
    "href": "PSYC122/Week11.html#sec-wk11-lectures",
    "title": "1. Week 11 - Correlation",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material comes in two parts.\n\nTheory(~30 minutes) Watch this part before you complete the reading and the pre-lab activities. The video has captions, in case you find that helpful. You can download the slides and a transcript from the links below the video. Finally, if you open the video in ‘eStream’ by clicking on the green ‘e’ in the bottom right, you can navigate to separate sections of the video by clicking on the ‘chapters’ pane. This might be particularly useful if you quickly want to revisit a particular section.\n\n\nSlides Transcript\n\nHow to(~13 minutes) Watch this part after you’ve completed the pre-lab activities and before you attend the lab session.\n\n\nSlides Transcript",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-reading",
    "href": "PSYC122/Week11.html#sec-wk11-reading",
    "title": "1. Week 11 - Correlation",
    "section": "Reading",
    "text": "Reading\nThe reading that accompanies the lectures this week and next week is from chapter 9 of the core text by Howell (2017).\nRougly, this week we’ll cover the material in sections 9.1 to 9.4, as well as sections 9.8 to 9.11 and section 9.15. Next week, we’ll cover the material in sections 9.5 to 9.7, and sections 9.12 to 9.13. Even if a section is not mentioned here, all of chapter 9 is relevant.",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-prelab-activities",
    "href": "PSYC122/Week11.html#sec-wk11-prelab-activities",
    "title": "1. Week 11 - Correlation",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures on correlation and read the textbook sections you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Visualing correlations\nHave a look at this visualisation of correlations by Kristoffer Magnusson.\nAfter having read the relevant sections of Howell (2017) Chapter 9, use this visualisation page to visually replicate the scatterplots in Figures 9.1 and 9.2 - use a sample of 100. After that, visually replicate the scatterplots in Figure 9.3.\nEach time you change the correlation, pay attention to the shared variance (the overlap between the two variables) and see how this changes with the changing level of relationship between the two variables. The greater the shared variance, the stronger the relationship.\nAlso, try setting the correlation to r = .5 and then moving a single dot to see how one data point, a potential outlier, can change the stated correlation value between two variables.\n\n\nPre-lab activity 2: Guess the correlation\nNow that you are well versed in interpreting scatterplots (scattergrams) have a go at this online app on guessing the correlation.\nThis is a very basic app that allows you to see how good you are at recognising different correlation strengths from the scatterplots. We would recommend you click the “Track Performance” tab so you can keep an overview of your overall bias to underestimate or overestimate a correlation.\nIs this all just a bit of fun? Well, yes, because stats is actually fun, and no, because it serves a purpose of helping you determine if the correlations you see in your own data are real, and to help you see if correlations in published research match with what you are being told. As you will have seen from the above examples, one data point can lead to a misleading relationship and even what might be considered a medium to strong relationship may actually have only limited relevance in the real world. One only needs to mention Anscombe’s Quartet to be reminded of the importance of visualising your data, which leads us to the final pre-lab activity for this week.\n\n\nPre-lab activity 3: Anscombe’s quartet\nAnscombe (1973) showed that four sets of bivariate data (X, Y) that have the exact same means, medians, and relationships can look very different when plotted. You can read more about this here.\nAll in this is a clear example of why you should visualise your data and not to rely on just the numbers.\n\n\nPre-lab activity 4: Getting ready for the lab class\n\nRemind yourself of the basics of how to work with RStudio and get your files ready\nYou might want to re-visit the materials that John and Tom provided in PSYC121:\n\nBasics of working with RStudio\nCreate a folder for Week 11.\nDownload the 122_week11_forStudents.zip file and upload it into the new folder in RStudio Server you created at the previous step.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below.\n\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/122_week11_forStudents/exams.csv?raw=true\", destfile = \"exams.csv\")",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-labactivities",
    "href": "PSYC122/Week11.html#sec-wk11-labactivities",
    "title": "1. Week 11 - Correlation",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nconstructing and interpreting scatterplots\nrunning correlation analysis and interpret the results\nreporting the results in APA format\nconstructing a correlation matrix in APA format\nwhen and why to apply correlation analysis to answers questions in psychological science\n\n\nLab activity 1: Interpreting correlation\n\nQuestion 1\nBelow are scatterplots that show the relationship between ‘how much you know about correlation and how attractive you appear to members of the opposite (&/or same) sex’. Choose the type of correlation (strength and direction) displayed in each graph using one of the following:\n\nPerfect positive correlation\nPerfect negative correlation\nStrong positive correlation\nStrong negative correlation\nModerate positive correlation\nModerate negative correlation\nNull correlation\n\nFigure A \nFigure B \nFigure C \nFigure D \n\n\n\n\n\n\nNote\n\n\n\nFor the following questions, explain your chosen answer based on the statistic given, not on why you think the correlation may or may note make ‘logical’ sense.\n\n\n\n\nQuestion 2\nSuppose it was observed that there is a correlation of r = -.81 between a driver’s age and the cost of car insurance. This correlation would mean that, in general, older people pay more for car insurance.\nTRUE or FALSE? Explain why.\n\n\nQuestion 3\nSuppose that there is a correlation of r = .87 between the length of time a person is in prison and the amount of aggression the person displays on a psychological inventory administered at release. This means that spending a longer amount of time in prison causes people to become more aggressive.\nTRUE or FALSE? Explain why.\n\n\nQuestion 4\nA significant correlation was found between having great hair and performance in correlation labs. The correlation coefficient was .7. How much variance in correlation lab performance can the ‘greatness’ of your hair explain?\n\n51%\n70%\n49%\n30%\nWho cares I’ve got great hair.\n\nWhat was the reason for your answer?\nWhat is this ‘new coefficient’ called?\n\n\n\nLab activity 2: Visualising, calculating and reporting correlations\n\n\n\n\n\n\nWatch the ‘How to’ video\n\n\n\nIf you haven’t done so already, this is a good time to watch the ‘How to’ video (here Section 1) on ‘How to conduct a correlation analysis using R’.\n\n\nGoing back to the data discussed in the ‘How to’ video (see Section 1), you’ll remember it contains data from 25 8-year-old children on:\n\na standardised test of reading ability (Abil)\nintelligence (IQ)\nthe number of minutes per week spent reading in the home (Home)\nand the number of minutes per week spent watching TV (TV)\n\nIn the video on ‘How to conduct correlation analysis using R’ we looked at the correlation between reading ability and intelligence. Now, let’s look at the correlation between number of minutes per week spent reading in the home and watching TV.\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 4: Getting ready for the lab class’ contains the datafile (“MillerHadenData.csv”). Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nDo this if you couldn’t upload files to the server\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/MillerHadenData.csv?raw=true\", destfile = \"MillerHadenData.csv\")\n\n\n\n\n\n\n\nNew R Markdown script\n\n\n\nBefore we begin, make sure you have started a new R Markdown script. If you need a reminder of how to do that, please revisit week 6 of PSYC121 (here).\n\n\n\nStep 1. Add the code to load the broom and the tidyverse libraries in a new code chunk. If you are unsure, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library()function. Remember to put it inside a ‘code chunk’ in your R Markdown script.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(tidyverse)\n\n\n\n\nStep 2. Read in the data. You should now see a dataframe with 25 observations and 5 variables in the ‘Environment’. Click on it to view it.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nmh &lt;- read_csv(\"MillerHadenData.csv\")\n\n\n\n\nStep 3. Construct a scatterplot of the relationship between ‘Home’ and ‘TV’. Also add a line of best fit and make sure you use clear labels for your axes.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the ggplot()function in combination with geom_point() and geom_smooth(). Make sure you use clear labels for your axes by using labs().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variable names. Also add clear labels for your axes.\nggplot(DATA, aes(x = , y = )) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"\", y = \"\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nggplot(mh, aes(x = Home, y = TV)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Time spend reading at home\", y = \"Time spend watching TV at home\")\n\n\n\nQuestion 3a: What can you tell from the scatterplot about the direction of the relationship? Write a few sentences in your R Markdown script to describe the relationship.\n\nStep 4. Conduct the correlation analysis.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the cor.test()function in combination with tidy().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variables names.\nresults &lt;- cor.test(DATA$X, \n                    DATA$Y, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nresults &lt;- cor.test(mh$Home, \n                    mh$TV, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\nOnce you’ve run this code chunk, the output should appear in your R Markdown script and you can answer the questions below using that output. You can also pull out the different pieces of information by using the pull() function and round the values using the round() function, like this:\nr &lt;- results %&gt;%\n  pull(estimate) %&gt;%\n  round(2)\nQuestion 4a: What is the correlation coefficient (Pearson’s r)?\nQuestion 4b: What is the p value?\nQuestion 4c: Is the correlation significant at the p &lt; .05 level?\nQuestion 4d: What are the degrees of freedom you need to report?\n\nStep 5. Calculate how much variance in ‘time spent reading’ can be accounted for by ‘time spent watching TV’?\n\nAs discussed in the theory lecture, this is referred to as the ‘coefficient of determination’ or ‘R-squared’. To calculate it, you square the value for Pearson’s r. To calculate how much variance in one variable is accounted for by the other variable, you multiply it by 100 and round it to 0 decimals.\n\nStep 6. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\nLab activity 3: Hazardous alcohol use and impulsivity\nResearchers were interested in the relationship between hazardous alcohol use and impulsivity (making unplanned, rapid decisions without thinking or ‘acting on a whim’). To investigate the relationship, 20 participants completed both the alcohol use disorder identification test (AUDIT; Saunders, Aasland, Babor, de la Fuente, & Grant, 1993) and Barratt’s Impulsiveness Scale (BIS-11) (Patton, Stanford, & Barratt, 1995).\n\n\n\n\n\n\nBefore we begin\n\n\n\nAssuming you are using the same R Markdown script as for the previous lab activity, you should already have code to load the broom and the tidyverse libraries. If this is a new session, you just need to re-run that code chunk to ensure they are loaded. At this point, it is a good idea to clear your environment to avoid any confusion between data frames or values. You can do this by clicking on the broom icon on the top right of the Environment pane. The data file (“alcoholUse_Impulsivity.csv”) is in the folder you were asked to download under ‘Pre-lab activity 4: Getting ready for the lab class’. As long as that folder is set as your working directory, you are good to go.\n\n\n\n\n\n\n\n\nDo this if you couldn’t upload files to the server\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/122_week11_forStudents/alcoholUse_Impulsivity.csv?raw=true\", destfile = \"alcoholUse_Impulsivity.csv\")\n\n\nStep 1. Read in the data. You should now see an object containing the data in the ‘Environment’.\n\nQuestion 1a: How many variables does it have?\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\ndata &lt;- read_csv(\"alcoholUse_Impulsivity.csv\")\n\n\n\n\nStep 2. Plot the relationship between hazard alcohol use and impulsivity using a scatterplot and a line of best fit\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the ggplot()function in combination with geom_point() and geom_smooth(). Make sure you use clear labels for your axes by using labs().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nUse this code template and add the name of the data frame and the variables. Also add informative labels for your axes.\nggplot(, aes(x = , y = )) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"\", y = \"\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below\nggplot(data, aes(x = hau, y = imp)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Hazardous Alcohol Use\", y = \"Impulsivity\")\n\n\n\nQuestion 2a: What can you tell from the scatterplot about the direction of the relationship?\n\nStep 3. Conduct the correlation analysis.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the cor.test()function in combination with tidy().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variables names.\nresults &lt;- cor.test(DATA$X, \n                    DATA$Y, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nresults &lt;- cor.test(data$hau, \n                    data$imp, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\n\nresults\n\n\n\nQuestion 3a: What is the correlation coefficient (Pearson’s r)?\nQuestion 3b: What is the p value?\nQuestion 3c: Is the correlation significant at the p &lt; .05 level?\nQuestion 3d: What are the degrees of freedom you need to report?\nQuestion 3e: How much variance in ‘impulsivity’ can be accounted for by ‘hazardous alcohol use’?\nQuestion 3f: Give three logically possible directions of causality, indicating for each direction whether it is a plausible explanation in light of the variables involved (and why). No, this is not a trick question —-I know that correlation does not infer causation, but think critically! New studies/ideas are constructed by thinking what the previous study doesn’t tell us about what could be happening with the variables of interest.\n\nStep 4. Write a few sentences in which you report this result, following APA guidelines.\n\nJob completed — Well done!",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#answers",
    "href": "PSYC122/Week11.html#answers",
    "title": "1. Week 11 - Correlation",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at code written by someone else…\n\n\nLab activity 1: Interpreting correlation\n\nBelow are scatterplots that show the relationship between ‘how much you know about correlation and how attractive you appear to members of the opposite (&/or same) sex’. Choose the type of correlation (strength and direction) displayed in each graph.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nstrong positive correlation\nnull correlation\nmoderate positive correlation\nperfect negative correlation\n\n\n\n\n\nSuppose it was observed that there is a correlation of r = -.81 between a driver’s age and the cost of car insurance. This correlation would mean that, in general, older people pay more for car insurance.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFALSE Explanation: The correlation coefficient is negative and therefore infers a negative correlation. As such, older people pay less for car insurance: as age increases, car insurance costs decrease.\n\n\n\n\nSuppose that there is a correlation of r = .87 between the length of time a person is in prison and the amount of aggression the person displays on a psychological inventory administered at release. This means that spending a longer amount of time in prison causes people to become more aggressive.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFALSE Explanation: This is a bit of trick question as it has the sneaky ‘cause’ word in. The correlation coefficient is a positive number, suggesting a positive relationship between length of time in prison and aggression. However, causation cannot be inferred from correlation and therefore we cannot know whether time spent in prison CAUSES aggression, and rather we suggest a relationship between the two: as length of time in prison increases, aggression increases.\n\n\n\n\nA significant correlation was found between having great hair and performance in correlation labs. The correlation coefficient was .7. How much variance in correlation lab performance can the ‘greatness’ of your hair explain?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nc 49% The ‘coefficient of determination’ or ‘R-squared’ tells us the proportion or variance in one variable that can be predicted if we know the other variable. We can determine this by squaring the r. Therefore, .72 = .49, R2 = .49.\n\n\n\n\n\nLab activity 2: Constructing scatterplots and calculating correlations\nYou can download the RMd-script that contains the code to complete lab activities 2 and 3 here: 122_wk11_labActivities2_3.Rmd.\nQuestion 3a: What can you tell from the scatterplot about the direction of the relationship?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is a negative association between ‘Home’ and ‘TV’. This means that the longer a child spends watching TV, the shorter they will read at home.\n\n\n\nQuestion 4a: What is the correlation coefficient (Pearson’s r)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nr = -.65\n\n\n\nQuestion 4b: What is the p value?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\np &lt; .001\n\n\n\nQuestion 4c: Is the correlation significant at the p &lt; .05 level?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes, because the p-value is smaller than .005\n\n\n\nQuestion 4d: What are the degrees of freedom you need to report?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n23\n\n\n\nStep 5. How much variance in ‘time spent reading’ can be accounted for by ‘time spent watching TV’?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n42%\n\n\n\nStep 6. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSomething along the lines of: A Pearson’s correlation coefficient was used to assess the relationship between time spent reading at home and time spent watching TV at home. There was a significant negative correlation, r(23) = -.65, p &lt; .001. As time spent watching TV increased, time spent reading at home decreased.\n\n\n\n\n\nLab activity 3: Hazardous alcohol use and impulsivity\nQuestion 1a: How many variables does it have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n3\n\n\n\nQuestion 2a: What can you tell from the scatterplot about the direction of the relationship?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is a positive association between ‘hazardous alcohol use’ and ‘impulsivity’. This means that as a participant’s score on ‘hazardous alcohol use’ goes up, their score on ‘impulsivity’ also goes up.\n\n\n\nQuestion 3a: What is the correlation coefficient (Pearson’s r)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nr = .54\n\n\n\nQuestion 3b: What is the p value?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\np = .014\n\n\n\nQuestion 3c: Is the correlation significant at the p &lt; .05 level?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes\n\n\n\nQuestion 3d: What are the degrees of freedom you need to report?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n18\n\n\n\nQuestion 3e: How much variance in ‘impulsivity’ can be accounted for by ‘hazardous alcohol use’?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n29%\n\n\n\nQuestion 3f:. Give three logically possible directions of causality, indicating for each direction whether it is a plausible explanation in light of the variables involved (and why). No, this is not a trick question —-I know that correlation does not infer causation, but think critically! New studies/ideas are constructed by thinking what the previous study doesn’t tell us about what could be happening with the variables of interest.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nJust really looking for reasoning here.\nExamples:\n\nBeing more impulsive may make people consume more alcohol.\nConsuming more alcohol may make people more impulsive.\nAn outgoing personality might influence both your level of impulsivity and you are more likely to be socialising in the pub and consuming alcohol. So the same ‘third factor’ may influence both our variables of interest.\n\n\n\n\nStep 4. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSomething along the lines of: A Pearson’s correlation coefficient was used to assess the relationship between alcohol use and impulsivity. There was a significant positive correlation, r(18) = .54, p &lt; .014. People who reported to consume more alcohol, scored higher on the impulsivity scale.",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/Week11.html#online-qa",
    "href": "PSYC122/Week11.html#online-qa",
    "title": "1. Week 11 - Correlation",
    "section": "Online Q&A",
    "text": "Online Q&A\nBelow is the recording of this week’s online Q&A.\n\nTranscript",
    "crumbs": [
      "Home",
      "PSYC122",
      "1. Week 11 - Correlation"
    ]
  },
  {
    "objectID": "PSYC122/data/week14/122_wk14_labAct2.html",
    "href": "PSYC122/data/week14/122_wk14_labAct2.html",
    "title": "122_wk13_labActivity2",
    "section": "",
    "text": "Aim: What we want to do is to run a chi-square analysis to determine whether those in the RTA condition were more likely to remember to return the paper-clips than those in the control condition."
  },
  {
    "objectID": "PSYC122/data/week14/122_wk14_labAct2.html#lab-activity-2---reminders-through-association",
    "href": "PSYC122/data/week14/122_wk14_labAct2.html#lab-activity-2---reminders-through-association",
    "title": "122_wk13_labActivity2",
    "section": "",
    "text": "Aim: What we want to do is to run a chi-square analysis to determine whether those in the RTA condition were more likely to remember to return the paper-clips than those in the control condition."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "",
    "text": "In Week 19, we aim to further develop skills in working with the linear model.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nIn this class, what is new is our focus on critically evaluating – comparing, reflecting on – the evidence from more than one relevant study.\n\nThis work simulates the kind of critical evaluation of evidence that psychologists must do in professional research.\n\n\n\nI will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this how-to guide, we use data from two 2020 studies of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nThe reason we are going to work with two datasets is that we will be comparing the results of analyses of the data to assess whether the results are robust.\nHere, our assessment of robustness focuses on whether similar results are found in two different studies.\nCheck out the PSYC122 Week 19 lecture for a discussion of how an assessment of robustness is important to psychological science."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#naming-things",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#naming-things",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-one-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "",
    "text": "In this how-to guide, we use data from two 2020 studies of the response of adults from a UK national sample to written health information:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nThe reason we are going to work with two datasets is that we will be comparing the results of analyses of the data to assess whether the results are robust.\nHere, our assessment of robustness focuses on whether similar results are found in two different studies.\nCheck out the PSYC122 Week 19 lecture for a discussion of how an assessment of robustness is important to psychological science."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-1-set-up",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-1-set-up",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"ggeffects\")\n\nWarning: package 'ggeffects' was built under R version 4.2.3\n\nlibrary(\"patchwork\")\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-2-load-the-data",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data files we will be using\nThe data files are called:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data files into R:\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")  \n\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")  \n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data files in, give the data objects you create distinct name e.g. study.one.gen versus study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look at both datasets.\n\nsummary(study.one.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\n\nNotice that study.two.gen was designed to be a replication of study.one.gen.\n\nWe use the same online survey methods to collect data in both studies.\nWe present different health information texts in the different studies and recorded responses from different groups of adults in the UK."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-3-compare-the-data-from-the-different-studies",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-3-compare-the-data-from-the-different-studies",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 3: Compare the data from the different studies",
    "text": "Step 3: Compare the data from the different studies\n\nRevise: practice to strengthen skills\n\n\nTask 5 – Compare the data distributions from the two studies\n\nQ.1. What is the mean of the mean.acc and SHIPLEY variables in the two studies?\nA.1. The means are:\nstudy one – mean.acc – mean = 0.8163\nstudy one – mean.self – mean = 6.906\nstudy two – mean.acc – mean = 0.7596\nstudy two – mean.self – mean = 7.101\nQ.2. Draw histograms of both mean.acc and mean.self for both studies.\nA.2. You can write the code as you have been shown to do e.g. in 2023-24-PSYC122-w17-how-to.Rmd:\n\n\nggplot(data = study.one.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.one.gen, aes(x = mean.self)) + \n  geom_histogram(binwidth = 1) +\n  theme_bw() +\n  labs(x = \"Mean self-rated accuracy (mean.self)\", y = \"frequency count\") +\n  xlim(0,10)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = mean.self)) + \n  geom_histogram(binwidth = 1) +\n  theme_bw() +\n  labs(x = \"Mean self-rated accuracy (mean.self)\", y = \"frequency count\") +\n  xlim(0,10)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\n\nTask 6 – Create grids of plots to make the comparison easier to do\n\n\nhint: Task 6 – What we are going to do is to create two histograms and then present them side by side to allow easy comparison of variable distributions\nWe need to make two changes to the coding approach you have been using until now.\nBefore we explain anything, let’s look at an example: run these line of code and check the result.\n\nMake sure you identify what is different about the plotting code, shown following, compared to what you have done before: there is a surprise in what is going to happen.\n\nFirst, create plot objects, give them names, but do not show them:\n\nplot.one &lt;- ggplot(data = study.one.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study One\") +\n  xlim(0, 1)\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study Two\") +\n  xlim(0, 1)\n\nSecond, show the plots, side-by-side:\n\nplot.one + plot.two\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nThis is what you are doing: check out the process, step-by-step. (And notice that you repeat the process for each of two (or more) plots.)\n\nggplot(...) tell R you want to make a plot using the ggplot() function;\nplot.one &lt;- tell R you want to give the plot a name; the name appears in the environment;\nggplot(data = study.one.gen ...) tell R you want to make a plot with the study.two data;\nggplot(..., aes(x = mean.acc)) tell R that you want to make a plot with the variable mean.acc;\n\n\nhere, specify the aesthetic mapping, x = mean.acc\n\n\ngeom_histogram() tell R you want to plot values of mean.acc as a histogram;\nbinwidth = .1 adjust the binwidth to show enough detail but not too much in the distribution;\ntheme_bw() tell R what theme you want, adjusting the plot appearance;\nlabs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study One\") fix the x-axis and y-axis labels;\n\n\nhere, add a title for the plot, so you can tell the two plots apart;\n\n\nxlim(0, 1) adjust the x-axis limits to show the full range of possible score values on this variable.\n\nDo this process twice, once for each dataset, creating two plots so that you can compare the distribution of mean.acc scores between the studies.\nFinally, having created the two plots, produce them for viewing:\n\nplot.one + plot.two having constructed – and named – both plots, you enter their names, separated by a +, to show them in a grid of two plots.\n\nNotice: until you get to step 10, nothing will appear.\nThis will be surprising but it is perfectly normal when we increase the level of complexity of the plots we build.\n\nYou first build the plots.\nYou are creating plot objects and you give these objects names.\nThe objects will appear in the Environment with the names you give them.\nYou then produce the plots for viewing, by using their names.\n\nUntil you complete the last step, you will not see any changes until you use the object names to produce them for viewing.\nThis is how you construct complex arrays of plots.\n\n\nTask 7 – Try this out for yourself, focusing now on the distribution of mean.self scores in the two studies\nFirst, create plot objects but do not show them.\n\nGive each plot a name. You will use the names next.\n\n\nplot.one &lt;- ggplot(data = study.one.gen, aes(x = mean.self)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Self-rated accuracy (mean.self)\", y = \"frequency count\", title = \"Study One\") +\n  xlim(0, 10)\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = mean.self)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Self-rated accuracy (mean.self)\", y = \"frequency count\", title = \"Study Two\") +\n  xlim(0, 10)\n\nSecond produce the plots for viewing, side-by-side, by naming them.\n\nplot.one + plot.two\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nQ.3. Now use the plots to do some data analysis work: how do the mean.self distributions compare, when you compare the mean.self of study.one.gen versus `mean.self of study.two.gen?\nA.3. When you compare the plots side-by-side you can see that the mean.self distributions are similar in the two studies: most people have high mean.self scores. This means that they rated the accuracy of their understanding at a high level, on average.\nQ.4. Is the visual impression you get from comparing the distributions consistent with the statistics you see in the summary?\nA.4. Yes: If you go back to the summary of mean.self, comparing the two studies datasets, then you can see that the median and mean are similar (around 7) in both study.one.gen and study.two.gen datasets."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-4-now-use-scatterplots-and-correlation-to-examine-associations-between-variables",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-4-now-use-scatterplots-and-correlation-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 4: Now use scatterplots and correlation to examine associations between variables",
    "text": "Step 4: Now use scatterplots and correlation to examine associations between variables\n\nRevise: practice to strengthen skills\n\n\nTask 8 – Draw scatterplots to compare the potential association between mean.acc and mean.self in both study.one.gen and study.two.gen datasets\n\n\nhint: Task 8 – The plotting steps are explained in some detail in 2023-24-PSYC122-w17-how-to.Rmd\n\nggplot(data = study.one.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nTask 9 – Create a grid of plots to make the comparison easier to do\n\n\nhint: Task 9 – We follow the same steps as we used in tasks 6 and 7 to create the plots\nWe again:\n\nFirst construct the plot objects and give them names;\nThen create and show a grid of named plots.\n\nThough this time we are producing a grid of scatterplots.\nFirst, create plot objects – give them names but do not show them:\n\nplot.one &lt;- ggplot(data = study.one.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\", title = \"Study One\") +\n  xlim(0, 10) + ylim(0, 1)\n\nplot.two &lt;- ggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\", title = \"Study Two\") +\n  xlim(0, 10) + ylim(0, 1)\n\n\nNotice that in the plotting code we ask R to give each plot a title using labs().\n\nSecond name the plots, to show them side-by-side in the plot window:\n\nplot.one + plot.two\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNow use the plots to make comparison judgments.\n\nQ.5. How does the association, shown in the plots, between mean.self and mean.acc compare when you look at the study.one.gen versus the study.two.gen plot?\nhint: Q.5. When comparing evidence about associations in different studies, we are mostly going to focus on the slope – the angle – of the prediction lines, and the ways in which points do or do not cluster about the prediction lines.\nA.5. If you examine the study.one.gen versus the study.two.gen plots then you can see that in both plots higher mean.self scores appear to be associated with higher mean.acc scores. But the trend maybe is a bit stronger – the line is steeper – in study.two.gen compared to study.two.gen.\n\nWe are now in a position to answer one of our research questions:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nIf people can accurately evaluate whether they correctly understand written health information then mean.self (a score representing their evaluation) should be associated with mean.acc (a score representing their accuracy of understanding) for each person.\n\n\nRevise: practice to strengthen skills\n\n\nTask 10 – Can you estimate the association between mean.acc and mean.self in both datasets?\n\n\nhint: Task 10 – Use cor.test() as you have been shown how to do e.g. in 2023-24-PSYC122-w16-how-to.Rmd\nDo the correlation for both datasets.\nFirst, look at the correlation between mean.acc and mean.self in study.one.gen:\n\ncor.test(study.one.gen$mean.acc, study.one.gen$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one.gen$mean.acc and study.one.gen$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\nQ.6. What is r, the correlation coefficient?\nA.6. r = 0.4863771\nQ.7. Is the correlation significant?\nA.7. r is significant\nQ.8. What are the values for t and p for the significance test for the correlation?\nA.8. t = 7.1936, p-value = 2.026e-11\n\nSecond, look at the correlation between mean.acc and mean.self in study.two.gen:\n\ncor.test(study.two.gen$mean.acc, study.two.gen$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$mean.acc and study.two.gen$mean.self\nt = 8.4991, df = 170, p-value = 9.356e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4317217 0.6431596\nsample estimates:\n      cor \n0.5460792 \n\n\n\nQ.9. What is r, the correlation coefficient?\nA.9. r = 0.5460792\nQ.10. Is the correlation significant?\nA.10. r is significant\nQ.11. What are the values for t and p for the significance test for the correlation?\nA.11. t = 8.4991, p = 9.356e-15\n\nNow we can answer the research question:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nQ.12. What do the correlation estimates tell you is the answer to the research question?\nA.12.\n\n\nThe correlations are positive and significant, indicating that higher mean.self (evaluations) are associated with higher mean.acc (understanding), suggesting that people can judge their accuracy of understanding.\n\n\nQ.13. Can you compare the estimates, given the two datasets, to evaluate if the result in study.one.gen is replicated in study.two.gen?\nhint: Q.13. We can judge if the result in a study is replicated in another study by examining if – here – the correlation coefficient is significant in both studies and if the coefficient has the same size and sign in both studies.\nA.13. If you compare the correlation estimates from both study.one.gen and study.two.gen you can see:\nfirst, the correlation is significant in both studies;\nsecond, the correlation is positive in both studies,\nthird, the correlation is similar in magnitude, about \\(r = .5\\) in both studies.\n\nThis suggests that the association we see in study.one.gen is replicated in study.two.gen."
  },
  {
    "objectID": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-5-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "href": "PSYC122/data/week19/2023-24-PSYC122-w19-how-to.html#step-5-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "title": "2023-24-PSYC122-w19-how-to",
    "section": "Step 5: Use a linear model to to answer the research questions – multiple predictors",
    "text": "Step 5: Use a linear model to to answer the research questions – multiple predictors\n\nRevise: practice to strengthen skills\n\n\nTask 11 – Examine the relation between outcome mean accuracy (mean.acc) and multiple predictors\nWe specify linear models including as predictors the variables:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nreading strategy (FACTOR3).\n\n\n\nhint: Task 11 – Use lm(), as you have done before, see e.g. 2023-24-PSYC122-w18-how-to.R\n\n\nTask 11 – Examine the predictors of mean accuracy (mean.acc), first, for the study.one.gen data\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40322 -0.05349  0.01152  0.07128  0.18434 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.302030   0.091257   3.310  0.00115 ** \nHLVA        0.017732   0.003923   4.521 1.17e-05 ***\nSHIPLEY     0.005363   0.002336   2.296  0.02291 *  \nFACTOR3     0.003355   0.001264   2.654  0.00872 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1033 on 165 degrees of freedom\nMultiple R-squared:  0.2474,    Adjusted R-squared:  0.2337 \nF-statistic: 18.08 on 3 and 165 DF,  p-value: 3.423e-10\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:\n\nQ.14. What is the estimate for the coefficient of the effect of the predictor SHIPLEY in this model?\nA.14. 0.005363\nQ.15. Is the effect significant?\nA.15. It is significant, p &lt; .05\nQ.16. What are the values for t and p for the significance test for the coefficient?\nA.16. t = 2.296, p = 0.02291\nQ.17. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.one.gen data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.17. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\nA.17.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 165) = 18.08, p &lt; .001, and explains 23% of variance (adjusted R2 = 0.23). Mean accuracy was predicted to be higher given higher scores in health literacy (HLVA estimate = .018, t = 4.52, p &lt; .001), vocabulary knowledge (SHIPLEY estimate = .005, t = 2.96, p &lt; .001), and reading strategy (FACTOR3 estimate = .003, t = 2.65, p = .009).\n\n\n\nTask 12 – Examine the predictors of mean accuracy (mean.acc), now, for the study.two.gen data\n\nmodel &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,    Adjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: &lt; 2.2e-16\n\n\nUsing the model estimates, we can answer the research question:\n\nWhat person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:\n\nQ.18. What is the estimate for the coefficient of the effect of the predictor, SHIPLEY, in this model?\nA.18. 0.008397\nQ.19. Is the effect significant?\nA.19. It is significant, p &lt; .05\nQ.20. What are the values for t and p for the significance test for the coefficient?\nA.20. t = 4.533, p = 1.1e-05\nQ.21. Now consider the estimates for all the variables, what do you conclude is the answer to the research question – given the study.two.gen data:\n\n\nWhat person attributes predict success in understanding?\n\n\nhint: Q.21. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\nA.21.\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and health literacy (HLVA), reading strategy (FACTOR3), and vocabulary (SHIPLEY) as predictors. The model is significant overall, with F(3, 168) = 31.99, p &lt; .001, and explains 35% of variance (adjusted R2 = 0.35). Mean accuracy was predicted to be higher given higher scores in health literacy (HLVA estimate = .018, t = 4.90, p &lt; .001), vocabulary knowledge (SHIPLEY estimate = .008, t = 4.53, p &lt; .001), and reading strategy (FACTOR3 estimate = .003, t = 2.68, p = .008).\n\n\nQ.22. Are the findings from study.one.gen replicated in study.two.gen?\nhint: Q.22. We can judge if the results in an earlier study are replicated in another study by examining if – here – the linear model estimates are significant in both studies and if the coefficient estimates have the same size and sign in both studies.\nA.22. If you compare the linear model coefficient estimates from both study.one.gen and study.two.gen you can see:\nfirst, the HLVA, SHIPLEY and FACTOR3 estimates are significant in both study.one.gen and study.two.gen;\nsecond, the estimates have the same sign – positive – in both studies.\n\nThis suggests that the results we see in study.one.gen are replicated in study.two.gen.\n\nQ.23. Are there any important differences between the results of the two studies?\nhint: Q.23. You can look at the estimates but you can also use the model prediction plotting code you used before, see example code in 2022-23-PSYC122-w18-how-to.R.\nhint: Q.23. – Let’s focus on comparing the study.one.gen and study.two.gen estimates for the effect of vocabulary knowledge in both models: we can plot model predictions for comparison:\n\nFirst: fit the models – using different names for the different models:\n\nmodel.one &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\nsummary(model.one)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40322 -0.05349  0.01152  0.07128  0.18434 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.302030   0.091257   3.310  0.00115 ** \nHLVA        0.017732   0.003923   4.521 1.17e-05 ***\nSHIPLEY     0.005363   0.002336   2.296  0.02291 *  \nFACTOR3     0.003355   0.001264   2.654  0.00872 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1033 on 165 degrees of freedom\nMultiple R-squared:  0.2474,    Adjusted R-squared:  0.2337 \nF-statistic: 18.08 on 3 and 165 DF,  p-value: 3.423e-10\n\nmodel.two &lt;- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model.two)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,    Adjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: &lt; 2.2e-16\n\n\nSecond, create prediction plots for the SHIPLEY effect for each model:\n\ndat.one &lt;- ggpredict(model.one, \"SHIPLEY\")\nplot.one &lt;- plot(dat.one) + labs(title = \"Study One\")\ndat.two &lt;- ggpredict(model.two, \"SHIPLEY\")\nplot.two &lt;- plot(dat.two) + labs(title = \"Study Two\")"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "",
    "text": "In Week 17, we aim to further develop skills in visualizing and testing the associations between variables in psychological data.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like the linear model.\nWhen we do these analyses, we need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model;\nwe usually need to decide, is the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nand is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\nfocusing on how we edit ggplot() code to produce professional looking plots.\n\n\n\nI will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#naming-things",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#naming-things",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "",
    "text": "In this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-1-set-up",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-1-set-up",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-2-load-the-data",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")\n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look.\n\nhead(study.two.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studytwo.1        0.411      6.07 studyt…    26      27     6      50        9\n2 studytwo.10       0.607      8.5  studyt…    38      24     9      58       15\n3 studytwo.100      0.875      8.93 studyt…    66      40    13      60       20\n4 studytwo.101      0.964      8.5  studyt…    21      31    11      59       14\n5 studytwo.102      0.714      7.07 studyt…    74      35     7      52       18\n6 studytwo.103      0.768      5.07 studyt…    18      40    11      54       15\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\n\nEven though you have done this before, you will want to do it again, here, and pay particular attention to what you see, for the numeric variables, in the information about minimum (Min.) and maximum (Max.) values."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 3: Use histograms to examine the distributions of variables",
    "text": "Step 3: Use histograms to examine the distributions of variables\n\nRevise: practice to strengthen skills\n\n\nTask 5 – Draw histograms to examine the distributions of variables\n\n\nhint: Task 5\nUse ggplot() with geom_histogram().\nWhen we create a plot, we take things step-by-step.\nHere’s an example you have seen before: run the lines of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.two.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\nNotice that the code works the same whether we have the different bits of code on the same line or in a series of lines.\n\n\nRevise: make sure you are confident about doing these things\n\n\nTask 6 – Practice editing the appearance of a histogram plot step-by-step\nStart by constructing a basic histogram.\n\nhint: Task 6 – Choose whichever numeric variable from the study.two.gen dataset you please\n\n\nhint: Task 6 – Use the line-by-line format to break the plot code into steps\nIt will make it easier to read, and it will make it easier to add edits e.g.\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe are going to revise editing:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using `labs().\n\nThen we are going to try some new moves:\n\nSetting the x-axis limits to reflect the full range of possible scores on the x-axis variable;\nAdding annotation – here, a vertical line – indicating the sample average for a variable.\n\n\n\nQuestions: Task 6\n\nQ.1. Edit the appearance of the bars by specifying a binwidth value.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\nQ.2. Then add an edit to the appearance of the background using theme_bw().\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nQ.3. Then add an edit to the appearance of the labels using labs().\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"frequency count\")\n\n\n\n\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\nQ.4. Now add an edit by setting the x-axis limits using x.lim().\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nQ.5. Then add an edit to draw a vertical line to show the mean value of the variable you are plotting.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40) +\n  geom_vline(xintercept = mean(study.two.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nQ.6. Can you find information on how to define the limits on the x-axis and on the y-axis?\nhint: Q.6. You can see the information in this week’s how-to but try a search online for “ggplot reference xlim”.\nA.6. See ggplot reference information on setting limits here:\n\nhttps://ggplot2.tidyverse.org/reference/lims.html\n\nQ.7. Can you find information on how to a reference line?\nhint: Q.7. You can see the information in this week’s how-to but try a search online for “ggplot reference vline”.\nA.7. See ggplot reference information on setting limits here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-4-now-draw-scatterplots-to-examine-associations-between-variables",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-4-now-draw-scatterplots-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 4: Now draw scatterplots to examine associations between variables",
    "text": "Step 4: Now draw scatterplots to examine associations between variables\n\nConsolidation: should be no surprises here\n\n\nTask 7 – Create a scatterplot to examine the association between some variables\nBetween the outcome mean.acc and each of three numeric potential predictor variables SHIPLEY, HLVA and AGE.\n\nhint: Task 7 – We are working with geom_point() and you need x and y aesthetic mappings.\n\n\nhint: Task 7 – The outcome variable mean.acc has to be mapped to the y-axis using ...y = ...\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nRevise: make sure you are confident about doing these things\n\n\nTask 8 – Edit the appearance of each plot step-by-step\n\nhint: Task 8 – You may want to use the same plot appearance choices for all plots\nBecause a consistent appearance is generally neater and easier for your audience to process.\n\n\nhint: Task 8 – You can find links to reference information on options in the how-to guide\nUse the information to make the plots pleasing in appearance to you.\n\n\nhint: Task 8 – Do not be afraid to copy then paste code you re-use.\nBut be careful that things like axis values are sensible for each variable.\n\n\nQuestions: Task 8\n\nQ.8. – First, edit the appearance of the points using alpha, size, shape, and colour:\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\n\n\n\n\n\n\n\n\nQ.9. – Then edit the colour of the background using theme_bw():\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nQ.10. – Then edit the appearance of the labels using labs():\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"Age (Years)\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\nQ.11. – Then set the x-axis and y-axis limits to the minimum-maximum ranges of the variables you are plotting\nhint: Q.11. – For these plots the y-axis limits will be the same because the outcome stays the same\nhint: Q.11. – But the x-axis limits will be different for each different predictor variable\nhint: Q.11. – The minimum value will always be 0\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\") +\n  xlim(0, 16) + ylim(0, 1)\n\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"Age (Years)\", y = \"mean accuracy\") +\n  xlim(0, 80) + ylim(0, 1)"
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-5-use-correlation-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-5-use-correlation-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 5: Use correlation to to answer the research questions",
    "text": "Step 5: Use correlation to to answer the research questions\n\nRevise: make sure you are confident about doing these things\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\nTask 9 – Examine the correlations between the outcome variable and predictor variables\n\nhint: Task 9 – We use cor.test()\n\n\nhint: Task 9 – You can look at the how-to guide for more advice\nYou need to run three separate correlations:\n\nbetween mean accuracy and SHIPLEY\nbetween mean accuracy and HLVA and\nbetween mean accuracy and AGE\n\n\ncor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$SHIPLEY and study.two.gen$mean.acc\nt = 6.8493, df = 170, p-value = 1.299e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3390103 0.5746961\nsample estimates:\n      cor \n0.4650537 \n\n\n\ncor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$HLVA and study.two.gen$mean.acc\nt = 7.5288, df = 170, p-value = 2.866e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3787626 0.6044611\nsample estimates:\n      cor \n0.5000559 \n\n\n\ncor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$AGE and study.two.gen$mean.acc\nt = 0.30121, df = 170, p-value = 0.7636\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1269774  0.1721354\nsample estimates:\n       cor \n0.02309589 \n\n\nNow use the results from the correlations to answer the following questions.\n\nQ.12. – What is r, the coefficient for the correlation between mean.acc and SHIPLEY?\nA.12. – r = 0.4650537\nQ.13. – Is the correlation between mean.acc and HLVA significant?\nA.13. – r is significant, p &lt; .05\nQ.14. – What are the values for t and p for the significance test for the correlation between mean.acc and AGE?\nA.14. – t = 0.30121, p = 0.7636\nQ.15. – For which pair of outcome-predictor variables is the correlation the largest?\nA.15. – The correlation is the largest between mean.acc and HLVA.\nQ.16. – What is the sign or direction of each of the correlations?\nA.16. – All the correlations are positive."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-6-use-a-linear-model-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-6-use-a-linear-model-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 6: Use a linear model to to answer the research questions",
    "text": "Step 6: Use a linear model to to answer the research questions\n\nIntroduce: Make some new moves\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\n\nTask 10 – Examine the relation between outcome mean accuracy (mean.acc)\nAnd each of the predictors: SHIPLEY, HLVA and AGE\n\nhint: Task 10 – Use lm()\n\n\nhint: Task 10 – Run three separate lm() analyses\nAll with mean.acc as the outcome but each with one predictor variable\n\n\nhint: Task 10 – See the how-to guide for example code\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.285771 -0.076662  0.002099  0.079416  0.257793 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.308027   0.066426   4.637 7.01e-06 ***\nSHIPLEY     0.012854   0.001877   6.849 1.30e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.107 on 170 degrees of freedom\nMultiple R-squared:  0.2163,    Adjusted R-squared:  0.2117 \nF-statistic: 46.91 on 1 and 170 DF,  p-value: 1.299e-10\n\n\n\nmodel &lt;- lm(mean.acc ~ HLVA, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27457 -0.06777  0.01474  0.08025  0.23146 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.522016   0.032544  16.040  &lt; 2e-16 ***\nHLVA        0.026207   0.003481   7.529 2.87e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1047 on 170 degrees of freedom\nMultiple R-squared:  0.2501,    Adjusted R-squared:  0.2456 \nF-statistic: 56.68 on 1 and 170 DF,  p-value: 2.866e-12\n\n\n\nmodel &lt;- lm(mean.acc ~ AGE, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ AGE, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.34684 -0.08464  0.01084  0.08323  0.21968 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.7519965  0.0267206  28.143   &lt;2e-16 ***\nAGE         0.0002136  0.0007092   0.301    0.764    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1208 on 170 degrees of freedom\nMultiple R-squared:  0.0005334, Adjusted R-squared:  -0.005346 \nF-statistic: 0.09073 on 1 and 170 DF,  p-value: 0.7636\n\n\nNotice that we do the linear model in the steps:\n\nmodel &lt;- lm(...) fit the model using lm(...), and give the model a name, here, we call it model;\n...lm(mean.acc ~ SHIPLEY...) tell R you want a model of the outcome mean.acc predicted ~ by the predictor SHIPLEY\n...data = study.two) tell R that the variables you name in the formula live in the study.two dataset.\nsummary(model) ask R for a summary of the model you called model.\n\nNotice that R has a general formula syntax:\noutcome ~ predictor *or* y ~ x\n\nand uses the same format across a number of different functions;\neach time, the left of the tilde symbol ~ is some output or outcome;\nand the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\nQuestions: Task 10\nIf you look at the model summary you can answer the following questions.\n\nQ.17. What is the estimate for the coefficient of the effect of the predictor HLVA on mean.acc?\nA.17. 0.026207\nQ.18. Is the effect significant?\nA.18. It is significant, p &lt; .05\nQ.19. What are the values for t and p for the significance test for the coefficient?\nA.19. t = 7.529, p = 2.87e-12\nQ.20. How would you describe in words the shape or direction of the association between HLVA and mean.acc?\nA.20. The slope coefficient – and a scatterplot (draw it) – suggest that as HLVA scores increase so also do mean accuracy scores.\nQ.21. How how would you describe the relations apparent between the predictor and outcome in all three models?\nA.21. It is possible to see, given coefficient estimates, that the association between predictor and outcome is positive for each model: mean accuracy appears to increase for increasing values of SHIPLEY vocabulary, HLVA health literacy, and age."
  },
  {
    "objectID": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-7-use-a-linear-model-to-generate-predictions",
    "href": "PSYC122/data/week17/2023-24-PSYC122-w17-workbook-answers.html#step-7-use-a-linear-model-to-generate-predictions",
    "title": "2023-24-PSYC122-w17-workbook-answers",
    "section": "Step 7: Use a linear model to generate predictions",
    "text": "Step 7: Use a linear model to generate predictions\n\nIntroduce: make some new moves\n\n\nTask 11 – We can use the model we have just fitted to plot the model predictions\n\nhint: Task 11 – We are going to draw a scatterplot and add a line\nThe line will show the model predictions, given the model intercept and effect coefficient estimates.\nFirst fit a model and get a summary: model the relationship between mean.acc and HLVA\n\nmodel &lt;- lm(mean.acc ~ HLVA, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ HLVA, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27457 -0.06777  0.01474  0.08025  0.23146 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.522016   0.032544  16.040  &lt; 2e-16 ***\nHLVA        0.026207   0.003481   7.529 2.87e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1047 on 170 degrees of freedom\nMultiple R-squared:  0.2501,    Adjusted R-squared:  0.2456 \nF-statistic: 56.68 on 1 and 170 DF,  p-value: 2.866e-12\n\n\n\nQ.22. What is the coefficient estimate for the intercept?\nA.22. 0.522016\nQ.23. What is the coefficient estimate for the slope of HLVA (see earlier)?\nA.23. 0.026207\n\nSecond, use the geom_point() to draw a scatterplot and geom_abline() function to draw the prediction line representing the association between this outcome and predictor\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  geom_abline(intercept = 0.522016, slope = 0.026207, colour = \"red\", size = 1.5) +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\") +\n  xlim(0, 15) + ylim(0, 1)\n\n\n\n\n\n\n\n\nYou can see reference information here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html"
  },
  {
    "objectID": "PSYC122/data/week11/122_wk11_labActivities2_3.html#lab-activity-3---hazardous-alcohol-use-and-impulsivity",
    "href": "PSYC122/data/week11/122_wk11_labActivities2_3.html#lab-activity-3---hazardous-alcohol-use-and-impulsivity",
    "title": "122_wk11_labActivities2_3",
    "section": "Lab activity 3 - Hazardous alcohol use and impulsivity",
    "text": "Lab activity 3 - Hazardous alcohol use and impulsivity"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "",
    "text": "In Week 16, we aim to develop skills in visualizing and testing the associations between variables in psychological data.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like correlation and linear models.\nWe will consolidate and extend learning on data visualization:\n\nUse histograms to examine the distributions of variables;\nUse scatterplots to examine the relationships we may observe or predict.\n\n\n\nI will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#naming-things",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#naming-things",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "",
    "text": "In this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-1-set-up",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-1-set-up",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-2-load-the-data",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask Task 3 – Read in the data file we will be using\nThe data file is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")\n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a clear name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\n\n\nQ.1. What is the median of AGE?\nA.1. 32.50\nQ.2. What class is the variable ETHNICITY?\nA.2. character\nQ.3. Does the summary indicate if any variable has missing values (NAs)?\nQ.3. No\n\n\n\nTask 5 – Change the class or type of the variable ETHNICITY to factor\nYou can use the as.factor() function you have used before:\n\nstudy.two.gen$ETHNICITY &lt;- as.factor(study.two.gen$ETHNICITY)\n\n\nQ.4. After you have done this, what information does summary() give you about the variable ETHNICITY?\n\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION         ETHNICITY  \n Min.   : 6.00   Length:172         Length:172         Asian: 15  \n 1st Qu.:12.00   Class :character   Class :character   Black:  5  \n Median :14.00   Mode  :character   Mode  :character   Mixed:  7  \n Mean   :13.88                                         White:145  \n 3rd Qu.:16.00                                                    \n Max.   :20.00                                                    \n\n\n\nA.4. We can see that ETHNICITY lists observations following UK Office National Statistics ethnicity grouping:\nAsian: 15\nBlack: 5\nMixed: 7\nWhite: 145"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-3-use-histograms-to-examine-the-distributions-of-variables",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 3: Use histograms to examine the distributions of variables",
    "text": "Step 3: Use histograms to examine the distributions of variables\n\nTask 6 – Draw histograms to examine the distributions of variables\n\nHint: Task 6\nUse ggplot() with geom_histogram().\nThe first time we do this, we take things step-by-step.\nHere’s an example: run the line of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.two.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\n\n\nQuestions: Task 6\n\nQ.5. Did you get a message in the Console window in R-Studio: what does it say?\nA.5. The message says:\nstat_bin() using bins = 30. Pick better value with binwidth.\nQ.6. Draw two different histograms to examine the distributions of two different variables: SHIPLEY and HLVA\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nQ.7. Now re-do both plots: can you change the binwidth in geom_histogram() to make the bars wider?\n\nIf you are going to change binwidth the number you use needs to be a number larger than\nthe minimum and smaller than the maximum for the variable.\nRemember, min and max values are given for each numeric variable in summary().\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\nWe adjust binwidth typically to improve the appearance of the plot.\nThis is a bit subjective so try different numbers and see how you feel about the changes in appearance.\nWe want histograms that show us enough detail about the frequency of occurrence of groupings (bins) of values for each variable.\nBut we do not want histograms that show us so much detail it is difficult to see the pattern for the distribution.\n\nQ.8 – How would you describe the distributions – in a sentence – of the distributions of the SHIPLEY and HLVA variable values for our sample?\nA.8. The SHIPLEY values lie between about 25 and 40, and are skewed towards high scores.\nA.8. The HLVA values lie between 4 and about 14, and peak in the middle (near 7)."
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-4-edit-your-plots-to-make-them-look-good",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-4-edit-your-plots-to-make-them-look-good",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 4: Edit your plots to make them look good",
    "text": "Step 4: Edit your plots to make them look good\n\nTask 7 – Edit the appearance of a histogram plot for one numeric variable\nNote that ggplot() code does not all have to be on the same line.\nYou can create a new plot for each edit so you can see what difference your edits make.\n\nQ.9. Edit the appearance of the bars using binwidth\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\nQ.10. Edit the colour of the background using theme_bw()\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nQ.11. Edit the appearance of the labels using labs()\n\n\nggplot(data = study.two.gen, aes(x = HLVA)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"count\")\n\n\n\n\n\n\n\n\nNotice how, if you are doing edits in steps, one line at a time, each line in your code except the last one ends in a +.\nWhat we are doing is telling R we want this + this + this … Each line then adds an extra step.\nYou can break this code by not adding a + at the end of each bit (except the last line).\nNotice that how to break the code, and how to figure out how to fix the break, are discussed in the how-to .R"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-5-now-draw-scatterplots-to-examine-associations-between-variables",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-5-now-draw-scatterplots-to-examine-associations-between-variables",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 5: Now draw scatterplots to examine associations between variables",
    "text": "Step 5: Now draw scatterplots to examine associations between variables\n\nTask 8 – Create a scatterplot to examine the association between some variables\nWe are working with geom_point() and you need x and y aesthetic mappings\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThis plot shows the possible association between x-axis variable HLVA and y-axis variable mean.acc.\nThe plot code moves through the following steps:\n\nggplot(...) make a plot\nggplot(data = study.two.gen, ...) with the study.two.gen dataset\nggplot(...aes(x = HLVA, y = mean.acc)) using two aesthetic mappings:\n\n\nx = HLVAmapHLVA` values to x-axis (horizontal, left to right) positions\ny = mean.accmapmeann.acc` values to y-axis (vertical, bottom to top) positions\n\n\ngeom_point() show the mappings as points\n\n\n\nTask 9 – Now do scatterplots with every numeric predictor variable in the study.two.gen dataset\nYou always want to use as the y-axis variable the outcome mean.acc so:\n\ny = mean.acc\n\nThen you can use each numeric predictor variable as the x-axis variable so:\n\nx = mean.self\n\nRemember what we saw with summary(): not every variable consists of numbers\nIf the summary() does not show you a mean for a variable, then R does not think that variable is numeric\nIt can be hard to decide what an association looks like:\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point()  \n\n\n\n\n\n\n\n\n\nQ.12. What is the shape (direction) of the association between mean.self and mean.acc?\nA.12. Increase in mean.self is associated with increase in mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nQ.13. What is the shape (direction) of the association between AGE and mean.acc?\nA.13. There is no clear association between AGE and mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()  \n\n\n\n\n\n\n\n\n\nQ.14. What is the shape (direction) of the association between SHIPLEY and mean.acc?\nA.14. Increase in SHIPLEY is associated with increase in mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nQ.15. – What is the shape (direction) of the association between HLVA and mean.acc?\nA.15. Increase in HLVA is associated with increase in mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = FACTOR3, y = mean.acc)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nQ.16. What is the shape (direction) of the association between FACTOR3 and mean.acc?\nA.16. Increase in FACTOR3 is associated with increase in mean.acc\n\n\n\nDraw the plot, answer the question\n\nggplot(data = study.two.gen, aes(x = QRITOTAL, y = mean.acc)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nQ.17. What is the shape (direction) of the association between QRITOTAL and mean.acc?\nA.17. Increase in QRITOTAL is associated with increase in mean.acc"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-6-edit-the-scatterplots-to-make-them-look-good",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-6-edit-the-scatterplots-to-make-them-look-good",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 6: Edit the scatterplots to make them look good",
    "text": "Step 6: Edit the scatterplots to make them look good\n\nTask 10 – Edit the appearance of one plot step-by-step\n\nHint: Task 10 – We are going to edit:\n\nthe appearance of the points using alpha, size and colour;\nthe colour of the background using theme_bw();\nthe appearance of the labels using labs().\n\nJust like with geom_histogram() there is ggplot reference information for the geom you can use here – take a look:\nhttps://ggplot2.tidyverse.org/reference/geom_point.html\nYou can find some example code and come back here if you are unsure what to do\n\n\nQuestions: Task 10\n\nQ.18. Change the appearance of the points using alpha, size and colour:\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\") \n\n\n\n\n\n\n\n\n\nQ.19. Edit the colour of the background using theme_bw()\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\")   +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nQ.20. Edit the appearance of the labels using labs()\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"red\")   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\")\n\n\n\n\n\n\n\n\n\nQ.21. Can you find the ggplot reference page?\n\nDo a search with the keywords “ggplot reference geom_point”\n\nA.21. – It is here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_point.html"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#now-you-experiment",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#now-you-experiment",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Now you: experiment!",
    "text": "Now you: experiment!"
  },
  {
    "objectID": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-7-use-correlation-to-to-answer-the-research-questions",
    "href": "PSYC122/data/week16/2023-24-PSYC122-w16-workbook-answers.html#step-7-use-correlation-to-to-answer-the-research-questions",
    "title": "2023-24-PSYC122-w16-workbook-answers",
    "section": "Step 7: Use correlation to to answer the research questions",
    "text": "Step 7: Use correlation to to answer the research questions\n\nTask 11 – Examine the correlation between mean accuracy (mean.acc) and some numeric predictor variables\nWe use cor.test()\n\nQ.22. What is r (given as cor in the output) for the correlation between HLVA and mean.acc?\n\n\ncor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$HLVA and study.two.gen$mean.acc\nt = 7.5288, df = 170, p-value = 2.866e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3787626 0.6044611\nsample estimates:\n      cor \n0.5000559 \n\n\n\nA.22. r = 0.5000559\nQ.23. Is the correlation significant?\nA.23. r is significant\nQ.24. What are the values for t and p for the significance test for the correlation?\nA.24. t = 7.5288, p = 2.866e-12\nQ.25. What do you conclude, given the correlation results? (Maybe draw a scatterplot to examine the shape of the association.)\nA.25. HLVA and mean.acc are positively correlated suggesting that as HLVA scores increase so also do mean.acc scores\nQ.26. What is r (given as cor in the output) for the correlation between mean.self and mean.acc?\n\n\ncor.test(study.two.gen$mean.self, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$mean.self and study.two.gen$mean.acc\nt = 8.4991, df = 170, p-value = 9.356e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4317217 0.6431596\nsample estimates:\n      cor \n0.5460792 \n\n\n\nA.26. r = 0.5460792\nQ.27. Is the correlation between AGE and mean.acc significant?\n\n\ncor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$AGE and study.two.gen$mean.acc\nt = 0.30121, df = 170, p-value = 0.7636\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1269774  0.1721354\nsample estimates:\n       cor \n0.02309589 \n\n\n\nA.27. r is not significant\nQ.28. What are the values for t and p for the significance test for the correlation between QRITOTAL and mean.acc?\n\n\ncor.test(study.two.gen$QRITOTAL, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$QRITOTAL and study.two.gen$mean.acc\nt = 6.4711, df = 170, p-value = 9.993e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3159538 0.5571417\nsample estimates:\n    cor \n0.44457 \n\n\n\nA.28. t = 6.4711, p = 9.993e-10\nQ.29. What do you conclude, given the correlation results, about the association between SHIPLEY and mean.acc?\n\n\ncor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.two.gen$SHIPLEY and study.two.gen$mean.acc\nt = 6.8493, df = 170, p-value = 1.299e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3390103 0.5746961\nsample estimates:\n      cor \n0.4650537 \n\n\n\nA.29. SHIPLEY and mean.acc are positively correlated suggesting that as HLVA scores increase so also do mean.acc scores"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "",
    "text": "In Week 18, we aim to further develop skills in working with the linear model.\nWe do this to learn how to answer research questions like:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nThese kinds of research questions can be answered using methods like the linear model.\nWhen we do these analyses, we need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model.\n\nWe usually need to decide:\n\nis the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nand is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\nfocusing on how we edit ggplot() code to produce professional looking plots.\n\n\n\nI will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}.\n\n\n\nIn this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#naming-things",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#naming-things",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "",
    "text": "I will format dataset names like this:\n\nstudy-two-general-participants.csv\n\nI will also format variable (data column) names like this: variable\nI will also format value or other data object (e.g. cell value) names like this: studyone\nI will format functions and library names like this: e.g. function ggplot() or e.g. library {tidyverse}."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#the-data-we-will-be-using",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#the-data-we-will-be-using",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "",
    "text": "In this activity, we use data from a second 2020 study of the response of adults from a UK national sample to written health information:\n\nstudy-two-general-participants.csv"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-1-set-up",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-1-set-up",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 1: Set-up",
    "text": "Step 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())                            \n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"ggeffects\")\n\nWarning: package 'ggeffects' was built under R version 4.2.3\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.1     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-2-load-the-data",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-2-load-the-data",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 2: Load the data",
    "text": "Step 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R:\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")\n\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you read the data file in, give the data object you create a distinct name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look.\n\nhead(study.two.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studytwo.1        0.411      6.07 studyt…    26      27     6      50        9\n2 studytwo.10       0.607      8.5  studyt…    38      24     9      58       15\n3 studytwo.100      0.875      8.93 studyt…    66      40    13      60       20\n4 studytwo.101      0.964      8.5  studyt…    21      31    11      59       14\n5 studytwo.102      0.714      7.07 studyt…    74      35     7      52       18\n6 studytwo.103      0.768      5.07 studyt…    18      40    11      54       15\n# ℹ 3 more variables: GENDER &lt;chr&gt;, EDUCATION &lt;chr&gt;, ETHNICITY &lt;chr&gt;\n\nsummary(study.two.gen)\n\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n\n\nEven though you have done this before, you will want to do it again, here, and pay particular attention to:\n\nsummary information about the numeric variables;\nsummary information about variables of class: character."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-3-use-a-linear-model-to-to-answer-the-research-questions-one-predictor",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-3-use-a-linear-model-to-to-answer-the-research-questions-one-predictor",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 3: Use a linear model to to answer the research questions – one predictor",
    "text": "Step 3: Use a linear model to to answer the research questions – one predictor\n\nRevise: practice to strengthen skills\n\n\nRevise: We start by revising how to use lm() with one predictor\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe can address this question by examining whether someone’s rated evaluation of their own understanding matches their performance on a test of that understanding, and by investigating what variables predict variation in mean self-rated accuracy.\n\nNote that ratings of accuracy are ordinal data but that, here, we may choose to examine the average of participants’ ratings of their own understanding of health information to keep our analysis fairly simple.\nFor these data, participants were asked to respond to questions about health information to get mean.acc scores and then were asked to rate their own understanding of the same information.\n\nIf you can evaluate your own understanding then ratings of understanding should be associated with performance on tests of understanding\n\n\nTask 5 – Estimate the relation between outcome mean self-rated accuracy (mean.self) and tested accuracy of understanding (mean.acc)\n\n\nhint: Task 5\nFor these data, participants were asked to respond to questions about health information to get mean.acc scores and were asked to rate their own understanding of the same information.\n\n\nhint: Task 5\nWe can use lm() to estimate whether the ratings of accuracy actually predict the outcome tested accuracy levels.\n\nmodel &lt;- lm(mean.self ~ mean.acc, data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\nIn R analysis code, we write method(outcome ~ predictor) so:\nlm(mean.self ~ mean.acc, data = study.two.gen)\n\ngets us an analysis of whether or how mean.self predicts variation in outcome mean.acc.\n\nIf you look at the model summary you can answer the following questions.\n\nQuestions: Task 5\n\nQ.1. What is the estimate for the coefficient of the effect of the predictor mean.acc on the outcome mean.self in this model?\nA.1. 5.5670\nQ.2. Is the effect significant?\nA.2. It is significant, p &lt; .05\nQ.3. What are the values for t and p for the significance test for the coefficient?\nA.3. t = 8.499, p = 9.36e-15\nQ.4. What do you conclude is the answer to the research question, given the linear model results?\nA.4. The model slope estimate suggests that higher levels of tested understanding can predict higher levels of rated understanding so, yes: it does appear that people can evaluate their own understanding.\nQ.5. What is the F-statistic for the regression? Report F, DF and the p-value.\nA.5. F-statistic: 72.24 on 1 and 170 DF, p-value: 9.356e-15\nQ.6. Is the regression significant?\nA.6. Yes: the regression is significant.\nQ.7. What is the Adjusted R-squared?\nA.7. Adjusted R-squared: 0.2941\nQ.8. Explain in words what this R-squared value indicates?\nA.8. The R-squared suggests that about 30% of outcome variance can be explained by the model"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-4-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-4-use-a-linear-model-to-to-answer-the-research-questions-multiple-predictors",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 4: Use a linear model to to answer the research questions – multiple predictors",
    "text": "Step 4: Use a linear model to to answer the research questions – multiple predictors\n\nIntroduce: make some new moves\nOne of our research questions is:\n\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe have already looked at this question by asking whether ratings of understanding predict performance on tests of understanding.\nBut there is a problem with that analysis – it leaves open the question:\n\nWhat actually predicts ratings of understanding?\n\nWe can look at this follow-up question, next.\n\n\nTask 6 – Examine the relation between outcome mean self-rated accuracy (mean.self) and multiple predictors\nHere, the predictors will include:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nage in years (AGE);\nreading strategy (FACTOR3);\nas well as average accuracy of the tested understanding of health information (mean.acc).\n\n\nhint: Task 6 – We use lm(), as before, but now specify each variable listed here by variable name\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc, \n            data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc, \n    data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.72027 -0.49118 -0.00177  0.55561  2.00134 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.561110   0.700632   0.801   0.4244    \nHLVA         0.041272   0.034833   1.185   0.2378    \nSHIPLEY     -0.046125   0.018701  -2.466   0.0147 *  \nFACTOR3      0.063689   0.010747   5.926 1.74e-08 ***\nAGE          0.025570   0.005472   4.673 6.12e-06 ***\nmean.acc     4.763278   0.708166   6.726 2.69e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8805 on 166 degrees of freedom\nMultiple R-squared:  0.5014,    Adjusted R-squared:  0.4864 \nF-statistic: 33.39 on 5 and 166 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nQuestions: Task 6\nIf you look at the model summary you can answer the following questions.\n\nQ.9. What predictors are significant in this model?\nA.9. Vocabulary (SHIPLEY), reading strategy (FACTOR3), AGE, and performance on tests of accuracy of understanding (mean.acc) all appear to significantly predict variation in mean ratings of understanding (mean.self).\nQ.10. What is the estimate for the coefficient of the effect of the predictor mean.acc in this model?\nA.10. 4.763278\nQ.11. Is the effect significant?\nA.11. It is significant, p &lt; .05\nQ.12. What are the values for t and p for the significance test for the coefficient?\nA.12. t = 6.726, p = 2.69e-10\nQ.13. What do you conclude is the answer to the follow-up question, what actually predicts ratings of understanding?\nA.13. Ratings of understanding appear to be predicted by performance on tests of accuracy of understanding, together with variation in age, vocabulary knowledge, health literacy and reading strategy"
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-5-understanding-linear-model-predictions-by-comparing-one-outcome-predictor-relation",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-5-understanding-linear-model-predictions-by-comparing-one-outcome-predictor-relation",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 5: Understanding linear model predictions by comparing one outcome-predictor relation",
    "text": "Step 5: Understanding linear model predictions by comparing one outcome-predictor relation\nNext, we focus in on whether mean.self predicts mean.acc or, in reverse, whether mean.acc predicts mean.self?\n\nNote that a comparison between these models teaches us something important about what it is that linear models predict.\nQ.14. Why do you think it appears that the slope coefficient estimate is different if you compare :\n\n\nThe model mean.acc ~ mean.self versus\nThe model mean.self ~ mean.acc?\n\n\nhint: Q.14. You want to fit two simple models here, using the verbal description in the Q.14 wording.\n\n1. The model mean.acc ~ mean.self\n\nmodel.1 &lt;- lm(mean.acc ~ mean.self, data = study.two.gen)\nsummary(model.1)\n\n\nCall:\nlm(formula = mean.acc ~ mean.self, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.293692 -0.069200  0.005422  0.080041  0.215240 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.379182   0.045415   8.349 2.31e-14 ***\nmean.self   0.053566   0.006303   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1013 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\n2. The model mean.self ~ mean.acc\n\nmodel.2 &lt;- lm(mean.self ~ mean.acc, \n              data = study.two.gen)\nsummary(model.2)\n\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\n\nhint: Q.14. You may benefit here by reflecting on the lm-intro lecture and practical materials, especially where they concern predictions.\nA.14. Linear models are prediction models. We use them to predict variation in outcomes given some set of predictor variables. Predictions will necessarily be scaled in the same way as the outcome variable.\n\nSo, to expand on that explanation a bit more, to help understanding – the answer is:\n\nIf we have the model, mean.acc ~ mean.self then this means that the outcome is mean.acc.\n\n\nSo if we are predicting change in outcome mean.acc, which is scaled 0-1, then we are looking at coefficients that will lie somewhere on the same scale (also 0-1).\nHere: the model estimate suggests that each unit change in values of the variable mean.self predicts an increase of 0.053566 in mean.acc.\n\n\nWhereas if we have the model, mean.self ~ mean.acc then this means that the outcome is mean.self.\n\n\nSo if we are predicting change in outcome mean.self, which is scaled 1-9 , then we are looking at coefficients that will lie somewhere on the same scale (also 1-9).\nHere: the model estimate suggests that unit change in mean.acc predicts increase of 5.5670 in mean.self.\n\nNote that:\n\nWhere we reference model estimates, here, we are looking at the values in the Estimate column of the lm() model summary.\nThese estimates give us the expected or predicted change in the outcome, given change in the predictor variable named on that row.\n\nRemember that:\n\nmean.acc is scaled from 0 to 1 because it represents the average accuracy of the responses made by study participants to questions about health texts. This average has to have a minimum of 0 (no responses correct) and a maximum of 1 (all responses correct). The average is calculated by adding up all the correct answers and dividing by the number of questions answered by each participant.\nmean.self is scaled from 1 to 9 bcause it represents the average self-rated accuracy of understanding. Participants are asked to rate on a scale form 1 (not all) to 9 (very well) how well they think they understand a health information text. The average is calculated by adding up all the ratings and dividing by the number of texts responded to by each participant.\n\nThe important lesson, here, is that estimates of predictor effects are scaled in terms of predicted change in the outcome, so whatever scale the outcome measurement is in determines how big or small the predictor coefficient estimates can be.\nWe can visualize this to see what it means in practice.\n\nQ.15. Can you plot the predictions from each model?\nA.15. Here is the code to plot the predictions from both models.\n\nFirst fit the models.\n\nRemember to give each model object distinct names.\n\n\nmodel.1 &lt;- lm(mean.acc ~ mean.self, data = study.two.gen)\nsummary(model.1)\n\n\nCall:\nlm(formula = mean.acc ~ mean.self, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.293692 -0.069200  0.005422  0.080041  0.215240 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.379182   0.045415   8.349 2.31e-14 ***\nmean.self   0.053566   0.006303   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1013 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\nmodel.2 &lt;- lm(mean.self ~ mean.acc, \n            data = study.two.gen)\nsummary(model.2)\n\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,    Adjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n\nSecond get the predictions:\n\ndat.1 &lt;- ggpredict(model.1, \"mean.self\")\ndat.2 &lt;- ggpredict(model.2, \"mean.acc\")\n\nThird make the prediction plots:\n\nPredictions from the model mean.acc ~ mean.self\n\n\nplot(dat.1)\n\n\n\n\n\n\n\n\n\nPredictions from the model mean.self ~ mean.acc\n\n\nplot(dat.2)\n\n\n\n\n\n\n\n\n\nQ.16. Look at the two plots: what do you see?\nhint: Q.16. Look at changes in height of the prediction line, given changes in x-axis position of the line\nA.16. A side-by-side comparison shows that:\n\n\nFor model mean.acc ~ mean.self increases in mean.self from about 4 to 9 are associated with a change in mean.acc from about .6 to about .85;\nFor model mean.self ~ mean.acc increases in mean.acc from about 0.4 to 1.0 are associated with a change in mean.self from about 5 to about 9."
  },
  {
    "objectID": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-6-estimate-the-effects-of-factors-as-well-as-numeric-variables",
    "href": "PSYC122/data/week18/2023-24-PSYC122-w18-workbook-answers.html#step-6-estimate-the-effects-of-factors-as-well-as-numeric-variables",
    "title": "2023-24-PSYC122-w18-workbook-answers",
    "section": "Step 6: Estimate the effects of factors as well as numeric variables",
    "text": "Step 6: Estimate the effects of factors as well as numeric variables\n\nConsolidation: build your skills\nWe have not yet included any categorical or nominal variables as predictors but we can, and should: lm() can cope with any kind of variable as a predictor.\nThere are different ways to do this, here we ask you to use the R default method.\n\n\nTask 7 – Fit a linear model to examine what variables predict outcome mean self-rated accuracy of mean.self\n\nhint: Task 7 – Include as predictors both numeric variables and categorical variables\nHere, our model includes predictors that are both numeric like:\n\nhealth literacy (HLVA);\nvocabulary (SHIPLEY);\nAGE;\nreading strategy (FACTOR3);\naccuracy mean.acc\n\nAs well as a categorical or nominal variable like\n\nEDUCATION.\n\nNote: EDUCATION is different because participants are classified by what education category (higher education, further education, secondary school) they report themselves as having received.\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc +\n                        EDUCATION, \n            data = study.two.gen)\nsummary(model)\n\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + \n    EDUCATION, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70987 -0.50037  0.01988  0.55965  2.01412 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.487753   0.702049   0.695   0.4882    \nHLVA                0.047100   0.034915   1.349   0.1792    \nSHIPLEY            -0.044132   0.018719  -2.358   0.0196 *  \nFACTOR3             0.061918   0.010771   5.749 4.29e-08 ***\nAGE                 0.023997   0.005595   4.289 3.06e-05 ***\nmean.acc            4.912833   0.712381   6.896 1.10e-10 ***\nEDUCATIONHigher    -0.082217   0.146390  -0.562   0.5751    \nEDUCATIONSecondary  0.346161   0.266030   1.301   0.1950    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8783 on 164 degrees of freedom\nMultiple R-squared:  0.5099,    Adjusted R-squared:  0.489 \nF-statistic: 24.38 on 7 and 164 DF,  p-value: &lt; 2.2e-16\n\n\n\nQ.17. Can you report the overall model and model fit statistics?\nA.17.\n\n\nWe fitted a linear model with mean self-rated accuracy as the outcome and with the predictors: health literacy (HLVA), vocabulary (SHIPLEY), reading strategy (FACTOR3), AGE, as well as mean accuracy (mean.acc) and education level (EDUCATION). The model is significant overall, with F(7, 164) = 24.38, p &lt; .001, and explains 49% of variance (adjusted R2 = 0.489).\n\n\nQ.18. Can you plot the predicted effect of EDUCATION given your model?\nhint: Q.18. We first fit the model, including EDUCATION.\n\n\nmodel &lt;- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + EDUCATION, \n            data = study.two.gen)\n\n\nhint: Q.18. We then use the ggpredict() function to get the prediction for the effect of EDUCATION differences on outcome mean.self.\n\n\ndat &lt;- ggpredict(model, \"EDUCATION\")\nplot(dat)\n\n\n\n\n\n\n\n\n\nQ.19. The plot should give you dot-and-whisker representations of the estimated mean.self outcome for different levels of EDUCATION. What is the difference in the estimated mean.self between the groups?\nhint: Q.19. The effect or prediction plot will show you dot-and-whisker representations of predicted outcome mean.self. In these plots, the dots represent the estimated mean.self while the lines (whiskers) represent confidence intervals.\nA.19. The difference in the estimated mean.self between these groups is small: the groups vary between ratings of about 7, 7.10 and 7.5.\nQ.20. Compare the difference in the estimated mean.self between these groups, given the plot, with the coefficient estimate from the model summary: what do you see?\nA.20. The effect of EDUCATION is presented in the summary as two estimates:\nEDUCATIONHigher    -0.082217\nEDUCATIONSecondary  0.346161\n\nThe reference level for EDUCATION is Further.\nThe estimates therefore show that people with Higher education have mean.self scores about -.08 lower than mean.self for people with Further education.\nPeople with Secondary education have mean.self scores about .35 higher than mean.self for people with Further education.\nWe are learning some new things here so it is useful to explain them:\n\nCategorical variables or factors and reference levels.\n\n\nIf you have a categorical variable like EDUCATION then when you use it in an analysis, R will look at the different categories (called levels) e.g., here,higher education, further education, secondary school` and it will pick one level to be the reference or baseline level.\nThe reference is the the level against which other levels are compared.\nHere, the reference level is Further (education) simply because, unless you tell R otherwise, it picks the level with a category name that begins earlier in the alphabet as the reference level.\n\n\nDot and whisker plots show estimates with confidence intervals.\n\n\nDot and whisker plots are a nice way to present a concise visual summary about the estimates we get from prediction models.\nHere, the plots show the coefficient estimates from our model (the dots) plus confidence intervals (the lines or “whiskers”).\n\n\nConfidence intervals are often misunderstood but they are helpful.\n\n\nEssentially, a confidence interval tells us about we might expect to see using our analysis procedure (Hoekstra et al., 2014).\n\n\nIf we were to repeat the experiment over and over, then 95 % of the time the confidence intervals contain the true mean.\n\n\nAnd you can read more about this here\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E. J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21, 1157-1164."
  },
  {
    "objectID": "PSYC122/Week17.html",
    "href": "PSYC122/Week17.html",
    "title": "6. Week 17 – Better understanding the linear model",
    "section": "",
    "text": "Caution\n\n\n\nThis page is under construction for 24/25 and may be subject to change before the teaching week.",
    "crumbs": [
      "Home",
      "PSYC122",
      "6. Week 17 -- Better understanding the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week17.html#sec-wk17-introduction",
    "href": "PSYC122/Week17.html#sec-wk17-introduction",
    "title": "6. Week 17 – Better understanding the linear model",
    "section": "Week 17: Introduction",
    "text": "Week 17: Introduction\nWelcome to your overview of our work together in PSYC122 Week 17.\n\n\n\n\n\n\nTip\n\n\n\nPutting it all together\n\nWe will complete four classes in weeks 16-19.\nThese classes are designed to help you to revise and to put into practice some of the key ideas and skills you have been developing in the first year research methods modules PSYC121, PSYC123 and PSYC124.\nWe will do this in the context of a live research project with potential real world impacts: the Clearly Understood project.\n\n\n\n\nOur learning goals\nIn Week 17, we aim to further develop skills in analyzing and in visualizing psychological data.\nWe will do this in the context of the Clearly Understood project: our focus will be on what makes it easy or difficult for people to understand written health information.\n\n\n\n\n\n\nTip\n\n\n\nIn the Week 17 class, we will aim to answer the research question:\n\nWhat person attributes predict success in understanding?\n\nIn psychological science, research questions like our question can be examined using linear models.\n\n\nWhen we do these analyses, we will need to think about how we report the results:\n\nwe usually need to report information about the kind of model we specify;\nand we will need to report the nature of the association estimated in our model.\n\nThis means we will usually need to decide:\n\nis the association significant?\ndoes the association reflect a positive or negative relationship between outcome and predictor?\nis the association relatively strong or weak?\n\nOur thinking, and our decision-making, will be helped by developing our data visualization skills. At every stage, as we work, we will visualize the data to:\n\nUnderstand the shape of the relationships we may observe or predict.\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe will aim to build skills in producing professional-looking plots for our audiences.",
    "crumbs": [
      "Home",
      "PSYC122",
      "6. Week 17 -- Better understanding the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week17.html#sec-wk17-lectures",
    "href": "PSYC122/Week17.html#sec-wk17-lectures",
    "title": "6. Week 17 – Better understanding the linear model",
    "section": "Lectures",
    "text": "Lectures\n\n\n\n\n\n\nTip\n\n\n\nBefore you go on to the activities in Section 5, watch the lectures:\n\n\nThe lecture for this week is presented in four short parts. You can view video recordings of the lectures using Panopto, by clicking on the links shown following.\n\nOverview (19 minutes): What we are doing in Week 17 – thinking critically about predicting people.\n\n\n\nUsing linear models to do prediction (11 minutes): How we answer live research questions by using linear models to predict behaviour.\n\n\n\nHow linear models work (9 minutes): How we can visualize and think about predictions, and about the difference between what we predict and what we observe when we study people.\n\n\n\nInterpreting, reporting and visualizing linear model results (15 minutes): Identifying, interpreting and communicating the key statistics.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe slides presented in the videos can be downloaded either as a web page or as a Word document.\n\n\n\nThe slides exactly as presented (21 MB).\nThe slides converted to a Word .docx (11 MB).\n\nYou can download the web page .html file and click on it to open it in any browser (e.g., Chrome, Edge or Safari). The slide images are high quality so the file is quite big and may take a few seconds to download.\nYou can download the .docx file and click on it to open it as a Word document that you can then edit. Converting the slides to a .docx distorts some images but the benefit of the conversion is that it makes it easier for you to add your notes.\n\nThe lectures have two main areas of focus\n1. Understanding the scientific process\nI outline the steps through which a psychological scientist may progress, in logic and practice, from research questions to hypotheses to analyses.\nWe are learning data analysis methods. But the key point is that we use these methods in the context of a research project with concerns, aims, methodological assumptions, and choices. This is generally true so the aim is to present a concrete example of how research works.\nAs part of the discussion, I raise questions you might want to consider. These questions are also part of the context for our data analysis, because they help to inform how you interpret or evaluate the results. These questions are examples of the critical evaluation that you will need to develop through your studies.\n2. The linear model\nWe look at how the linear model can be used to address research questions in the context of the Clearly understood health comprehension project. But I aim to outline some general ideas about why we use the linear model technique, and how it works.\nI build on work you have done with Margriet Groen in earlier PSYC122 classes, so that we can strengthen understanding, and extend skills.\nThe lectures end with a discussion of the critical information you must identify and extract when you view the summary of a linear model results.\nI then show you how to report the results. I give you examples of the conventional language you can use to report your results.\n\n\n\n\n\n\nTip\n\n\n\nTo work with the recordings:\n\nWatch the video parts right through.\nUse the printable versions of the slides (provided on Moodle) to make notes.\nTry out the coding exercises in the how-to guide and the acitivity tasks or questions (Section 5) to learn how to construct visualizations and do analyses.",
    "crumbs": [
      "Home",
      "PSYC122",
      "6. Week 17 -- Better understanding the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week17.html#reading-links-to-other-classes",
    "href": "PSYC122/Week17.html#reading-links-to-other-classes",
    "title": "6. Week 17 – Better understanding the linear model",
    "section": "Reading: Links to other classes",
    "text": "Reading: Links to other classes\nWe do not provide further reading for this class but you will find it helpful to revise some of the key ideas you have been learning about PSYC122 and in other modules.\n\nThe lectures in PSYC123 on: the scientific method; reliability and validity; experimental design, especially between-subjects studies; hypothesis testing; and precise hypotheses.\nThe lecture in PSYC122 on correlations.",
    "crumbs": [
      "Home",
      "PSYC122",
      "6. Week 17 -- Better understanding the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week17.html#sec-wk17-prelab-activities",
    "href": "PSYC122/Week17.html#sec-wk17-prelab-activities",
    "title": "6. Week 17 – Better understanding the linear model",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\n\nPre-lab activity 1\nIn weeks 16-19, we will be working together on a research project to investigate how people vary in their response to health advice.\nCompleting the project involves collecting responses from PSYC122 students: you.\nTo enter your responses, we invite you to complete a short survey.\nComplete the survey by clicking on the link here\n\n\n\n\n\n\nTip\n\n\n\nIn our week 19 class activity, we will analyze the data we collect here.\n\n\nThe survey should take about 20 minutes to complete.\nTaking part in the survey is completely voluntary. You can stop at any time without completing the survey if you do not want to finish it. If you do not want to do the survey, you can do an alternative activity (see below).\nAll responses will be recorded completely anonymously.\n\n\nPre-lab activity alternative option\nIf you do not want to complete the survey, we invite you to read the pre-registered research plan for the PSYC122 health advice research project.\nRead the project pre-registration",
    "crumbs": [
      "Home",
      "PSYC122",
      "6. Week 17 -- Better understanding the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week17.html#sec-wk17-lab-activities",
    "href": "PSYC122/Week17.html#sec-wk17-lab-activities",
    "title": "6. Week 17 – Better understanding the linear model",
    "section": "Lab activities",
    "text": "Lab activities\n\nIntroduction\nWe will do our practical lab work to develop your skills in the context of the Clearly Understood project.\n\nOur focus will be on what makes it easy or difficult for people to understand written health information.\n\n\n\n\n\n\n\nImportant\n\n\n\nIn these classes, we will complete a research project to answer the research questions:\n\nWhat person attributes predict success in understanding health information?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\n\n\n\nGet ready\n\nDownload the data\nClick on the link: 122_week17_for_students.zip to download the data files folder. Then upload the contents to the new folder you created in RStudio Server.\nThe downloadable .zip folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand the R Markdown .Rmd:\n\n2023-24-PSYC122-w17-how-to.Rmd\n\nIf you can’t upload these files to the server – this affects some students – you can use some code to get R to do it for you: uncover the code box below to reveal the code to do this.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nYou can use the code below to directly download the file you need in this lab activity to the server.\nRemember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\nGet the study-one-general-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week17/study-one-general-participants.csv?raw=true\", destfile = \"study-one-general-participants.csv\")\n\n\nGet the study-two-general-participants.csv data\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week17/study-two-general-participants.csv?raw=true\", destfile = \"study-two-general-participants.csv\")\n\n\nGet the 2023-24-PSYC122-w17-how-to.Rmd how-to guide\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week17/2023-24-PSYC122-w17-how-to.Rmd?raw=true\", destfile = \"2023-24-PSYC122-w17-how-to.Rmd\")\n\n\n\n\n\n\nCheck: What is in the data files?\nEach of the data files we will work with has a similar structure, as you can see in this extract.\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\n\n\n\n\n\nYou can use the scroll bar at the bottom of the data window to view different columns.\nYou can see the columns:\n\nparticipant_ID participant code;\nmean.acc average accuracy of response to questions testing understanding of health guidance (varies between 0-1);\nmean.self average self-rated accuracy of understanding of health guidance (varies between 1-9);\nstudy variable coding for what study the data were collected in\nAGE age in years;\nHLVA health literacy test score (varies between 1-16);\nSHIPLEY vocabulary knowledge test score (varies between 0-40);\nFACTOR3 reading strategy survey score (varies between 0-80);\nGENDER gender code;\nEDUCATION education level code;\nETHNICITY ethnicity (Office National Statistics categories) code.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is always a good idea to view the dataset – click on the name of the dataset in the R-Studio Environment window, and check out the columns, scroll through the rows – to get a sense of what you are working with.\n\n\n\n\n\nLab activity 1: Work with the How-to guide\nThe how-to guide comprises an .Rmd file:\n\n2023-24-PSYC122-w17-how-to.Rmd\n\nIt is full of advice and example code.\nThe code in the how-to guide was written to work with the data file:\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\nTip\n\n\n\nWe show you how to do everything you need to do in the lab activity (Section 5.4, next) in the how-to guide.\n\nStart by looking at the how-to guide to understand what steps you need to follow in the lab activity.\n\n\n\nWe will take things step-by-step.\nWe split .Rmd scripts by steps, tasks and questions:\n\ndifferent steps for different phases of the analysis workflow;\ndifferent tasks for different things you need to do;\ndifferent questions to examine different ideas or coding challenges\n\n\n\n\n\n\n\nTip\n\n\n\n\nMake sure you start at the top of the .Rmd file and work your way, in order, through each task.\nComplete each task before you move on to the next task.\n\n\n\nIn the activity Section 5.4, we are going to work through the following tasks.\n\n\n\n\n\n\nTip\n\n\n\n\nNotice that we are gradually building up our skills: consolidating what we know; revising important learning; and extending ourselves to acquire new skills.\nOver time, we will refer less and less to what we have learned before.\n\n\n\nStep 1: Set-up\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\n\nStep 2: Load the data\n\nRead in the data file – using read_csv()\nInspect the data – using head() and summary()\n\nStep 3: Use histograms to examine the distributions of variables\n\nDraw histograms to examine the distributions of variables – using ggplot() and geom_histogram()\nPractice editing the appearance of a histogram plot step-by-step\n\nStep 4: Now draw scatterplots to examine associations between variables\n\nCreate scatterplots to examine the association between some variables\nEdit the appearance of each plot step-by-step\n\nStep 5: Use correlation to to answer the research questions \n\nExamine the correlations between the outcome variable and predictor variables\n\nStep 6: Use a linear model to to answer the research questions\n\nExamine the relation between outcome mean accuracy (mean.acc) and each of the potential predictors: SHIPLEY, HLVA and AGE\n\nStep 7: Use a linear model to generate predictions\n\nUse a model we have fitted to plot model predictions\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are unsure about what you need to do, look at the advice in 2023-24-PSYC122-w17-how-to.Rmd on how to do the tasks, with examples on how to write the code.\n\n\nYou will see that you can match a task in the activity Section 5.4 to the same task in the how-to guide. The how-to shows you what function you need and how you should write the function code.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in modern psychological science.\n\n\n\n\n\n\nWarning\n\n\n\nDon’t forget: You will need to change the names of the dataset or the variables to complete the tasks in the activity.\n\n\n\n\nLab activity 2\n\n\nOK: now let’s do it!\nIn the following, we will guide you through the tasks and questions step by step. You will learn more if you follow this advice:\n\n\n\n\n\n\nTip\n\n\n\n\nWe will hide the code to do some tasks behind a drop-down button. Try to write and run the code for yourself first.\nWe won’t always give you the code required to do something: this gives you the chance to check what you have learned by trying out your code without the answer in front of you.\nWe will not at first give you the answers to questions about the data or about the results of analyses.\nAn answers version of the workbook will be provided after the last lab session (check the answers then in Section 6) so that you can check whether your independent work has been correct.\n\n\n\n\nQuestions\n\n\nStep 1: Set-up\nTo begin, we set up our environment in R.\n\nTask 1 – Run code to empty the R environment\n\nrm(list=ls())\n\n\n\nTask 2 – Run code to load relevant libraries\n\nlibrary(\"tidyverse\")\n\n\n\n\nStep 2: Load the data\n\nTask 3 – Read in the data file we will be using\nThe data file for the workbook is called:\n\nstudy-two-general-participants.csv\n\nUse the read_csv() function to read the data file into R.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nstudy.two.gen &lt;- read_csv(\"study-two-general-participants.csv\")\n\n\n\n\nWhen you code this, you can choose your own file name, but be sure to give the data object you create a distinct name e.g. study.two.gen.\n\n\nTask 4 – Inspect the data file\nUse the summary() or head() functions to take a look\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nsummary(study.two.gen)\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\nEven though you have done this before, you will want to do it again, here.\n\nPay attention to what you see, for the numeric variables, in the information about minimum (Min.) and maximum (Max.) values.\n\n\n\n\n\n\nStep 3: Use histograms to examine the distributions of variables\n\n\nRevise: make sure you are confident about doing these things\n\nTask 5 – Draw histograms to examine the distributions of variables\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse ggplot() with geom_histogram().\nWhen we create a plot, we take things step-by-step.\nHere’s an example you have seen before: run the lines of code and see the result in the Plots window in R-Studio.\n\nggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThese are the steps, set out one at a time:\n\nggplot(...) you tell R you want to make a plot using the ggplot() function\nggplot(data = study.two.gen ...) you tell R you want to make a plot with the study.two.gen data\nggplot(..., aes(x = mean.acc)) you tell R that you want to make a plot with the variable mean.acc – here, you specify the aesthetic mapping, x = mean.acc\nggplot(...) + geom_histogram() you tell R you want to plot values of mean.acc as a histogram\n\nNotice that the code works the same whether we have the different bits of code on the same line or in a series of lines.\n\n\n\n\n\nTask 6 – Practice editing the appearance of a histogram plot step-by-step\nStart by constructing a basic histogram.\n\nDraw a histogram plot to visualize the distribution of whichever numeric variable from the study.two.gen dataset you please.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nUse the line-by-line format to break the plot code into steps.\nIt will make it easier to read, and it will make it easier to add edit.\n\n\n\n\n\nPick numeric variable in the dataset.\nRun the code to produce a histogram of the variable values.\n\nCan you work out how to do it without looking at the code example?\nClick on the button to see the code example: compare it to the code you wrote.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram()\n\n\n\n\nWe are going to revise editing:\n\nThe appearance of the bars using binwidth;\nThe colour of the background using theme_bw();\nThe appearance of the labels using `labs().\n\nThen we are going to try some new moves:\n\nSetting the x-axis limits to reflect the full range of possible scores on the x-axis variable;\nAdding annotation – here, a vertical line – indicating the sample average for a variable.\n\n\nQ.1. Edit the appearance of the bars by specifying a binwidth value.\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2)\n\n\n\n\n\nQ.2. Then add an edit to the appearance of the background using theme_bw().\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw()\n\n\n\n\n\nQ.3. Then add an edit to the appearance of the labels using labs().\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"frequency count\")\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\nQ.4. Now add an edit by setting the x-axis limits using x.lim().\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40)\n\n\n\n\n\nQ.5. Then add an edit to draw a vertical line to show the mean value of the variable you are plotting..\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0,40) +\n  geom_vline(xintercept = mean(study.two.gen$SHIPLEY), colour = \"red\", size = 1.5)\n\n\n\n\n\nQ.6. Can you find information on how to define the limits on the x-axis and on the y-axis?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can see the information in this week’s how-to guide but try a search online for “ggplot reference xlim”.\n\n\n\n\n\n\nQ.7. Can you find information on how to a reference line?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can see the information in this week’s how-to but try a search online for “ggplot reference vline”.\n\n\n\n\n\n\n\nStep 4: Now draw scatterplots to examine associations between variables\n\n\nConsolidation: should be no surprises here\nBut if you want to remind yourself how to do things, click on the box to reveal hint information.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nWe are working with geom_point() and you need x and y aesthetic mappings.\nThe outcome variable mean.acc has to be mapped to the y-axis using ...y = ...\n\nThis is how the target scatterplot code works.\n\nggplot(data = data.set, aes(x = predictor.variable, y = outcome.variable)) +\n  geom_point()\n\nThe plot code moves through the following steps:\n\nggplot(...) make a plot;\nggplot(data = data.set, ...) working with the data.set, using the name you gave the dataset you are working with;\nggplot(...aes(x = predictor.variable, y = outcome.variable)) using two aesthetic mappings\n\n\nx = predictor.variable maps values of the predictor.variable (whatever it is called) to x-axis (horizontal, left to right) positions;\ny = outcome.variable maps values of the outcome.variable(whatever it is called) to y-axis (vertical, bottom to top) positions;\n\n\ngeom_point() show the mappings as points.\n\n\n\n\n\nTask 7 – Create a scatterplot to examine the association between some variables\nCreate three scatterplots to visualize the relationship between (1.) the outcome mean.acc and (2.) each of three numeric potential predictor variables SHIPLEY, HLVA and AGE.\nCheck first if you can write the code you need to produce each scatterplot. Click on the button to see the code example: compare it to the code you wrote.\n\nNotice that R will tolerate some variation in how code is written.\nThis is like any language where we can ask for the same thing in different ways.\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nCheck out the example code for each of the scatterplots we are asking you to do.\n\nNotice what changes and what stays the same.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point()\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point()\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point()\n\n\n\n\n\n\n\nRevise: make sure you are confident about doing these things\n\nTask 8 – Edit the appearance of each plot step-by-step\n\nYou may want to use the same plot appearance choices for all plots.\n\n\nProducing plots with a consistent appearance will make it easier for your audience to read your plots.\n\n\nYou can find links to reference information on options in the how-to guide.\n\n\nUse the information to make the plots pleasing in appearance to you.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nDo not be afraid to select, copy then paste code to re-use it and save yourself the effort of typing out the code over and over again.\nBut be careful to make sure that you change variable names, and that things like axis values are sensible for each variable.\n\n\n\n\n\nQ.8. First, edit the appearance of the points using alpha, size, shape, and colour.\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nCheck out the example code for each of the scatterplots.\n\nNotice what changes and what stays the same.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')\n\n\n\n\n\nQ.9. Then edit the colour of the background using theme_bw().\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nCheck out the example code for each of the scatterplots.\n\nNotice what changes and what stays the same.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw()\n\n\n\n\n\nQ.10. Then edit the appearance of the labels using labs().\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nCheck out the example code for each of the scatterplots.\n\nNotice what changes and what stays the same.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\")\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\")\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"Age (Years)\", y = \"mean accuracy\")\n\n\n\n\n\n\n\nIntroduce: make some new moves\n\nQ.11. Then set the x-axis and y-axis limits to the minimum-maximum ranges of the variables you are plotting.\n\nYou can set axis limits by adding the xlim() and ylim() function calls to the chunk of code you have written to produce each plot.\n\nThe task, here, is to work out what numeric values you should enter inside xlim() or ylim().\nThe code works if you enter values like this: xlim(minimum, maximum) and ylim(minimum, maximum).\nWhere minimum, maximum are the numbers representing the smallest possible (minimum) and largest possible (maximum) value for each variable.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor these plots the y-axis limits will be the same because the outcome stays the same.\nBut the x-axis limits will be different for each different predictor variable.\nCheck out the information in the summary() you got of the dataset.\nThe minimum values for the variables will often (not always) be 0 e.g. if you are looking at data from ability tests and people who do the tests can get 0 (because none of their responses are correct). However, if you are looking at e.g. ratings data then the minimim value could be 1 (e.g. because people are asked to rate something on a scale from 1-9).\nThe maximum values for the variables is not necessarily the largest value recorded for that variable in the sample data-set you are working with (e.g., because nobody in your sample got all test questions correct). Thus, you need to use information about measurement design, see Section 5.2.2.\n\n\n\n\nCheck first if you can write the code you need to produce each scatterplot. Click on the button to see the code example: compare it to the code you wrote.\n\n\n\n\n\n\nCode\n\n\n\n\n\nCheck out the example code for each of the scatterplots.\n\nNotice what changes and what stays the same.\n\n\nggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"SHIPLEY\", y = \"mean accuracy\") +\n  xlim(0, 40) + ylim(0, 1)\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\") +\n  xlim(0, 16) + ylim(0, 1)\n\nggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  theme_bw() +\n  labs(x = \"Age (Years)\", y = \"mean accuracy\") +\n  xlim(0, 80) + ylim(0, 1)\n\n\n\n\n\n\nStep 5: Use correlation to to answer the research questions\n\n\nRevise: make sure you are confident about doing these things\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\nTask 9 – Examine the correlations between the outcome variable and predictor variables\nYou need to run three separate correlations:\n\nbetween mean accuracy and SHIPLEY;\nbetween mean accuracy and HLVA;\nbetween mean accuracy and AGE.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nUse cor.test() to do the correlation analysis.\nYou can look at the how-to guide or review previous materials (e.g. ?@sec-wk12-labactivities or ?@sec-wk16-lab-activities-1-questions) for more advice.\n\n\n\n\nCheck first if you can write the code you need to complete each correlation analysis. Click on the button to see the code example: compare it to the code you wrote.\n\n\n\n\n\n\nCode\n\n\n\n\n\nCheck out the example code for doing each of the correlation analyses.\n\nNotice what changes and what stays the same.\n\n\ncor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\ncor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\ncor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\n\n\n\nNow use the results from the correlations to answer the following questions.\n\nQ.12. What is r, the coefficient for the correlation between mean.acc and SHIPLEY?\n\n\n\nQ.13. Is the correlation between mean.acc and HLVA significant?\n\n\n\nQ.14. What are the values for t and p for the significance test for the correlation between mean.acc and AGE?\n\n\n\nQ.15. For which pair of outcome-predictor variables is the correlation the largest?\n\n\n\nQ.16. What is the sign or direction of each of the correlations?\n\n\n\n\n\nStep 6: Use a linear model to to answer the research questions\n\n\nIntroduce: Make some new moves\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\nTask 10 – Examine the relation between outcome mean accuracy (mean.acc) and each of the predictors: SHIPLEY, HLVA and AGE\nYou need to run three separate lm() analyses:\n\nwith mean accuracy as the outcome and SHIPLEY as the predictor;\nwith mean accuracy as the outcome and HLVA as the predictor;\nwith mean accuracy as the outcome and AGE as the predictor.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou need to use lm() to do the analyses.\n\nBe careful to identify the outcome and predictor variables correctly.\nRemember that analysis code is arranged like this:\n\n\nlm(outcome.variable ~ predictor.variable, data = data.set)\n\nWith:\n\nlm() asking R to do the linear model analysis;\noutcome.variable ~ ... specified on the left of the ~;\nthe predictor.variable ~ ... specified on the right of the ~;\nand data.set identifying to R what dataset you are working with.\n\nNotice that R has a general formula syntax:\noutcome ~ predictor *or* y ~ x\n\nand uses the same format across a number of different functions;\neach time, the left of the tilde symbol ~ is some output or outcome;\nand the right of the tilde ~ is some input or predictor or set of predictors.\n\n\n\n\nCheck first if you can write the code you need to complete each linear model analysis. Click on the button to see the code example: compare it to the code you wrote.\n\n\n\n\n\n\nCode\n\n\n\n\n\nCheck out the example code for each of the models.\n\nNotice what changes and what stays the same.\n\n\nmodel.1 &lt;- lm(mean.acc ~ SHIPLEY, data = study.two.gen)\nsummary(model.1)\n\nmodel.2 &lt;- lm(mean.acc ~ HLVA, data = study.two.gen)\nsummary(model.2)\n\nmodel.3 &lt;- lm(mean.acc ~ AGE, data = study.two.gen)\nsummary(model.3)\n\n\n\n\nIf you look at the model summary you can answer the following questions.\n\nQ.17. What is the estimate for the coefficient of the effect of the predictor HLVA on mean.acc?\n\n\n\nQ.18. Is the effect significant?\n\n\n\nQ.19. What are the values for t and p for the significance test for the coefficient?\n\n\n\nQ.20. How would you describe in words the shape or direction of the association between HLVA and mean.acc?\n\n\n\nQ.21. How how would you describe the relations apparent between the predictor and outcome in all three models?\n\n\n\n\n\nStep 7: Use a linear model to generate predictions\n\n\nIntroduce: Make some new moves\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\n\nTask 11 – We can use the model we have just fitted to plot the model predictions\nWe are going to draw a scatterplot and add a line.\n\nThe line will show the model predictions, given the model intercept and effect coefficient estimates.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can see reference information here:\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html\n\n\n\nFirst fit a model and get the summary: model the relationship between mean.acc and HLVA.\nCheck first if you can write the code you need to complete the linear model analysis. Click on the button to see the code example: compare it to the code you wrote.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ HLVA, data = study.two.gen)\nsummary(model)\n\n\n\n\nYou will need to record some information from the model summary so you can use it next.\n\nQ.22. What is the coefficient estimate for the intercept?\n\n\n\nQ.23. What is the coefficient estimate for the slope of HLVA (see earlier)?\n\n\nSecond, draw a prediction plot, using the geom_point() to draw a scatterplot and using the geom_abline() function to draw the prediction line representing the association between this outcome and predictor.\nCheck first if you can write the code you need to produce the prediction plot. Click on the button to see the code example: compare it to the code you wrote.\n\n\n\n\n\n\nCode\n\n\n\n\n\n\nggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +\n  geom_point(alpha = 0.5, size = 2, colour = \"blue\", shape = 'square')   +\n  geom_abline(intercept = 0.522016, slope = 0.026207, \n              colour = \"red\", size = 1.5) +\n  theme_bw() +\n  labs(x = \"HLVA\", y = \"mean accuracy\") +\n  xlim(0, 15) + ylim(0, 1)\n\n\n\n\n\n\n\nYou have now completed the Week 17 questions.\n\n\n\n\n\n\nImportant\n\n\n\nPredicting human behaviour is at the heart of:\n\nPsychological science, and our collective attempt to understand ourselves.\nBehavioural analytics, and the ways businesses work with what we know about people.\n\nThis is an important step in your developmental journey: Well done!\n\nWe will continue to deepen and extend your skills and understanding but everything builds on the key lessons we have been learning here.",
    "crumbs": [
      "Home",
      "PSYC122",
      "6. Week 17 -- Better understanding the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week17.html#sec-wk17-lab-activities-answers",
    "href": "PSYC122/Week17.html#sec-wk17-lab-activities-answers",
    "title": "6. Week 17 – Better understanding the linear model",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week.\n\n\n\n\n\n\nTip\n\n\n\nThe .Rmd script containing all code and all answers for each task and each question will be made available after the final lab session has taken place.\n\nYou can download the script by clicking on the link: 2023-24-PSYC122-w17-workbook-answers.Rmd when it is available.\nOr by copying the code into the R Console window and running it to get the 2023-24-PSYC122-w17-workbook-answers.Rmd loaded directly into R:\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/2023-24-PSYC122-w17-workbook-answers.Rmd?raw=true\", destfile = \"2023-24-PSYC122-w17-workbook-answers.Rmd\")\n\n\n\nWe set out answers information the Week 17 Better understanding the linear model questions, below.\n\nWe focus on the Lab activity 2 questions where we ask you to interpret something or say something.\nWe do not show questions where we have given example or target code in the foregoing lab activity Section 5.4.\n\nYou can see all the code and all the answers in 2023-24-PSYC122-w17-workbook-answers.Rmd.\n\nAnswers\n\n\n\n\n\n\nTip\n\n\n\nClick on a box to reveal the answer.\n\n\n\nQuestions\n\nQ.6. Can you find information on how to define the limits on the x-axis and on the y-axis?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can see the information in this week’s how-to guide but try a search online for “ggplot reference xlim”.\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.6. See ggplot reference information on setting limits here:\n\nhttps://ggplot2.tidyverse.org/reference/lims.html\n\n\n\n\nQ.7. Can you find information on how to a reference line?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can see the information in this week’s how-to but try a search online for “ggplot reference vline”.\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.7. See ggplot reference information on adding lines here:\n\nhttps://ggplot2.tidyverse.org/reference/geom_abline.html\n\n\n\nOne of our research questions is:\n\nWhat person attributes predict success in understanding?\n\nExamine the correlations between the outcome variable and predictor variables.\nYou need to run three separate correlations:\n\nbetween mean accuracy and SHIPLEY;\nbetween mean accuracy and HLVA;\nbetween mean accuracy and AGE.\n\nCheck out the example code for doing each of the correlation analyses.\n\ncor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\ncor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\ncor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = \"pearson\",  alternative = \"two.sided\")\n\nNow use the results from the correlations to answer the following questions.\n\nQ.12. What is r, the coefficient for the correlation between mean.acc and SHIPLEY?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.12. r = 0.4650537\n\n\n\n\n\nQ.13. Is the correlation between mean.acc and HLVA significant?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.13. – r is significant, p &lt; .05\n\n\n\n\n\nQ.14. What are the values for t and p for the significance test for the correlation between mean.acc and AGE?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.14. t = 0.30121, p = 0.7636\n\n\n\n\n\nQ.15. For which pair of outcome-predictor variables is the correlation the largest?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.15. – The correlation is the largest between mean.acc and HLVA.\n\n\n\n\n\nQ.16. What is the sign or direction of each of the correlations?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.16. – All the correlations are positive.\n\n\n\n\nExamine the relation between outcome mean accuracy (mean.acc) and each of the predictors: SHIPLEY, HLVA and AGE\nYou need to run three separate lm() analyses:\n\nwith mean accuracy as the outcome and SHIPLEY as the predictor;\nwith mean accuracy as the outcome and HLVA as the predictor;\nwith mean accuracy as the outcome and AGE as the predictor.\n\nCheck out the example code for each of the models.\n\nmodel.1 &lt;- lm(mean.acc ~ SHIPLEY, data = study.two.gen)\nsummary(model.1)\n\nmodel.2 &lt;- lm(mean.acc ~ HLVA, data = study.two.gen)\nsummary(model.2)\n\nmodel.3 &lt;- lm(mean.acc ~ AGE, data = study.two.gen)\nsummary(model.3)\n\nIf you look at the model summary you can answer the following questions.\n\nQ.17. What is the estimate for the coefficient of the effect of the predictor HLVA on mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.17. 0.026207\n\n\n\n\n\nQ.18. Is the effect significant?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.18. It is significant, p &lt; .05\n\n\n\n\n\nQ.19. What are the values for t and p for the significance test for the coefficient?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.19. t = 7.529, p = 2.87e-12\n\n\n\n\n\nQ.20. How would you describe in words the shape or direction of the association between HLVA and mean.acc?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.20. The slope coefficient – and a scatterplot (draw it) – suggest that as HLVA scores increase so also do mean accuracy scores.\n\n\n\n\n\nQ.21. How how would you describe the relations apparent between the predictor and outcome in all three models?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.21. It is possible to see, given coefficient estimates, that the association between predictor and outcome is positive for each model: mean accuracy appears to increase for increasing values of SHIPLEY vocabulary, HLVA health literacy, and age.\n\n\n\n\nWe are going to draw a scatterplot and add a line.\n\nThe line will show the model predictions, given the model intercept and effect coefficient estimates.\n\nFirst fit a model and get the summary: model the relationship between mean.acc and HLVA.\nYou will need to record some information from the model summary so you can use it next.\n\nQ.22. What is the coefficient estimate for the intercept?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.22. 0.522016\n\n\n\n\n\nQ.23. What is the coefficient estimate for the slope of HLVA (see earlier)?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nA.23. 0.026207",
    "crumbs": [
      "Home",
      "PSYC122",
      "6. Week 17 -- Better understanding the linear model"
    ]
  },
  {
    "objectID": "PSYC122/Week17.html#sec-wk17-lab-Q-and-A",
    "href": "PSYC122/Week17.html#sec-wk17-lab-Q-and-A",
    "title": "6. Week 17 – Better understanding the linear model",
    "section": "Online Q&A",
    "text": "Online Q&A\nYou will find, below, a link to the video recording of the Week 17 online Q&A after it has been completed.",
    "crumbs": [
      "Home",
      "PSYC122",
      "6. Week 17 -- Better understanding the linear model"
    ]
  }
]